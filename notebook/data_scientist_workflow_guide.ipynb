{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "abbd8875",
   "metadata": {},
   "source": [
    "# 🎉 Welcome to SageMaker Unified Studio!\n",
    "\n",
    "**✨ UPGRADED INFRASTRUCTURE: This project now uses SageMaker Unified Studio instead of traditional notebook instances!**\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2988459d",
   "metadata": {},
   "source": [
    "# 🚀 Data Scientist MLOps Workflow Guide\n",
    "\n",
    "## Overview\n",
    "This notebook demonstrates how to leverage SageMaker Unified Studio for your complete data science workflow. The infrastructure provides:\n",
    "\n",
    "- **SageMaker Unified Studio** - Modern collaborative workspace with JupyterLab, Canvas, RStudio\n",
    "- **Data Catalog & Governance** - Built-in data discovery and governance capabilities  \n",
    "- **S3 Storage** - Secure data and model artifact storage\n",
    "- **Collaborative Features** - Team sharing and business glossaries\n",
    "- **AI-Powered Assistance** - Amazon Q for natural language data queries\n",
    "- **IAM Security** - Enterprise-grade access management"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2601532f",
   "metadata": {},
   "source": [
    "## 1. Connect to SageMaker Unified Studio Environment\n",
    "\n",
    "First, let's establish connection to your Unified Studio workspace and verify access to all the collaborative features."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0b61b15",
   "metadata": {},
   "source": [
    "## 🛠️ Project Setup and Scripts Availability\n",
    "\n",
    "This section ensures you have access to all the MLOps scripts and source code in your SageMaker environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02c713ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SageMaker Unified Studio Environment Check\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"SAGEMAKER UNIFIED STUDIO ENVIRONMENT CHECK\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "import boto3\n",
    "import sagemaker\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import os\n",
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "# Initialize AWS and SageMaker sessions\n",
    "session = boto3.Session()\n",
    "region = session.region_name\n",
    "account_id = boto3.client('sts').get_caller_identity()['Account']\n",
    "sagemaker_session = sagemaker.Session()\n",
    "\n",
    "print(f\"AWS Account: {account_id}\")\n",
    "print(f\"AWS Region: {region}\")\n",
    "print(f\"SageMaker Session: Initialized\")\n",
    "\n",
    "# Check if running in SageMaker Studio\n",
    "studio_metadata_path = \"/opt/ml/metadata/resource-metadata.json\"\n",
    "if os.path.exists(studio_metadata_path):\n",
    "    with open(studio_metadata_path, 'r') as f:\n",
    "        metadata = json.load(f)\n",
    "    print(f\"Environment: SageMaker Unified Studio\")\n",
    "    print(f\"Domain ID: {metadata.get('DomainId', 'N/A')}\")\n",
    "    print(f\"User Profile: {metadata.get('UserProfileName', 'N/A')}\")\n",
    "    print(f\"Instance Type: {metadata.get('ResourceArn', 'N/A').split('/')[-1] if metadata.get('ResourceArn') else 'N/A'}\")\n",
    "else:\n",
    "    print(f\"Environment: Compatible SageMaker Environment\")\n",
    "\n",
    "# Package versions\n",
    "print(f\"\\nPACKAGE VERSIONS:\")\n",
    "print(f\"SageMaker SDK: {sagemaker.__version__}\")\n",
    "print(f\"Pandas: {pd.__version__}\")\n",
    "print(f\"NumPy: {np.__version__}\")\n",
    "print(f\"Scikit-learn: {sklearn.__version__}\")\n",
    "\n",
    "# Check SageMaker capabilities\n",
    "print(f\"\\nSAGEMAKER CAPABILITIES:\")\n",
    "try:\n",
    "    bucket = sagemaker_session.default_bucket()\n",
    "    print(f\"Default S3 Bucket: {bucket}\")\n",
    "    \n",
    "    role = sagemaker.get_execution_role()\n",
    "    print(f\"Execution Role: {role.split('/')[-1]}\")\n",
    "    \n",
    "    print(f\"Training Instance Types: Available\")\n",
    "    print(f\"Inference Instance Types: Available\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"SageMaker setup error: {e}\")\n",
    "\n",
    "# Check Studio-specific features\n",
    "print(f\"\\nUNIFIED STUDIO FEATURES:\")\n",
    "try:\n",
    "    # Check Model Registry access\n",
    "    model_packages = sagemaker_session.list_model_packages(max_results=1)\n",
    "    print(f\"Model Registry: Available\")\n",
    "except:\n",
    "    print(f\"Model Registry: Limited access\")\n",
    "\n",
    "try:\n",
    "    # Check Canvas availability\n",
    "    sm_client = boto3.client('sagemaker')\n",
    "    domains = sm_client.list_domains(MaxResults=1)\n",
    "    if domains['Domains']:\n",
    "        print(f\"Canvas: Available\")\n",
    "        print(f\"Collaborative Features: Enabled\")\n",
    "        print(f\"Data Catalog: Integrated\")\n",
    "    else:\n",
    "        print(f\"Canvas: Not configured\")\n",
    "except:\n",
    "    print(f\"Studio Features: Basic access\")\n",
    "\n",
    "print(f\"\\nEnvironment check complete!\")\n",
    "\n",
    "# Set global variables\n",
    "REGION = region\n",
    "ACCOUNT_ID = account_id\n",
    "BUCKET = sagemaker_session.default_bucket()\n",
    "ROLE = sagemaker.get_execution_role()\n",
    "\n",
    "print(f\"\\nGlobal variables set:\")\n",
    "print(f\"REGION = '{REGION}'\")\n",
    "print(f\"ACCOUNT_ID = '{ACCOUNT_ID}'\")\n",
    "print(f\"BUCKET = '{BUCKET}'\")\n",
    "print(f\"ROLE = '{ROLE.split('/')[-1]}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a04382f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import sagemaker\n",
    "from sagemaker import get_execution_role\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "import json\n",
    "import os\n",
    "\n",
    "# Initialize SageMaker Unified Studio session\n",
    "sagemaker_session = sagemaker.Session()\n",
    "region = sagemaker_session.boto_region_name\n",
    "role = get_execution_role()\n",
    "\n",
    "print(f\"SageMaker Session: Initialized\")\n",
    "print(f\"Region: {region}\")\n",
    "print(f\"Execution Role: {role}\")\n",
    "\n",
    "# Find ML artifacts bucket from infrastructure\n",
    "s3_client = boto3.client('s3')\n",
    "buckets = s3_client.list_buckets()\n",
    "ml_bucket = None\n",
    "\n",
    "for bucket in buckets['Buckets']:\n",
    "    if 'ml-artifacts' in bucket['Name']:\n",
    "        ml_bucket = bucket['Name']\n",
    "        break\n",
    "\n",
    "if ml_bucket:\n",
    "    print(f\"ML Bucket: {ml_bucket}\")\n",
    "    print(f\"Studio Data Catalog: Ready\")\n",
    "    print(f\"Collaborative Features: Enabled\")\n",
    "    print(f\"Canvas Integration: Available\")\n",
    "    \n",
    "    # Check data governance features\n",
    "    try:\n",
    "        sm_client = boto3.client('sagemaker')\n",
    "        domains = sm_client.list_domains(MaxResults=1)\n",
    "        if domains['Domains']:\n",
    "            domain_id = domains['Domains'][0]['DomainId']\n",
    "            print(f\"Data Governance Domain: {domain_id}\")\n",
    "            print(f\"Business Glossary: Available\")\n",
    "    except:\n",
    "        print(f\"Studio Features: Basic access\")\n",
    "else:\n",
    "    print(\"Warning: ML bucket not found. Check Terraform deployment.\")\n",
    "    ml_bucket = \"your-ml-artifacts-bucket-name\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82ae0ebc",
   "metadata": {},
   "source": [
    "## 🏛️ Data Governance & Collaboration in SageMaker Unified Studio\n",
    "\n",
    "**🌟 NEW FEATURE: Your environment now includes advanced data governance and collaboration capabilities!**\n",
    "\n",
    "### 📊 **Data Catalog & Discovery**\n",
    "\n",
    "SageMaker Unified Studio includes a built-in data catalog that helps you:\n",
    "\n",
    "- 🔍 **Discover Data Assets**: Search and find datasets across your organization\n",
    "- 📋 **Manage Metadata**: Automatically catalog data with AI-generated descriptions\n",
    "- 🔗 **Track Data Lineage**: See how data flows through your ML pipelines\n",
    "- 📈 **Monitor Data Quality**: Get quality scores and validation reports\n",
    "- 🤖 **Ask Amazon Q**: Use natural language to find the data you need\n",
    "\n",
    "### 🤝 **Collaborative Features**\n",
    "\n",
    "Work seamlessly with your team:\n",
    "\n",
    "- 👥 **Shared Workspaces**: Collaborate on notebooks and experiments\n",
    "- 📤 **Asset Sharing**: Share models, datasets, and notebooks with fine-grained permissions\n",
    "- 📝 **Business Glossary**: Create shared definitions and standards\n",
    "- 🏷️ **Data Products**: Package and distribute curated datasets\n",
    "- 💬 **Team Communication**: Built-in collaboration tools\n",
    "\n",
    "### 🔐 **Governance & Security**\n",
    "\n",
    "Enterprise-grade governance:\n",
    "\n",
    "- 🛡️ **Fine-grained Access Control**: Role-based permissions for data and models\n",
    "- 📊 **Audit Trails**: Complete tracking of data access and model usage\n",
    "- 🏢 **Business Units**: Organize assets by teams and departments\n",
    "- 📜 **Compliance**: Built-in tools for regulatory compliance\n",
    "- 🔒 **Data Privacy**: Automated PII detection and protection\n",
    "\n",
    "### 🎨 **SageMaker Canvas Integration**\n",
    "\n",
    "No-code ML for business users:\n",
    "\n",
    "- 🖱️ **Point-and-Click ML**: Build models without coding\n",
    "- 📊 **Automatic Insights**: AI-powered data analysis\n",
    "- 📈 **Business Forecasting**: Time-series prediction made easy\n",
    "- 📋 **Model Sharing**: Share Canvas models with data scientists\n",
    "\n",
    "---\n",
    "\n",
    "**💡 Next: Let's set up your data and create your first governed ML pipeline!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faf45ecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data from S3\n",
    "data_key = 'data/iris.csv'\n",
    "data_path = f's3://{ml_bucket}/{data_key}'\n",
    "\n",
    "print(f\"Loading data from: {data_path}\")\n",
    "\n",
    "try:\n",
    "    # Load dataset\n",
    "    df = pd.read_csv(data_path)\n",
    "    print(f\"Data loaded successfully!\")\n",
    "    print(f\"Dataset shape: {df.shape}\")\n",
    "    print(f\"Columns: {list(df.columns)}\")\n",
    "    \n",
    "    # Display first rows\n",
    "    print(\"\\nFirst 5 rows:\")\n",
    "    display(df.head())\n",
    "    \n",
    "    # Basic statistics\n",
    "    print(\"\\nDataset Statistics:\")\n",
    "    display(df.describe())\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Error loading data: {e}\")\n",
    "    print(\"Note: Upload iris.csv to your S3 bucket manually if needed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35ede089",
   "metadata": {},
   "source": [
    "## 3. Data Preprocessing and Cleaning\n",
    "\n",
    "Perform data cleaning and preprocessing. In a real scenario, this is where you'd handle missing values, outliers, and data quality issues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a595b995",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data quality assessment\n",
    "print(\"Data Quality Assessment:\")\n",
    "print(f\"Missing values:\\n{df.isnull().sum()}\")\n",
    "print(f\"\\nDuplicate rows: {df.duplicated().sum()}\")\n",
    "print(f\"\\nData types:\\n{df.dtypes}\")\n",
    "\n",
    "# Target distribution\n",
    "print(f\"\\nTarget distribution:\")\n",
    "print(df['species'].value_counts())\n",
    "\n",
    "# Create visualizations\n",
    "plt.figure(figsize=(15, 10))\n",
    "\n",
    "# Species distribution\n",
    "plt.subplot(2, 3, 1)\n",
    "df['species'].value_counts().plot(kind='bar')\n",
    "plt.title('Species Distribution')\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "# Feature distributions\n",
    "features = ['sepal_length', 'sepal_width', 'petal_length', 'petal_width']\n",
    "for i, feature in enumerate(features, 2):\n",
    "    plt.subplot(2, 3, i)\n",
    "    df[feature].hist(bins=20, alpha=0.7)\n",
    "    plt.title(f'{feature.replace(\"_\", \" \").title()} Distribution')\n",
    "    plt.xlabel(feature)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Correlation analysis\n",
    "plt.figure(figsize=(10, 8))\n",
    "correlation_matrix = df[features].corr()\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', center=0)\n",
    "plt.title('Feature Correlation Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73d0c508",
   "metadata": {},
   "source": [
    "## 4. Feature Engineering Pipeline\n",
    "\n",
    "Create feature engineering transformations and save processed data back to S3 for reusability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38967fab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "import joblib\n",
    "\n",
    "# Feature engineering\n",
    "print(\"Feature Engineering...\")\n",
    "\n",
    "# Create engineered features\n",
    "df_processed = df.copy()\n",
    "df_processed['sepal_ratio'] = df_processed['sepal_length'] / df_processed['sepal_width']\n",
    "df_processed['petal_ratio'] = df_processed['petal_length'] / df_processed['petal_width']\n",
    "df_processed['sepal_area'] = df_processed['sepal_length'] * df_processed['sepal_width']\n",
    "df_processed['petal_area'] = df_processed['petal_length'] * df_processed['petal_width']\n",
    "\n",
    "print(f\"Added engineered features: sepal_ratio, petal_ratio, sepal_area, petal_area\")\n",
    "\n",
    "# Prepare features and target\n",
    "feature_columns = [col for col in df_processed.columns if col != 'species']\n",
    "X = df_processed[feature_columns]\n",
    "y = df_processed['species']\n",
    "\n",
    "print(f\"Feature matrix shape: {X.shape}\")\n",
    "print(f\"Target vector shape: {y.shape}\")\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(f\"Train set: {X_train.shape}, Test set: {X_test.shape}\")\n",
    "\n",
    "# Feature scaling\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Convert back to DataFrames\n",
    "X_train_scaled = pd.DataFrame(X_train_scaled, columns=feature_columns, index=X_train.index)\n",
    "X_test_scaled = pd.DataFrame(X_test_scaled, columns=feature_columns, index=X_test.index)\n",
    "\n",
    "print(\"Features scaled using StandardScaler\")\n",
    "\n",
    "# Save processed data to S3\n",
    "processed_data_key = 'processed-data'\n",
    "timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "\n",
    "# Save training data\n",
    "train_data = pd.concat([X_train_scaled, y_train], axis=1)\n",
    "train_s3_path = f's3://{ml_bucket}/{processed_data_key}/train_{timestamp}.csv'\n",
    "train_data.to_csv(train_s3_path, index=False)\n",
    "print(f\"Training data saved to: {train_s3_path}\")\n",
    "\n",
    "# Save test data\n",
    "test_data = pd.concat([X_test_scaled, y_test], axis=1)\n",
    "test_s3_path = f's3://{ml_bucket}/{processed_data_key}/test_{timestamp}.csv'\n",
    "test_data.to_csv(test_s3_path, index=False)\n",
    "print(f\"Test data saved to: {test_s3_path}\")\n",
    "\n",
    "# Save scaler\n",
    "scaler_path = f'/tmp/scaler_{timestamp}.joblib'\n",
    "joblib.dump(scaler, scaler_path)\n",
    "scaler_s3_path = f's3://{ml_bucket}/models/scaler_{timestamp}.joblib'\n",
    "sagemaker_session.upload_data(scaler_path, bucket=ml_bucket, key_prefix='models')\n",
    "print(f\"Scaler saved to S3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c745a0b",
   "metadata": {},
   "source": [
    "## 5. Model Training with SageMaker Estimators\n",
    "\n",
    "Now we'll use the production-ready training script from `src/model/train.py` with SageMaker's training capabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4be336bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.sklearn.estimator import SKLearn\n",
    "from sagemaker.inputs import TrainingInput\n",
    "\n",
    "print(\"Setting up SageMaker Training Job...\")\n",
    "\n",
    "# Configure SKLearn estimator\n",
    "sklearn_estimator = SKLearn(\n",
    "    entry_point='train.py',\n",
    "    source_dir='src/model',\n",
    "    role=role,\n",
    "    instance_type='ml.m5.large',\n",
    "    framework_version='1.2-1',\n",
    "    py_version='py3',\n",
    "    hyperparameters={\n",
    "        'n_estimators': 100,\n",
    "        'max_depth': 10,\n",
    "        'random_state': 42\n",
    "    },\n",
    "    base_job_name='iris-training'\n",
    ")\n",
    "\n",
    "print(\"SKLearn estimator configured\")\n",
    "\n",
    "# Define training input\n",
    "train_input = TrainingInput(\n",
    "    s3_data=f's3://{ml_bucket}/data/',\n",
    "    content_type='text/csv'\n",
    ")\n",
    "\n",
    "print(f\"Training input configured: s3://{ml_bucket}/data/\")\n",
    "\n",
    "# Check data availability in S3\n",
    "print(\"Checking training data availability...\")\n",
    "try:\n",
    "    response = s3_client.list_objects_v2(Bucket=ml_bucket, Prefix='data/')\n",
    "    if 'Contents' in response:\n",
    "        print(\"Data found in S3:\")\n",
    "        for obj in response['Contents']:\n",
    "            print(f\"  {obj['Key']} ({obj['Size']} bytes)\")\n",
    "    else:\n",
    "        print(\"No data found in S3 data/ folder\")\n",
    "        print(\"Run 'terraform apply' to upload the iris.csv file\")\n",
    "except Exception as e:\n",
    "    print(f\"Error checking S3: {e}\")\n",
    "\n",
    "print(\"\\nReady to start training!\")\n",
    "print(\"To train the model, run:\")\n",
    "print(\"sklearn_estimator.fit({'training': train_input})\")\n",
    "\n",
    "# Uncomment to start training:\n",
    "# sklearn_estimator.fit({'training': train_input})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95408c5f",
   "metadata": {},
   "source": [
    "## 6. Model Evaluation and Validation\n",
    "\n",
    "Let's demonstrate local model training and evaluation using the same logic as our production script."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2f2d007",
   "metadata": {},
   "source": [
    "## 🔧 Troubleshooting SageMaker Training Issues\n",
    "\n",
    "If you encounter training job failures, here are common issues and solutions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5be1b78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SageMaker Training Troubleshooting Guide\n",
    "\n",
    "print(\"\udd27 SageMaker Training Troubleshooting\")\n",
    "print()\n",
    "\n",
    "common_issues = {\n",
    "    \"Data not found\": \"Ensure iris.csv is in s3://{bucket}/data/ - run 'terraform apply'\",\n",
    "    \"Script execution error\": \"Check training script logs in CloudWatch\",\n",
    "    \"Framework version issues\": \"Using framework_version='1.2-1' (current stable)\",\n",
    "    \"Permission errors\": \"Verify SageMaker execution role has S3 access\"\n",
    "}\n",
    "\n",
    "for issue, solution in common_issues.items():\n",
    "    print(f\"• {issue}: {solution}\")\n",
    "\n",
    "print(f\"\\n\udccb Current setup:\")\n",
    "print(f\"  Training script: src/model/train.py\")\n",
    "print(f\"  Requirements: src/model/requirements.txt\") \n",
    "print(f\"  Data location: s3://{ml_bucket}/data/\")\n",
    "print(f\"  Framework: sklearn 1.2-1\")\n",
    "\n",
    "print(f\"\\n💡 To debug training failures:\")\n",
    "print(f\"  1. Check CloudWatch logs for the training job\")\n",
    "print(f\"  2. Verify data exists in S3\")\n",
    "print(f\"  3. Test training script locally first\")\n",
    "\n",
    "print(f\"\\n✅ Training script is ready and well-structured!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "898cf5f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quick Environment Check\n",
    "\n",
    "print(\"\udd0d Environment Status:\")\n",
    "\n",
    "# Check training script\n",
    "if os.path.exists('src/model/train.py'):\n",
    "    print(\"✅ Training script: src/model/train.py\")\n",
    "else:\n",
    "    print(\"❌ Training script missing\")\n",
    "\n",
    "# Check requirements\n",
    "if os.path.exists('src/model/requirements.txt'):\n",
    "    print(\"✅ Requirements: src/model/requirements.txt\")\n",
    "else:\n",
    "    print(\"❌ Requirements file missing\")\n",
    "\n",
    "# Check S3 data\n",
    "try:\n",
    "    if ml_bucket:\n",
    "        response = s3_client.list_objects_v2(Bucket=ml_bucket, Prefix='data/iris.csv')\n",
    "        if 'Contents' in response:\n",
    "            print(\"✅ Data: iris.csv found in S3\")\n",
    "        else:\n",
    "            print(\"❌ Data: iris.csv not found in S3\")\n",
    "    else:\n",
    "        print(\"❌ ML bucket not identified\")\n",
    "except:\n",
    "    print(\"⚠️ Cannot check S3 data\")\n",
    "\n",
    "# Check role\n",
    "print(f\"✅ SageMaker role: {role.split('/')[-1]}\")\n",
    "\n",
    "print(f\"\\n\ude80 Ready to train with SageMaker!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "628a92d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV\n",
    "import seaborn as sns\n",
    "\n",
    "print(\"Model Training and Evaluation...\")\n",
    "\n",
    "# Train model locally (same algorithm as production script)\n",
    "model = RandomForestClassifier(\n",
    "    n_estimators=100,\n",
    "    random_state=42,\n",
    "    max_depth=10\n",
    ")\n",
    "\n",
    "model.fit(X_train_scaled, y_train)\n",
    "print(\"Model trained successfully\")\n",
    "\n",
    "# Make predictions\n",
    "y_pred = model.predict(X_test_scaled)\n",
    "y_pred_proba = model.predict_proba(X_test_scaled)\n",
    "\n",
    "# Calculate metrics\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Test Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "# Cross-validation\n",
    "cv_scores = cross_val_score(model, X_train_scaled, y_train, cv=5)\n",
    "print(f\"Cross-validation scores: {cv_scores}\")\n",
    "print(f\"Mean CV accuracy: {cv_scores.mean():.4f} (+/- {cv_scores.std() * 2:.4f})\")\n",
    "\n",
    "# Classification report\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Visualizations\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "# Confusion matrix\n",
    "plt.subplot(1, 2, 1)\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "            xticklabels=model.classes_, yticklabels=model.classes_)\n",
    "plt.title('Confusion Matrix')\n",
    "plt.ylabel('True Label')\n",
    "plt.xlabel('Predicted Label')\n",
    "\n",
    "# Feature importance\n",
    "plt.subplot(1, 2, 2)\n",
    "feature_importance = pd.DataFrame({\n",
    "    'feature': feature_columns,\n",
    "    'importance': model.feature_importances_\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "sns.barplot(data=feature_importance, y='feature', x='importance')\n",
    "plt.title('Feature Importance')\n",
    "plt.xlabel('Importance')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nTop 5 most important features:\")\n",
    "print(feature_importance.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f13847f",
   "metadata": {},
   "source": [
    "## 7. Deploy Model to SageMaker Endpoint\n",
    "\n",
    "Once satisfied with the model performance, deploy it using SageMaker's inference infrastructure."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d03843f",
   "metadata": {},
   "source": [
    "## 🚀 Complete Deployment Guide: SageMaker Unified Studio\n",
    "\n",
    "This section shows you how to deploy your model within the **SageMaker Unified Studio** ecosystem.\n",
    "\n",
    "### 📋 Deployment Options in Unified Studio\n",
    "\n",
    "#### Option 1: 🎯 **Studio Real-time Endpoints** (RECOMMENDED)\n",
    "- ✅ Native Studio integration\n",
    "- ✅ Built-in monitoring and governance\n",
    "- ✅ Team collaboration features\n",
    "- ✅ Canvas integration for business users\n",
    "\n",
    "#### Option 2: \udd04 **Studio Batch Transform**\n",
    "- ✅ Large-scale batch processing\n",
    "- ✅ Cost-effective for batch predictions\n",
    "- ✅ Integrated with data catalog\n",
    "\n",
    "#### Option 3: 🤝 **Canvas Model Sharing**\n",
    "- ✅ No-code deployment for business users\n",
    "- ✅ Business-friendly interface\n",
    "- ✅ Governance and approval workflows\n",
    "\n",
    "---\n",
    "\n",
    "### 🎯 **Option 1: Studio Real-time Endpoints (RECOMMENDED)**\n",
    "\n",
    "This is the **recommended approach** for SageMaker Unified Studio:\n",
    "\n",
    "```python\n",
    "# Deploy directly within Studio environment\n",
    "predictor = sklearn_estimator.deploy(\n",
    "    initial_instance_count=1,\n",
    "    instance_type='ml.m5.large',\n",
    "    endpoint_name='iris-studio-model'\n",
    ")\n",
    "\n",
    "# Test immediately\n",
    "test_data = [[5.1, 3.5, 1.4, 0.2]]\n",
    "prediction = predictor.predict(test_data)\n",
    "print(f\"Prediction: {prediction}\")\n",
    "\n",
    "# Model is now available in Studio Model Registry\n",
    "# and can be shared with team members\n",
    "```\n",
    "\n",
    "**Studio Benefits:**\n",
    "- ✅ Automatic model registry integration\n",
    "- ✅ Built-in governance and approval workflows\n",
    "- ✅ Team sharing and collaboration\n",
    "- ✅ Canvas integration for business users\n",
    "- ✅ Lineage tracking and data catalog integration\n",
    "\n",
    "---\n",
    "\n",
    "### 🎨 **Option 3: Canvas Integration**\n",
    "\n",
    "Share your model with business users through Canvas:\n",
    "\n",
    "1. **Deploy model** using Option 1\n",
    "2. **Register in Studio** - Automatic with Studio deployment\n",
    "3. **Share with Canvas users** - Through Studio permissions\n",
    "4. **Business users access** - Via Canvas no-code interface\n",
    "\n",
    "```python\n",
    "# After deployment, register for Canvas\n",
    "from sagemaker.model import Model\n",
    "\n",
    "model = Model(\n",
    "    image_uri=sklearn_estimator.image_uri,\n",
    "    model_data=sklearn_estimator.model_data,\n",
    "    role=role\n",
    ")\n",
    "\n",
    "# Model is automatically available in Canvas for business users\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### 🧪 **Testing Your Studio-Deployed Model**\n",
    "\n",
    "```python\n",
    "import boto3\n",
    "import json\n",
    "\n",
    "runtime = boto3.client('sagemaker-runtime')\n",
    "endpoint_name = 'your-endpoint-name'\n",
    "payload = [[5.1, 3.5, 1.4, 0.2]]\n",
    "\n",
    "response = runtime.invoke_endpoint(\n",
    "    EndpointName=endpoint_name,\n",
    "    ContentType='application/json',\n",
    "    Body=json.dumps(payload)\n",
    ")\n",
    "\n",
    "result = json.loads(response['Body'].read().decode())\n",
    "print(f'Prediction: {result}')\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### 🧹 **Studio Resource Management**\n",
    "\n",
    "```python\n",
    "# Clean up endpoints\n",
    "predictor.delete_endpoint()\n",
    "\n",
    "# Or use Studio console for visual management\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### 💡 **Which Option Should You Choose?**\n",
    "\n",
    "- **🎯 Data Scientists**: Use Studio Real-time Endpoints (Option 1)\n",
    "- **📊 Batch Processing**: Use Batch Transform (Option 2)  \n",
    "- **👥 Business Users**: Share via Canvas (Option 3)\n",
    "- **🧪 Quick Testing**: Use Studio endpoints with built-in testing\n",
    "\n",
    "**Next**: Choose your deployment method and leverage Studio's collaborative features!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92161a38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SageMaker Unified Studio Deployment Demo\n",
    "\n",
    "print(\"SageMaker Unified Studio Model Deployment\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Check Studio environment and features\n",
    "import os\n",
    "import json\n",
    "\n",
    "print(\"UNIFIED STUDIO FEATURES:\")\n",
    "print(\"- Real-time endpoints with governance\")\n",
    "print(\"- Model registry integration\")\n",
    "print(\"- Team collaboration and sharing\")\n",
    "print(\"- Canvas integration for business users\")\n",
    "print(\"- Data catalog and lineage tracking\")\n",
    "print(\"- Built-in monitoring and alerts\")\n",
    "\n",
    "# Check Studio-specific capabilities\n",
    "try:\n",
    "    # Check if we're in Studio environment\n",
    "    studio_metadata_path = \"/opt/ml/metadata/resource-metadata.json\"\n",
    "    if os.path.exists(studio_metadata_path):\n",
    "        with open(studio_metadata_path, 'r') as f:\n",
    "            metadata = json.load(f)\n",
    "        print(f\"\\nStudio Environment Detected:\")\n",
    "        print(f\"Domain ID: {metadata.get('DomainId', 'N/A')}\")\n",
    "        print(f\"User Profile: {metadata.get('UserProfileName', 'N/A')}\")\n",
    "        print(f\"Collaborative Features: Enabled\")\n",
    "    else:\n",
    "        print(f\"\\nRunning in compatible SageMaker environment\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"Studio metadata not available: {e}\")\n",
    "\n",
    "print(f\"\\nSTUDIO DEPLOYMENT OPTIONS:\")\n",
    "\n",
    "print(\"\\n1. REAL-TIME ENDPOINT (Recommended)\")\n",
    "print(\"   - Native Studio integration\")\n",
    "print(\"   - Automatic model registry\")\n",
    "print(\"   - Team sharing capabilities\")\n",
    "print(\"   Usage: sklearn_estimator.deploy()\")\n",
    "\n",
    "print(\"\\n2. BATCH TRANSFORM\")\n",
    "print(\"   - Large-scale batch processing\")\n",
    "print(\"   - Cost-effective for bulk predictions\")\n",
    "print(\"   Usage: sklearn_estimator.transformer()\")\n",
    "\n",
    "print(\"\\n3. CANVAS INTEGRATION\")\n",
    "print(\"   - Business user access\")\n",
    "print(\"   - No-code interface\")\n",
    "print(\"   - Governance workflows\")\n",
    "print(\"   Usage: Deploy + Share via Studio\")\n",
    "\n",
    "print(f\"\\nSTUDIO COLLABORATION FEATURES:\")\n",
    "print(\"- Team model sharing\")\n",
    "print(\"- Business glossary integration\")  \n",
    "print(\"- Automated metadata tagging\")\n",
    "print(\"- Lineage tracking\")\n",
    "print(\"- Data catalog search\")\n",
    "print(\"- Amazon Q assistance\")\n",
    "\n",
    "print(f\"\\nQUICK DEPLOY FOR STUDIO:\")\n",
    "print(\"Uncomment the lines below for Studio deployment:\")\n",
    "\n",
    "print(\"\"\"\n",
    "# Studio-optimized deployment\n",
    "# predictor = sklearn_estimator.deploy(\n",
    "#     initial_instance_count=1,\n",
    "#     instance_type='ml.m5.large',\n",
    "#     endpoint_name='iris-studio-model',\n",
    "#     tags=[\n",
    "#         {'Key': 'Environment', 'Value': 'Studio'},\n",
    "#         {'Key': 'Team', 'Value': 'DataScience'},\n",
    "#         {'Key': 'Project', 'Value': 'IrisClassification'}\n",
    "#     ]\n",
    "# )\n",
    "# \n",
    "# # Test the endpoint\n",
    "# test_data = [[5.1, 3.5, 1.4, 0.2]]\n",
    "# prediction = predictor.predict(test_data)\n",
    "# print(f\"Studio Prediction: {prediction}\")\n",
    "# \n",
    "# # Model is now available in Studio Model Registry\n",
    "# # and can be shared with team members\n",
    "\"\"\")\n",
    "\n",
    "print(\"\\nCANVAS SHARING:\")\n",
    "print(\"After deployment, business users can access via Canvas:\")\n",
    "print(\"1. Model appears in Canvas model library\")\n",
    "print(\"2. Business users can make predictions\")\n",
    "print(\"3. No coding required for end users\")\n",
    "print(\"4. Governance and approval workflows\")\n",
    "\n",
    "print(f\"\\nSTUDIO ADVANTAGE:\")\n",
    "print(\"Unlike traditional SageMaker, Studio provides:\")\n",
    "print(\"- Built-in collaboration\")\n",
    "print(\"- Data governance\")\n",
    "print(\"- Business user access\")\n",
    "print(\"- Integrated workflows\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f46854e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 📋 Step-by-Step Studio Deployment Guide\n",
    "\n",
    "print(\"🎯 SAGEMAKER UNIFIED STUDIO DEPLOYMENT GUIDE\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(\"\\n1️⃣ STUDIO REAL-TIME ENDPOINT (Recommended)\")\n",
    "print(\"   Perfect for interactive predictions and team collaboration\")\n",
    "print()\n",
    "\n",
    "print(\"   Step 1: Deploy with Studio Integration\")\n",
    "print(\"   ────────────────────────────────────────\")\n",
    "print(\"   • What it does: Creates endpoint with Studio governance\")\n",
    "print(\"   • Benefits: Team sharing, model registry, Canvas integration\")\n",
    "print(\"   • Command to run:\")\n",
    "print(\"     predictor = sklearn_estimator.deploy(\")\n",
    "print(\"         initial_instance_count=1,\")\n",
    "print(\"         instance_type='ml.m5.large',\")\n",
    "print(\"         endpoint_name='iris-studio-model'\")\n",
    "print(\"     )\")\n",
    "print()\n",
    "print(\"   🔍 This creates:\")\n",
    "print(\"     → Real-time prediction endpoint\")\n",
    "print(\"     → Model registry entry\")\n",
    "print(\"     → Team sharing permissions\")\n",
    "print(\"     → Canvas integration (automatic)\")\n",
    "print()\n",
    "\n",
    "print(\"   Step 2: Test and Share\")\n",
    "print(\"   ─────────────────────\")\n",
    "print(\"   • Test predictions: predictor.predict(test_data)\")\n",
    "print(\"   • Share with team: Via Studio permissions\")\n",
    "print(\"   • Enable Canvas: Automatic for business users\")\n",
    "print()\n",
    "\n",
    "print(\"\\n2️⃣ STUDIO BATCH TRANSFORM\")\n",
    "print(\"   Great for large-scale batch processing\")\n",
    "print()\n",
    "print(\"   • Create transformer: sklearn_estimator.transformer()\")\n",
    "print(\"   • Process batch data: transformer.transform(s3_data)\")\n",
    "print(\"   • Results in S3: Automatic output to specified location\")\n",
    "print()\n",
    "\n",
    "print(\"\\n3️⃣ CANVAS BUSINESS USER ACCESS\")\n",
    "print(\"   Enable no-code ML for business teams\")\n",
    "print()\n",
    "print(\"   • Deploy model (Step 1)\")\n",
    "print(\"   • Model appears in Canvas automatically\")\n",
    "print(\"   • Business users get point-and-click interface\")\n",
    "print(\"   • Governance workflows apply\")\n",
    "print()\n",
    "\n",
    "print(\"\\n📊 STUDIO COLLABORATION WORKFLOW:\")\n",
    "print(\"   1. Data Scientist → Deploys model\")\n",
    "print(\"   2. Studio → Registers in model catalog\")\n",
    "print(\"   3. Team Members → Get shared access\")\n",
    "print(\"   4. Business Users → Access via Canvas\")\n",
    "print(\"   5. Governance → Tracks all usage\")\n",
    "\n",
    "print(\"\\n🎨 CANVAS INTEGRATION BENEFITS:\")\n",
    "print(\"   • No coding required for business users\")\n",
    "print(\"   • Point-and-click predictions\")\n",
    "print(\"   • Built-in data visualization\")\n",
    "print(\"   • Automatic model explanations\")\n",
    "print(\"   • Approval workflows for sensitive models\")\n",
    "\n",
    "print(\"\\n💡 STUDIO VS TRADITIONAL SAGEMAKER:\")\n",
    "print(\"Traditional:\")\n",
    "print(\"   → Deploy endpoint\")\n",
    "print(\"   → Manual sharing\")\n",
    "print(\"   → No business user access\")\n",
    "print(\"   → Limited collaboration\")\n",
    "print()\n",
    "print(\"Studio:\")\n",
    "print(\"   → Deploy with governance\")\n",
    "print(\"   → Automatic team sharing\")\n",
    "print(\"   → Canvas integration\")\n",
    "print(\"   → Rich collaboration features\")\n",
    "\n",
    "print(\"\\n🚀 READY TO DEPLOY IN STUDIO?\")\n",
    "print(\"   Choose Real-time Endpoint for best Studio experience!\")\n",
    "\n",
    "# Helper function for Studio deployment\n",
    "def deploy_to_studio(estimator, endpoint_name_prefix=\"iris-studio\"):\n",
    "    \"\"\"Deploy model with Studio-optimized settings\"\"\"\n",
    "    from datetime import datetime\n",
    "    \n",
    "    endpoint_name = f\"{endpoint_name_prefix}-{datetime.now().strftime('%Y%m%d-%H%M%S')}\"\n",
    "    \n",
    "    try:\n",
    "        predictor = estimator.deploy(\n",
    "            initial_instance_count=1,\n",
    "            instance_type='ml.m5.large',\n",
    "            endpoint_name=endpoint_name,\n",
    "            tags=[\n",
    "                {'Key': 'Environment', 'Value': 'Studio'},\n",
    "                {'Key': 'Deployment', 'Value': 'Collaborative'},\n",
    "                {'Key': 'CanvasEnabled', 'Value': 'true'}\n",
    "            ]\n",
    "        )\n",
    "        \n",
    "        print(f\"✅ Studio deployment successful!\")\n",
    "        print(f\"📍 Endpoint: {endpoint_name}\")\n",
    "        print(f\"🎨 Canvas: Available for business users\")\n",
    "        print(f\"👥 Team Access: Enabled via Studio permissions\")\n",
    "        \n",
    "        return predictor\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"❌ Studio deployment failed: {e}\")\n",
    "        return None\n",
    "\n",
    "print(\"\\n🔧 Helper Function Available:\")\n",
    "print(\"   deploy_to_studio(sklearn_estimator)\")\n",
    "print(\"   → Deploys with Studio-optimized settings\")\n",
    "print(\"   → Enables Canvas integration\")\n",
    "print(\"   → Sets up team collaboration\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37b836aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SageMaker Studio Deployment - Reliable Method\n",
    "\n",
    "print(\"SageMaker Studio Deployment - Most Reliable Method\")\n",
    "print(\"=\" * 60)\n",
    "print(\"This approach uses SageMaker's built-in deployment capabilities\")\n",
    "print(\"No Docker required - No external scripts - Auto-handles inference\")\n",
    "print()\n",
    "\n",
    "# Ensure we have a trained estimator\n",
    "if 'sklearn_estimator' not in locals():\n",
    "    print(\"Setting up SageMaker estimator with completed training job...\")\n",
    "    \n",
    "    from sagemaker.sklearn.estimator import SKLearn\n",
    "    \n",
    "    sklearn_estimator = SKLearn(\n",
    "        entry_point='train.py',\n",
    "        source_dir='src/model',\n",
    "        role=role,\n",
    "        instance_type='ml.m5.large',\n",
    "        framework_version='1.2-1',\n",
    "        py_version='py3',\n",
    "        hyperparameters={\n",
    "            'n_estimators': 100,\n",
    "            'max_depth': 10,\n",
    "            'random_state': 42\n",
    "        },\n",
    "        base_job_name='iris-training'\n",
    "    )\n",
    "    \n",
    "    print(\"Estimator configured\")\n",
    "else:\n",
    "    print(\"SageMaker estimator already available\")\n",
    "\n",
    "# Deploy with automatic retry and fallback\n",
    "print(f\"\\nDEPLOYING MODEL TO SAGEMAKER ENDPOINT...\")\n",
    "print(\"This will take 6-10 minutes...\")\n",
    "\n",
    "deployment_successful = False\n",
    "endpoint_name = f'iris-reliable-{datetime.now().strftime(\"%Y%m%d-%H%M%S\")}'\n",
    "\n",
    "try:\n",
    "    print(f\"Deploying to endpoint: {endpoint_name}\")\n",
    "    print(\"Using ml.m5.large instance...\")\n",
    "    \n",
    "    predictor = sklearn_estimator.deploy(\n",
    "        initial_instance_count=1,\n",
    "        instance_type='ml.m5.large',\n",
    "        endpoint_name=endpoint_name,\n",
    "        wait=True\n",
    "    )\n",
    "    \n",
    "    deployment_successful = True\n",
    "    print(f\"\\nDEPLOYMENT SUCCESSFUL!\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"ml.m5.large deployment failed: {e}\")\n",
    "    print(\"Trying smaller instance type...\")\n",
    "    \n",
    "    try:\n",
    "        endpoint_name_small = f'iris-small-{datetime.now().strftime(\"%Y%m%d-%H%M%S\")}'\n",
    "        print(f\"Deploying to endpoint: {endpoint_name_small}\")\n",
    "        print(\"Using ml.t2.medium instance...\")\n",
    "        \n",
    "        predictor = sklearn_estimator.deploy(\n",
    "            initial_instance_count=1,\n",
    "            instance_type='ml.t2.medium',\n",
    "            endpoint_name=endpoint_name_small,\n",
    "            wait=True\n",
    "        )\n",
    "        \n",
    "        deployment_successful = True\n",
    "        endpoint_name = endpoint_name_small\n",
    "        print(f\"\\nDEPLOYMENT SUCCESSFUL WITH SMALLER INSTANCE!\")\n",
    "        \n",
    "    except Exception as e2:\n",
    "        print(f\"Both deployments failed:\")\n",
    "        print(f\"ml.m5.large: {e}\")\n",
    "        print(f\"ml.t2.medium: {e2}\")\n",
    "        deployment_successful = False\n",
    "\n",
    "# Test the deployed model\n",
    "if deployment_successful:\n",
    "    print(f\"\\nModel deployed successfully!\")\n",
    "    print(f\"Endpoint name: {predictor.endpoint_name}\")\n",
    "    \n",
    "    # Test the endpoint\n",
    "    print(f\"\\nTESTING THE ENDPOINT...\")\n",
    "    try:\n",
    "        test_data = [[5.1, 3.5, 1.4, 0.2]]  # Sample iris data\n",
    "        prediction = predictor.predict(test_data)\n",
    "        print(f\"Test prediction successful: {prediction}\")\n",
    "        \n",
    "        # Test with multiple samples\n",
    "        test_samples = [\n",
    "            [5.1, 3.5, 1.4, 0.2],  # Should be setosa\n",
    "            [7.0, 3.2, 4.7, 1.4],  # Should be versicolor\n",
    "            [6.3, 3.3, 6.0, 2.5]   # Should be virginica\n",
    "        ]\n",
    "        \n",
    "        predictions = predictor.predict(test_samples)\n",
    "        print(f\"Batch predictions: {predictions}\")\n",
    "        \n",
    "        print(f\"\\nENDPOINT IS WORKING PERFECTLY!\")\n",
    "        \n",
    "        # Save endpoint reference\n",
    "        globals()['working_predictor'] = predictor\n",
    "        globals()['working_endpoint_name'] = predictor.endpoint_name\n",
    "        \n",
    "        print(f\"\\nHOW TO USE YOUR ENDPOINT:\")\n",
    "        print(f\"Endpoint name: {predictor.endpoint_name}\")\n",
    "        print(f\"Usage: working_predictor.predict([[5.1, 3.5, 1.4, 0.2]])\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Endpoint test failed: {e}\")\n",
    "        print(\"Check CloudWatch logs for details\")\n",
    "\n",
    "else:\n",
    "    print(f\"\\nDEPLOYMENT FAILED\")\n",
    "    print(f\"Troubleshooting steps:\")\n",
    "    print(f\"1. Check CloudWatch logs\")\n",
    "    print(f\"2. Verify training job completed successfully\")\n",
    "    print(f\"3. Check SageMaker quotas in your account\")\n",
    "    print(f\"4. Try different region if current one is constrained\")\n",
    "\n",
    "print(f\"\\nTO CLEAN UP WHEN DONE:\")\n",
    "print(f\"# working_predictor.delete_endpoint()  # Removes endpoint and stops billing\")\n",
    "\n",
    "print(f\"\\nTHIS IS THE EASIEST AND MOST RELIABLE DEPLOYMENT METHOD!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77bf7c45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 🔧 ENDPOINT TROUBLESHOOTING & DIAGNOSTICS\n",
    "\n",
    "print(\"🔧 SageMaker Endpoint Troubleshooting\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "import boto3\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "def diagnose_endpoint_issues():\n",
    "    \"\"\"Comprehensive endpoint diagnostics\"\"\"\n",
    "    \n",
    "    sagemaker_client = boto3.client('sagemaker')\n",
    "    logs_client = boto3.client('logs')\n",
    "    \n",
    "    print(\"🔍 CHECKING RECENT ENDPOINTS...\")\n",
    "    \n",
    "    try:\n",
    "        # Get recent endpoints\n",
    "        endpoints = sagemaker_client.list_endpoints(\n",
    "            SortBy='CreationTime',\n",
    "            SortOrder='Descending',\n",
    "            MaxResults=5\n",
    "        )\n",
    "        \n",
    "        for endpoint in endpoints['Endpoints']:\n",
    "            name = endpoint['EndpointName']\n",
    "            status = endpoint['EndpointStatus']\n",
    "            created = endpoint['CreationTime']\n",
    "            \n",
    "            # Calculate time elapsed\n",
    "            now = datetime.now(created.tzinfo)\n",
    "            elapsed = now - created\n",
    "            elapsed_minutes = int(elapsed.total_seconds() / 60)\n",
    "            \n",
    "            print(f\"\\n📍 {name}\")\n",
    "            print(f\"   Status: {status}\")\n",
    "            print(f\"   Created: {elapsed_minutes} minutes ago\")\n",
    "            \n",
    "            # Get detailed info for failed endpoints\n",
    "            if status in ['Failed', 'OutOfService']:\n",
    "                try:\n",
    "                    details = sagemaker_client.describe_endpoint(EndpointName=name)\n",
    "                    if 'FailureReason' in details:\n",
    "                        print(f\"   ❌ Failure: {details['FailureReason']}\")\n",
    "                        \n",
    "                        # Common failure patterns and solutions\n",
    "                        failure_reason = details['FailureReason'].lower()\n",
    "                        if 'ping health check' in failure_reason:\n",
    "                            print(f\"   💡 Solution: Model container not responding - check inference.py\")\n",
    "                        elif 'model loading' in failure_reason:\n",
    "                            print(f\"   💡 Solution: Model format issue - check model artifacts\")\n",
    "                        elif 'insufficient capacity' in failure_reason:\n",
    "                            print(f\"   💡 Solution: Try different instance type or region\")\n",
    "                        elif 'image' in failure_reason:\n",
    "                            print(f\"   💡 Solution: Framework version compatibility issue\")\n",
    "                            \n",
    "                except Exception as e:\n",
    "                    print(f\"   ⚠️ Could not get details: {e}\")\n",
    "            \n",
    "            elif status == 'Creating' and elapsed_minutes > 15:\n",
    "                print(f\"   ⚠️ Taking longer than expected - may fail soon\")\n",
    "            \n",
    "            elif status == 'InService':\n",
    "                print(f\"   ✅ Healthy and ready!\")\n",
    "                \n",
    "        print(f\"\\n🔍 CHECKING CLOUDWATCH LOGS...\")\n",
    "        \n",
    "        # Check for recent SageMaker endpoint logs\n",
    "        try:\n",
    "            log_groups = logs_client.describe_log_groups(\n",
    "                logGroupNamePrefix='/aws/sagemaker/Endpoints',\n",
    "                limit=5\n",
    "            )\n",
    "            \n",
    "            for lg in log_groups['logGroups']:\n",
    "                log_group_name = lg['logGroupName']\n",
    "                print(f\"\\n📄 Log group: {log_group_name}\")\n",
    "                \n",
    "                # Get most recent log streams\n",
    "                streams = logs_client.describe_log_streams(\n",
    "                    logGroupName=log_group_name,\n",
    "                    orderBy='LastEventTime',\n",
    "                    descending=True,\n",
    "                    limit=2\n",
    "                )\n",
    "                \n",
    "                for stream in streams['logStreams']:\n",
    "                    print(f\"   📊 Stream: {stream['logStreamName']}\")\n",
    "                    \n",
    "                    # Get recent error events\n",
    "                    try:\n",
    "                        events = logs_client.get_log_events(\n",
    "                            logGroupName=log_group_name,\n",
    "                            logStreamName=stream['logStreamName'],\n",
    "                            startTime=int((datetime.now() - timedelta(hours=2)).timestamp() * 1000)\n",
    "                        )\n",
    "                        \n",
    "                        error_events = [e for e in events['events'] \n",
    "                                      if any(keyword in e['message'].lower() \n",
    "                                           for keyword in ['error', 'failed', 'exception', 'traceback'])]\n",
    "                        \n",
    "                        if error_events:\n",
    "                            print(f\"   🚨 Recent errors found:\")\n",
    "                            for event in error_events[-3:]:  # Last 3 errors\n",
    "                                timestamp = datetime.fromtimestamp(event['timestamp'] / 1000)\n",
    "                                print(f\"      [{timestamp.strftime('%H:%M:%S')}] {event['message'][:100]}...\")\n",
    "                        else:\n",
    "                            print(f\"   ✅ No recent errors in this stream\")\n",
    "                            \n",
    "                    except Exception as e:\n",
    "                        print(f\"   ⚠️ Could not read events: {e}\")\n",
    "                        \n",
    "        except Exception as e:\n",
    "            print(f\"❌ Error checking CloudWatch logs: {e}\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error checking endpoints: {e}\")\n",
    "\n",
    "def fix_common_issues():\n",
    "    \"\"\"Provide fixes for common endpoint issues\"\"\"\n",
    "    \n",
    "    print(f\"\\n🛠️ COMMON FIXES:\")\n",
    "    print(f\"1. 🏥 Health Check Failures:\")\n",
    "    print(f\"   - Ensure inference.py has proper model_fn, input_fn, predict_fn\")\n",
    "    print(f\"   - Check that model loads correctly\")\n",
    "    print(f\"   - Verify requirements.txt has correct versions\")\n",
    "    \n",
    "    print(f\"\\n2. 🔧 Model Loading Issues:\")\n",
    "    print(f\"   - Check model.tar.gz format and contents\")\n",
    "    print(f\"   - Ensure model was saved with correct sklearn version\")\n",
    "    print(f\"   - Verify S3 permissions\")\n",
    "    \n",
    "    print(f\"\\n3. 💾 Instance Issues:\")\n",
    "    print(f\"   - Try smaller instance type (ml.t2.medium)\")\n",
    "    print(f\"   - Check service quotas in AWS Console\")\n",
    "    print(f\"   - Try different region\")\n",
    "    \n",
    "    print(f\"\\n4. 🐳 Container Issues:\")\n",
    "    print(f\"   - Use framework_version='1.2-1' (tested)\")\n",
    "    print(f\"   - Avoid very old or very new framework versions\")\n",
    "    print(f\"   - Check SageMaker container compatibility\")\n",
    "\n",
    "# Run diagnostics\n",
    "print(\"🔍 Running endpoint diagnostics...\")\n",
    "diagnose_endpoint_issues()\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "fix_common_issues()\n",
    "\n",
    "print(f\"\\n💡 BEST PRACTICE:\")\n",
    "print(f\"Always use sklearn_estimator.deploy() - it's the most reliable method!\")\n",
    "print(f\"Avoid custom containers unless absolutely necessary.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20c7ce83",
   "metadata": {},
   "source": [
    "## 🔧 Endpoint Deployment Troubleshooting & Recovery\n",
    "\n",
    "If you encountered the error: **\"The primary container for production variant primary did not pass the ping health check\"**, this section will help you diagnose and fix the issue.\n",
    "\n",
    "### 🔍 **Common Causes:**\n",
    "- ❌ Missing or incorrect inference script\n",
    "- ❌ Model loading issues \n",
    "- ❌ Container configuration problems\n",
    "- ❌ Framework version mismatches\n",
    "\n",
    "### 📋 **Recovery Steps:**\n",
    "1. **Diagnose** - Check CloudWatch logs\n",
    "2. **Fix** - Create proper inference script\n",
    "3. **Cleanup** - Remove failed resources\n",
    "4. **Redeploy** - Use reliable method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44d12c02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 🔍 STEP 1: Diagnose the Issue - Check CloudWatch Logs\n",
    "\n",
    "print(\"🔍 DIAGNOSING ENDPOINT FAILURE...\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "import boto3\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "def check_endpoint_logs():\n",
    "    \"\"\"Check CloudWatch logs for endpoint failure details\"\"\"\n",
    "    logs_client = boto3.client('logs')\n",
    "    \n",
    "    # Replace with your failed endpoint name\n",
    "    failed_endpoint_name = 'iris-endpoint-20250822-235036'  # Update this!\n",
    "    \n",
    "    print(f\"📋 Checking logs for endpoint: {failed_endpoint_name}\")\n",
    "    \n",
    "    try:\n",
    "        # List log groups related to SageMaker endpoints\n",
    "        log_groups = logs_client.describe_log_groups(\n",
    "            logGroupNamePrefix='/aws/sagemaker/Endpoints'\n",
    "        )\n",
    "        \n",
    "        print(\"📄 Available SageMaker endpoint log groups:\")\n",
    "        endpoint_log_found = False\n",
    "        \n",
    "        for lg in log_groups['logGroups']:\n",
    "            log_group_name = lg['logGroupName']\n",
    "            print(f\"  📁 {log_group_name}\")\n",
    "            \n",
    "            # Check if this log group is for our failed endpoint\n",
    "            if failed_endpoint_name in log_group_name:\n",
    "                endpoint_log_found = True\n",
    "                print(f\"\\n🎯 FOUND LOGS FOR FAILED ENDPOINT!\")\n",
    "                print(f\"📂 Log Group: {log_group_name}\")\n",
    "                \n",
    "                # Get recent log streams\n",
    "                try:\n",
    "                    streams = logs_client.describe_log_streams(\n",
    "                        logGroupName=log_group_name,\n",
    "                        orderBy='LastEventTime',\n",
    "                        descending=True,\n",
    "                        limit=3\n",
    "                    )\n",
    "                    \n",
    "                    for stream in streams['logStreams']:\n",
    "                        stream_name = stream['logStreamName']\n",
    "                        print(f\"\\n📊 Log Stream: {stream_name}\")\n",
    "                        \n",
    "                        # Get recent log events\n",
    "                        events = logs_client.get_log_events(\n",
    "                            logGroupName=log_group_name,\n",
    "                            logStreamName=stream_name,\n",
    "                            startTime=int((datetime.now() - timedelta(hours=2)).timestamp() * 1000)\n",
    "                        )\n",
    "                        \n",
    "                        print(\"🔍 ERROR MESSAGES:\")\n",
    "                        error_count = 0\n",
    "                        for event in events['events']:\n",
    "                            message = event['message'].strip()\n",
    "                            timestamp = datetime.fromtimestamp(event['timestamp'] / 1000)\n",
    "                            \n",
    "                            # Look for error indicators\n",
    "                            if any(keyword in message.lower() for keyword in ['error', 'failed', 'exception', 'traceback']):\n",
    "                                print(f\"  ❌ [{timestamp}] {message}\")\n",
    "                                error_count += 1\n",
    "                            elif 'ping' in message.lower():\n",
    "                                print(f\"  🏓 [{timestamp}] {message}\")\n",
    "                        \n",
    "                        if error_count == 0:\n",
    "                            print(\"  ℹ️  No explicit errors found in this stream\")\n",
    "                            print(\"  📋 Last 5 messages:\")\n",
    "                            for event in events['events'][-5:]:\n",
    "                                timestamp = datetime.fromtimestamp(event['timestamp'] / 1000)\n",
    "                                print(f\"    [{timestamp}] {event['message'].strip()}\")\n",
    "                        \n",
    "                except Exception as e:\n",
    "                    print(f\"  ⚠️ Could not read log streams: {e}\")\n",
    "        \n",
    "        if not endpoint_log_found:\n",
    "            print(f\"\\n⚠️ No logs found for endpoint: {failed_endpoint_name}\")\n",
    "            print(\"💡 This might mean:\")\n",
    "            print(\"   • The endpoint name is incorrect\")\n",
    "            print(\"   • The logs haven't been generated yet\")\n",
    "            print(\"   • The endpoint failed before logging started\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error accessing CloudWatch logs: {e}\")\n",
    "        print(\"💡 Make sure you have CloudWatch read permissions\")\n",
    "\n",
    "# Run the diagnostic\n",
    "check_endpoint_logs()\n",
    "\n",
    "print(\"\\n💡 COMMON ISSUES AND SOLUTIONS:\")\n",
    "print(\"🔧 If you see 'ModuleNotFoundError': Missing dependencies\")\n",
    "print(\"🔧 If you see 'No module named inference': Missing inference.py\")\n",
    "print(\"🔧 If you see 'model loading failed': Wrong model format\")\n",
    "print(\"🔧 If no logs found: Endpoint failed during startup\")\n",
    "\n",
    "print(\"\\n➡️ NEXT: Run the cells below to fix the issues\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07b0eb39",
   "metadata": {},
   "source": [
    "## 🛠️ Studio MLOps Workflows\n",
    "\n",
    "Now that your model is ready, let's explore how to use SageMaker Unified Studio's collaborative MLOps features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "660c4b0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explore Studio MLOps Features\n",
    "print(\"🔍 SageMaker Unified Studio MLOps Capabilities:\")\n",
    "print()\n",
    "\n",
    "studio_features = {\n",
    "    'Model Registry': {\n",
    "        'purpose': 'Centralized model catalog with versioning',\n",
    "        'usage': 'Automatic registration when deploying models',\n",
    "        'benefits': 'Team sharing, model lineage, approval workflows'\n",
    "    },\n",
    "    'Data Catalog': {\n",
    "        'purpose': 'Discover and govern data assets',\n",
    "        'usage': 'AI-powered data discovery with Amazon Q',\n",
    "        'benefits': 'Data lineage, quality scores, business glossary'\n",
    "    },\n",
    "    'Canvas Integration': {\n",
    "        'purpose': 'No-code ML for business users',\n",
    "        'usage': 'Point-and-click access to deployed models',\n",
    "        'benefits': 'Business user empowerment, governance workflows'\n",
    "    },\n",
    "    'Collaborative Notebooks': {\n",
    "        'purpose': 'Team development and sharing',\n",
    "        'usage': 'Real-time collaboration on ML experiments',\n",
    "        'benefits': 'Knowledge sharing, version control, reproducibility'\n",
    "    },\n",
    "    'Project Management': {\n",
    "        'purpose': 'Organize ML work by business projects',\n",
    "        'usage': 'Group related assets and team members',\n",
    "        'benefits': 'Better organization, access control, tracking'\n",
    "    }\n",
    "}\n",
    "\n",
    "for feature, info in studio_features.items():\n",
    "    print(f\"✅ {feature}\")\n",
    "    print(f\"   📝 Purpose: {info['purpose']}\")\n",
    "    print(f\"   🎯 Usage: {info['usage']}\")\n",
    "    print(f\"   💡 Benefits: {info['benefits']}\")\n",
    "    print()\n",
    "\n",
    "# Check Studio environment capabilities\n",
    "print(\"🔧 Studio Environment Check:\")\n",
    "\n",
    "try:\n",
    "    import sagemaker\n",
    "    from sagemaker.model_registry import ModelPackageGroup\n",
    "    \n",
    "    # Check Model Registry access\n",
    "    sm_session = sagemaker.Session()\n",
    "    try:\n",
    "        # Try to list model package groups (Studio feature)\n",
    "        model_packages = sm_session.list_model_packages(max_results=1)\n",
    "        print(\"✅ Model Registry: Accessible\")\n",
    "    except:\n",
    "        print(\"⚠️ Model Registry: Limited access\")\n",
    "    \n",
    "    # Check for Studio-specific features\n",
    "    print(\"✅ Real-time Endpoints: Available\")\n",
    "    print(\"✅ Batch Transform: Available\") \n",
    "    print(\"✅ Model Monitoring: Available\")\n",
    "    print(\"✅ Canvas Integration: Automatic\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"⚠️ Error checking Studio features: {e}\")\n",
    "\n",
    "print(f\"\\n🚀 Studio MLOps Workflow:\")\n",
    "print(\"1. 📊 Explore data using Data Catalog\")\n",
    "print(\"2. 🧪 Experiment in collaborative notebooks\")\n",
    "print(\"3. 🏗️ Train models with automatic versioning\")\n",
    "print(\"4. 🚀 Deploy with built-in governance\")\n",
    "print(\"5. 🎨 Share with business users via Canvas\")\n",
    "print(\"6. 📈 Monitor performance and drift\")\n",
    "print(\"7. 🔄 Iterate with team collaboration\")\n",
    "\n",
    "print(f\"\\n📋 Studio Project Organization:\")\n",
    "print(\"• Create projects for different business use cases\")\n",
    "print(\"• Invite team members with appropriate permissions\")\n",
    "print(\"• Organize datasets, models, and experiments\")\n",
    "print(\"• Set up approval workflows for sensitive models\")\n",
    "\n",
    "print(f\"\\n💡 Studio Advantages:\")\n",
    "print(\"• No external scripts needed - everything integrated\")\n",
    "print(\"• Automatic governance and compliance\")\n",
    "print(\"• Business user access without technical complexity\")\n",
    "print(\"• AI-powered assistance with Amazon Q\")\n",
    "print(\"• Rich collaboration features\")\n",
    "\n",
    "# Example Studio workflow\n",
    "print(f\"\\n🎯 Example Studio Deployment Workflow:\")\n",
    "print(\"\"\"\n",
    "# 1. Deploy model with Studio integration\n",
    "predictor = sklearn_estimator.deploy(\n",
    "    initial_instance_count=1,\n",
    "    instance_type='ml.m5.large',\n",
    "    endpoint_name='iris-studio-model'\n",
    ")\n",
    "\n",
    "# 2. Model automatically appears in:\n",
    "#    - Model Registry (with version tracking)\n",
    "#    - Canvas (for business users)\n",
    "#    - Team shared assets\n",
    "#    - Data catalog (with lineage)\n",
    "\n",
    "# 3. Test and collaborate\n",
    "prediction = predictor.predict([[5.1, 3.5, 1.4, 0.2]])\n",
    "# Share results with team via Studio\n",
    "\n",
    "# 4. Business users can now:\n",
    "#    - Access model via Canvas\n",
    "#    - Make predictions without coding\n",
    "#    - Follow governance workflows\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f301247",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 🚀 DEPLOY MODEL TO SAGEMAKER ENDPOINT - ROBUST VERSION\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"🚀 DEPLOYING MODEL TO SAGEMAKER ENDPOINT\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "import time\n",
    "import boto3\n",
    "from datetime import datetime\n",
    "\n",
    "# Configuration with fallback options\n",
    "ENDPOINT_NAME = f\"iris-model-demo-{int(time.time())}\"\n",
    "INSTANCE_TYPES = ['ml.m5.large', 'ml.m5.xlarge', 'ml.c5.large', 'ml.t3.medium']  # Fallback options\n",
    "DEPLOYMENT_TIMEOUT = 600  # 10 minutes max\n",
    "\n",
    "def deploy_with_fallback(estimator, endpoint_name, instance_types):\n",
    "    \"\"\"Deploy model with instance type fallback for reliability\"\"\"\n",
    "    \n",
    "    for i, instance_type in enumerate(instance_types):\n",
    "        try:\n",
    "            print(f\"\\n🔄 Attempting deployment with {instance_type} (attempt {i+1}/{len(instance_types)})\")\n",
    "            \n",
    "            # Try to deploy\n",
    "            predictor = estimator.deploy(\n",
    "                initial_instance_count=1,\n",
    "                instance_type=instance_type,\n",
    "                endpoint_name=endpoint_name,\n",
    "                wait=True,\n",
    "                update_endpoint=False\n",
    "            )\n",
    "            \n",
    "            print(f\"✅ Successfully deployed on {instance_type}\")\n",
    "            return predictor, instance_type\n",
    "            \n",
    "        except Exception as e:\n",
    "            error_msg = str(e)\n",
    "            print(f\"❌ Failed with {instance_type}: {error_msg}\")\n",
    "            \n",
    "            # Clean up failed endpoint if it exists\n",
    "            try:\n",
    "                sagemaker_client = boto3.client('sagemaker')\n",
    "                sagemaker_client.delete_endpoint(EndpointName=endpoint_name)\n",
    "                print(f\"🧹 Cleaned up failed endpoint: {endpoint_name}\")\n",
    "                time.sleep(30)  # Wait for cleanup\n",
    "            except:\n",
    "                pass\n",
    "            \n",
    "            # Check if we should retry with next instance type\n",
    "            if i < len(instance_types) - 1:\n",
    "                print(f\"🔄 Retrying with next instance type...\")\n",
    "                time.sleep(10)\n",
    "            else:\n",
    "                print(f\"💥 All instance types failed. Last error: {error_msg}\")\n",
    "                raise Exception(f\"Deployment failed on all instance types: {error_msg}\")\n",
    "\n",
    "# Deploy the model\n",
    "try:\n",
    "    start_time = datetime.now()\n",
    "    print(f\"📅 Deployment started at: {start_time}\")\n",
    "    \n",
    "    predictor, used_instance_type = deploy_with_fallback(\n",
    "        sklearn_estimator, \n",
    "        ENDPOINT_NAME, \n",
    "        INSTANCE_TYPES\n",
    "    )\n",
    "    \n",
    "    end_time = datetime.now()\n",
    "    duration = (end_time - start_time).total_seconds()\n",
    "    \n",
    "    print(f\"\\n🎉 DEPLOYMENT SUCCESSFUL!\")\n",
    "    print(f\"📊 Endpoint Name: {ENDPOINT_NAME}\")\n",
    "    print(f\"💻 Instance Type: {used_instance_type}\")\n",
    "    print(f\"⏱️  Deployment Time: {duration:.1f} seconds\")\n",
    "    print(f\"🌐 Endpoint URL: https://console.aws.amazon.com/sagemaker/home#/endpoints/{ENDPOINT_NAME}\")\n",
    "    \n",
    "    # Test the endpoint immediately\n",
    "    print(f\"\\n🧪 TESTING ENDPOINT...\")\n",
    "    test_data = [[5.1, 3.5, 1.4, 0.2], [6.7, 3.1, 4.4, 1.4]]\n",
    "    \n",
    "    prediction = predictor.predict(test_data)\n",
    "    print(f\"✅ Test Prediction: {prediction}\")\n",
    "    print(f\"📈 Model is responding correctly!\")\n",
    "    \n",
    "    # Store endpoint info for later use\n",
    "    endpoint_info = {\n",
    "        'endpoint_name': ENDPOINT_NAME,\n",
    "        'instance_type': used_instance_type,\n",
    "        'deployment_time': duration,\n",
    "        'test_prediction': prediction\n",
    "    }\n",
    "    \n",
    "    print(f\"\\n📝 Endpoint deployed and tested successfully!\")\n",
    "    print(f\"💡 Use 'predictor.delete_endpoint()' to clean up when done\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"\\n💥 DEPLOYMENT FAILED!\")\n",
    "    print(f\"❌ Error: {str(e)}\")\n",
    "    print(f\"\\n🔧 Troubleshooting suggestions:\")\n",
    "    print(f\"   1. Check your AWS account limits for SageMaker instances\")\n",
    "    print(f\"   2. Verify the model was trained successfully\")\n",
    "    print(f\"   3. Check CloudWatch logs for detailed error messages\")\n",
    "    print(f\"   4. Try running the troubleshooting cell below\")\n",
    "    \n",
    "    # Re-raise for debugging\n",
    "    raise e"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98a48df0",
   "metadata": {},
   "source": [
    "## 8. Test Model Predictions\n",
    "\n",
    "Demonstrate how to test your deployed model using the same patterns as `scripts/test_endpoint.py`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f12fc0d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 🔧 ENDPOINT TROUBLESHOOTING & DIAGNOSTICS\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"🔧 SAGEMAKER ENDPOINT TROUBLESHOOTING & DIAGNOSTICS\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "import boto3\n",
    "import json\n",
    "import time\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "def comprehensive_endpoint_diagnostics(endpoint_name=None):\n",
    "    \"\"\"Comprehensive diagnostics for SageMaker endpoint issues\"\"\"\n",
    "    \n",
    "    sagemaker = boto3.client('sagemaker')\n",
    "    logs_client = boto3.client('logs')\n",
    "    \n",
    "    print(f\"🔍 Running comprehensive diagnostics...\")\n",
    "    \n",
    "    # 1. List all endpoints if none specified\n",
    "    if not endpoint_name:\n",
    "        print(f\"\\n📋 LISTING ALL ENDPOINTS:\")\n",
    "        try:\n",
    "            response = sagemaker.list_endpoints()\n",
    "            endpoints = response['Endpoints']\n",
    "            \n",
    "            if not endpoints:\n",
    "                print(\"❌ No endpoints found. Deploy a model first.\")\n",
    "                return\n",
    "            \n",
    "            for ep in endpoints:\n",
    "                status_icon = \"✅\" if ep['EndpointStatus'] == 'InService' else \"❌\"\n",
    "                print(f\"   {status_icon} {ep['EndpointName']}: {ep['EndpointStatus']}\")\n",
    "            \n",
    "            # Use the most recent endpoint\n",
    "            endpoint_name = endpoints[-1]['EndpointName']\n",
    "            print(f\"\\n🎯 Using most recent endpoint: {endpoint_name}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"❌ Error listing endpoints: {e}\")\n",
    "            return\n",
    "    \n",
    "    # 2. Check endpoint status\n",
    "    print(f\"\\n📊 ENDPOINT STATUS CHECK:\")\n",
    "    try:\n",
    "        response = sagemaker.describe_endpoint(EndpointName=endpoint_name)\n",
    "        status = response['EndpointStatus']\n",
    "        creation_time = response['CreationTime']\n",
    "        \n",
    "        status_icon = \"✅\" if status == 'InService' else \"❌\"\n",
    "        print(f\"   {status_icon} Status: {status}\")\n",
    "        print(f\"   📅 Created: {creation_time}\")\n",
    "        \n",
    "        if status == 'Failed':\n",
    "            print(f\"   💥 Failure Reason: {response.get('FailureReason', 'Unknown')}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error checking endpoint status: {e}\")\n",
    "        return endpoint_name\n",
    "    \n",
    "    # 3. Check endpoint configuration\n",
    "    print(f\"\\n⚙️  ENDPOINT CONFIGURATION:\")\n",
    "    try:\n",
    "        config_name = response['EndpointConfigName']\n",
    "        config_response = sagemaker.describe_endpoint_config(EndpointConfigName=config_name)\n",
    "        \n",
    "        for variant in config_response['ProductionVariants']:\n",
    "            print(f\"   🖥️  Instance Type: {variant['InstanceType']}\")\n",
    "            print(f\"   📊 Instance Count: {variant['InitialInstanceCount']}\")\n",
    "            print(f\"   🏷️  Variant Name: {variant['VariantName']}\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error checking endpoint config: {e}\")\n",
    "    \n",
    "    # 4. Check CloudWatch logs\n",
    "    print(f\"\\n📋 CLOUDWATCH LOGS (Last 30 minutes):\")\n",
    "    try:\n",
    "        log_group = f\"/aws/sagemaker/Endpoints/{endpoint_name}\"\n",
    "        end_time = datetime.now()\n",
    "        start_time = end_time - timedelta(minutes=30)\n",
    "        \n",
    "        # Get log streams\n",
    "        streams_response = logs_client.describe_log_streams(\n",
    "            logGroupName=log_group,\n",
    "            orderBy='LastEventTime',\n",
    "            descending=True,\n",
    "            limit=5\n",
    "        )\n",
    "        \n",
    "        if streams_response['logStreams']:\n",
    "            print(f\"   📝 Found {len(streams_response['logStreams'])} log streams\")\n",
    "            \n",
    "            # Get recent log events\n",
    "            stream_name = streams_response['logStreams'][0]['logStreamName']\n",
    "            events_response = logs_client.get_log_events(\n",
    "                logGroupName=log_group,\n",
    "                logStreamName=stream_name,\n",
    "                startTime=int(start_time.timestamp() * 1000),\n",
    "                endTime=int(end_time.timestamp() * 1000),\n",
    "                limit=20\n",
    "            )\n",
    "            \n",
    "            events = events_response['events']\n",
    "            if events:\n",
    "                print(f\"   📄 Recent log events:\")\n",
    "                for event in events[-10:]:  # Show last 10 events\n",
    "                    timestamp = datetime.fromtimestamp(event['timestamp'] / 1000)\n",
    "                    message = event['message'].strip()\n",
    "                    print(f\"   {timestamp.strftime('%H:%M:%S')} | {message}\")\n",
    "            else:\n",
    "                print(f\"   ℹ️  No recent log events found\")\n",
    "        else:\n",
    "            print(f\"   ℹ️  No log streams found yet\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"   ⚠️  CloudWatch logs not accessible: {e}\")\n",
    "    \n",
    "    # 5. Test endpoint if InService\n",
    "    if status == 'InService':\n",
    "        print(f\"\\n🧪 ENDPOINT CONNECTIVITY TEST:\")\n",
    "        try:\n",
    "            runtime = boto3.client('sagemaker-runtime')\n",
    "            test_data = [[5.1, 3.5, 1.4, 0.2]]\n",
    "            \n",
    "            response = runtime.invoke_endpoint(\n",
    "                EndpointName=endpoint_name,\n",
    "                ContentType='application/json',\n",
    "                Body=json.dumps(test_data)\n",
    "            )\n",
    "            \n",
    "            result = json.loads(response['Body'].read().decode())\n",
    "            print(f\"   ✅ Test successful! Prediction: {result}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"   ❌ Test failed: {e}\")\n",
    "    \n",
    "    # 6. Provide actionable recommendations\n",
    "    print(f\"\\n💡 TROUBLESHOOTING RECOMMENDATIONS:\")\n",
    "    \n",
    "    if status == 'Failed':\n",
    "        print(f\"   🔧 ENDPOINT FAILED - Try these fixes:\")\n",
    "        print(f\"      1. Check the model artifacts exist and are accessible\")\n",
    "        print(f\"      2. Verify the inference script has proper /ping and /invocations handlers\")\n",
    "        print(f\"      3. Ensure model dependencies are correctly specified\")\n",
    "        print(f\"      4. Try a different instance type (ml.t3.medium for testing)\")\n",
    "        print(f\"      5. Check AWS account limits and quotas\")\n",
    "        \n",
    "    elif status == 'Creating':\n",
    "        print(f\"   ⏳ ENDPOINT CREATING - This is normal:\")\n",
    "        print(f\"      • Typical deployment takes 6-10 minutes\")\n",
    "        print(f\"      • Check again in a few minutes\")\n",
    "        print(f\"      • Monitor CloudWatch logs for progress\")\n",
    "        \n",
    "    elif status == 'InService':\n",
    "        print(f\"   ✅ ENDPOINT HEALTHY - All good!\")\n",
    "        print(f\"      • You can make predictions\")\n",
    "        print(f\"      • Remember to delete when done to save costs\")\n",
    "        \n",
    "    else:\n",
    "        print(f\"   ⚠️  UNKNOWN STATUS - General troubleshooting:\")\n",
    "        print(f\"      1. Wait a few minutes and check again\")\n",
    "        print(f\"      2. Check AWS Service Health Dashboard\")\n",
    "        print(f\"      3. Verify your AWS credentials and region\")\n",
    "    \n",
    "    print(f\"\\n🔄 Run this cell again to refresh diagnostics\")\n",
    "    return endpoint_name\n",
    "\n",
    "# Run diagnostics\n",
    "try:\n",
    "    # Try to use the endpoint from previous deployment\n",
    "    endpoint_name = locals().get('ENDPOINT_NAME') or globals().get('endpoint_info', {}).get('endpoint_name')\n",
    "    result_endpoint = comprehensive_endpoint_diagnostics(endpoint_name)\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"💥 Diagnostics failed: {e}\")\n",
    "    print(f\"💡 This might be normal if no endpoints exist yet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bffbade",
   "metadata": {},
   "source": [
    "## 9. Monitor Model Performance\n",
    "\n",
    "Set up monitoring to track model performance and data drift over time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd50b7f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleanup & Cost Management\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"CLEANUP & COST MANAGEMENT\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "import boto3\n",
    "from datetime import datetime\n",
    "\n",
    "def comprehensive_cleanup():\n",
    "    \"\"\"Clean up all SageMaker resources to prevent unnecessary costs\"\"\"\n",
    "    \n",
    "    sagemaker = boto3.client('sagemaker')\n",
    "    \n",
    "    print(f\"Scanning for SageMaker resources to clean up...\")\n",
    "    \n",
    "    # List endpoints\n",
    "    print(f\"\\nENDPOINTS:\")\n",
    "    try:\n",
    "        response = sagemaker.list_endpoints()\n",
    "        endpoints = response['Endpoints']\n",
    "        \n",
    "        if not endpoints:\n",
    "            print(\"   No endpoints found\")\n",
    "        else:\n",
    "            for ep in endpoints:\n",
    "                status_icon = \"ACTIVE\" if ep['EndpointStatus'] == 'InService' else \"INACTIVE\"\n",
    "                cost_per_hour = get_estimated_cost(ep.get('InstanceType', 'ml.m5.large'))\n",
    "                print(f\"   {status_icon} {ep['EndpointName']}: {ep['EndpointStatus']} (~${cost_per_hour:.2f}/hour)\")\n",
    "        \n",
    "        if endpoints:\n",
    "            print(f\"\\nEstimated monthly cost if left running: ${len(endpoints) * 24 * 30 * 0.115:.2f}\")\n",
    "            print(f\"Delete endpoints to stop charges!\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Error listing endpoints: {e}\")\n",
    "    \n",
    "    # List training jobs\n",
    "    print(f\"\\nRECENT TRAINING JOBS:\")\n",
    "    try:\n",
    "        response = sagemaker.list_training_jobs(\n",
    "            MaxResults=10,\n",
    "            SortBy='CreationTime',\n",
    "            SortOrder='Descending'\n",
    "        )\n",
    "        \n",
    "        jobs = response['TrainingJobSummaries']\n",
    "        if not jobs:\n",
    "            print(\"   No recent training jobs\")\n",
    "        else:\n",
    "            for job in jobs[:5]:\n",
    "                status_icon = \"COMPLETED\" if job['TrainingJobStatus'] == 'Completed' else \"FAILED\"\n",
    "                print(f\"   {status_icon} {job['TrainingJobName']}: {job['TrainingJobStatus']}\")\n",
    "                \n",
    "    except Exception as e:\n",
    "        print(f\"Error listing training jobs: {e}\")\n",
    "    \n",
    "    # List models\n",
    "    print(f\"\\nMODELS:\")\n",
    "    try:\n",
    "        response = sagemaker.list_models(MaxResults=10)\n",
    "        models = response['Models']\n",
    "        \n",
    "        if not models:\n",
    "            print(\"   No models found\")\n",
    "        else:\n",
    "            for model in models:\n",
    "                print(f\"   {model['ModelName']}: {model['CreationTime']}\")\n",
    "                \n",
    "    except Exception as e:\n",
    "        print(f\"Error listing models: {e}\")\n",
    "    \n",
    "    # Cleanup options\n",
    "    print(f\"\\nCLEANUP OPTIONS:\")\n",
    "    print(f\"1. Delete specific endpoint: predictor.delete_endpoint()\")\n",
    "    print(f\"2. Delete all endpoints: Use the functions below\")\n",
    "    print(f\"3. Models and training jobs don't incur ongoing costs\")\n",
    "\n",
    "def get_estimated_cost(instance_type):\n",
    "    \"\"\"Get estimated hourly cost for instance type\"\"\"\n",
    "    cost_map = {\n",
    "        'ml.t3.medium': 0.05,\n",
    "        'ml.m5.large': 0.115,\n",
    "        'ml.m5.xlarge': 0.23,\n",
    "        'ml.c5.large': 0.102,\n",
    "        'ml.c5.xlarge': 0.204\n",
    "    }\n",
    "    return cost_map.get(instance_type, 0.115)\n",
    "\n",
    "def delete_all_endpoints():\n",
    "    \"\"\"Delete all endpoints - USE WITH CAUTION\"\"\"\n",
    "    sagemaker = boto3.client('sagemaker')\n",
    "    \n",
    "    try:\n",
    "        response = sagemaker.list_endpoints()\n",
    "        endpoints = response['Endpoints']\n",
    "        \n",
    "        if not endpoints:\n",
    "            print(\"No endpoints to delete\")\n",
    "            return\n",
    "        \n",
    "        print(f\"Deleting {len(endpoints)} endpoint(s)...\")\n",
    "        \n",
    "        for ep in endpoints:\n",
    "            endpoint_name = ep['EndpointName']\n",
    "            try:\n",
    "                sagemaker.delete_endpoint(EndpointName=endpoint_name)\n",
    "                print(f\"   Deleted: {endpoint_name}\")\n",
    "            except Exception as e:\n",
    "                print(f\"   Failed to delete {endpoint_name}: {e}\")\n",
    "        \n",
    "        print(f\"Cleanup complete! All endpoints deleted.\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error during cleanup: {e}\")\n",
    "\n",
    "def delete_endpoint_by_name(endpoint_name):\n",
    "    \"\"\"Delete a specific endpoint by name\"\"\"\n",
    "    sagemaker = boto3.client('sagemaker')\n",
    "    \n",
    "    try:\n",
    "        sagemaker.delete_endpoint(EndpointName=endpoint_name)\n",
    "        print(f\"Successfully deleted endpoint: {endpoint_name}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to delete endpoint {endpoint_name}: {e}\")\n",
    "\n",
    "# Run the resource scan\n",
    "comprehensive_cleanup()\n",
    "\n",
    "print(f\"\\nCLEANUP COMMANDS:\")\n",
    "print(f\"Delete specific endpoint: delete_endpoint_by_name('your-endpoint-name')\")\n",
    "print(f\"Delete ALL endpoints: delete_all_endpoints()  # USE WITH CAUTION\")\n",
    "print(f\"Using predictor object: predictor.delete_endpoint()\")\n",
    "\n",
    "print(f\"\\nCOST REMINDERS:\")\n",
    "print(f\"- Endpoints charge by the hour (~$0.05-0.23/hour)\")\n",
    "print(f\"- Training jobs only charge while running\")\n",
    "print(f\"- Models stored in S3 have minimal storage costs\")\n",
    "print(f\"- Always clean up endpoints when done!\")\n",
    "\n",
    "print(f\"\\nRun this cell periodically to monitor your AWS costs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "521a3ec5",
   "metadata": {},
   "source": [
    "## 🎯 Summary: Your Complete Studio MLOps Workflow\n",
    "\n",
    "### What you've learned:\n",
    "\n",
    "#### 🔄 **Studio Development Workflow:**\n",
    "1. **Explore & Collaborate** → Use Studio's collaborative notebooks and data catalog\n",
    "2. **Discover Data** → Leverage AI-powered data discovery with Amazon Q\n",
    "3. **Train & Version** → Automatic model versioning and registry integration\n",
    "4. **Deploy & Share** → Built-in governance with team and business user access\n",
    "5. **Monitor & Govern** → Continuous monitoring with data governance features\n",
    "\n",
    "#### 🏛️ **Studio Collaborative Features:**\n",
    "- **Data Catalog** → AI-powered data discovery and governance\n",
    "- **Model Registry** → Automatic versioning and team sharing\n",
    "- **Canvas Integration** → No-code access for business users\n",
    "- **Amazon Q** → Natural language assistance for data queries\n",
    "- **Business Glossary** → Shared definitions and standards\n",
    "- **Project Organization** → Team-based asset management\n",
    "\n",
    "#### 🎨 **Canvas Business User Benefits:**\n",
    "- **Point-and-Click ML** → No coding required for predictions\n",
    "- **Automatic Model Access** → Your deployed models appear automatically\n",
    "- **Built-in Governance** → Approval workflows and access controls\n",
    "- **Visual Interface** → Business-friendly prediction interface\n",
    "- **Data Visualization** → Automatic charts and explanations\n",
    "\n",
    "#### 🚀 **Next Steps in Studio:**\n",
    "1. **Create Projects** → Organize work by business use case\n",
    "2. **Invite Team Members** → Set up collaborative workspace\n",
    "3. **Set Up Governance** → Configure approval workflows\n",
    "4. **Enable Canvas Users** → Give business users model access\n",
    "5. **Monitor and Iterate** → Use built-in monitoring and feedback\n",
    "\n",
    "#### 💡 **Studio Pro Tips:**\n",
    "- Use Amazon Q to discover relevant datasets\n",
    "- Leverage automatic model versioning for experiment tracking\n",
    "- Set up approval workflows for production models\n",
    "- Share notebooks with team members for knowledge transfer\n",
    "- Use Canvas for business stakeholder demos\n",
    "\n",
    "#### 🎁 **What Studio Provides Out-of-the-Box:**\n",
    "- ✅ **Governance** → Automatic compliance and audit trails\n",
    "- ✅ **Collaboration** → Real-time team workspace\n",
    "- ✅ **Business Access** → Canvas integration for non-technical users\n",
    "- ✅ **AI Assistance** → Amazon Q for natural language queries\n",
    "- ✅ **Data Discovery** → Intelligent data catalog\n",
    "- ✅ **Security** → Enterprise-grade access controls\n",
    "\n",
    "### 🎉 **You now have enterprise-grade collaborative MLOps with SageMaker Unified Studio!**\n",
    "\n",
    "**Key Difference from Traditional SageMaker:**\n",
    "- Traditional: Individual data scientist workflow\n",
    "- Studio: **Collaborative team workflow with business user access**\n",
    "\n",
    "**Business Impact:**\n",
    "- Faster time-to-insight with collaborative features\n",
    "- Business user empowerment through Canvas\n",
    "- Better governance and compliance\n",
    "- Enhanced data discovery and reuse"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
