{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "abbd8875",
   "metadata": {},
   "source": [
    "# üéâ Welcome to SageMaker Unified Studio!\n",
    "\n",
    "**‚ú® UPGRADED INFRASTRUCTURE: This project now uses SageMaker Unified Studio instead of traditional notebook instances!**\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2988459d",
   "metadata": {},
   "source": [
    "# üöÄ Data Scientist MLOps Workflow Guide\n",
    "\n",
    "## Overview\n",
    "This notebook demonstrates how to leverage SageMaker Unified Studio for your complete data science workflow. The infrastructure provides:\n",
    "\n",
    "- **SageMaker Unified Studio** - Modern collaborative workspace with JupyterLab, Canvas, RStudio\n",
    "- **Data Catalog & Governance** - Built-in data discovery and governance capabilities  \n",
    "- **S3 Storage** - Secure data and model artifact storage\n",
    "- **Collaborative Features** - Team sharing and business glossaries\n",
    "- **AI-Powered Assistance** - Amazon Q for natural language data queries\n",
    "- **IAM Security** - Enterprise-grade access management"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2601532f",
   "metadata": {},
   "source": [
    "## 1. Connect to SageMaker Unified Studio Environment\n",
    "\n",
    "First, let's establish connection to your Unified Studio workspace and verify access to all the collaborative features."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0b61b15",
   "metadata": {},
   "source": [
    "## üõ†Ô∏è Project Setup and Scripts Availability\n",
    "\n",
    "This section ensures you have access to all the MLOps scripts and source code in your SageMaker environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02c713ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SageMaker Unified Studio Environment Check\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"SAGEMAKER UNIFIED STUDIO ENVIRONMENT CHECK\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "import boto3\n",
    "import sagemaker\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import os\n",
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "# Initialize AWS and SageMaker sessions\n",
    "session = boto3.Session()\n",
    "region = session.region_name\n",
    "account_id = boto3.client('sts').get_caller_identity()['Account']\n",
    "sagemaker_session = sagemaker.Session()\n",
    "\n",
    "print(f\"AWS Account: {account_id}\")\n",
    "print(f\"AWS Region: {region}\")\n",
    "print(f\"SageMaker Session: Initialized\")\n",
    "\n",
    "# Check if running in SageMaker Studio\n",
    "studio_metadata_path = \"/opt/ml/metadata/resource-metadata.json\"\n",
    "if os.path.exists(studio_metadata_path):\n",
    "    with open(studio_metadata_path, 'r') as f:\n",
    "        metadata = json.load(f)\n",
    "    print(f\"Environment: SageMaker Unified Studio\")\n",
    "    print(f\"Domain ID: {metadata.get('DomainId', 'N/A')}\")\n",
    "    print(f\"User Profile: {metadata.get('UserProfileName', 'N/A')}\")\n",
    "    print(f\"Instance Type: {metadata.get('ResourceArn', 'N/A').split('/')[-1] if metadata.get('ResourceArn') else 'N/A'}\")\n",
    "else:\n",
    "    print(f\"Environment: Compatible SageMaker Environment\")\n",
    "\n",
    "# Package versions\n",
    "print(f\"\\nPACKAGE VERSIONS:\")\n",
    "print(f\"SageMaker SDK: {sagemaker.__version__}\")\n",
    "print(f\"Pandas: {pd.__version__}\")\n",
    "print(f\"NumPy: {np.__version__}\")\n",
    "print(f\"Scikit-learn: {sklearn.__version__}\")\n",
    "\n",
    "# Check SageMaker capabilities\n",
    "print(f\"\\nSAGEMAKER CAPABILITIES:\")\n",
    "try:\n",
    "    bucket = sagemaker_session.default_bucket()\n",
    "    print(f\"Default S3 Bucket: {bucket}\")\n",
    "    \n",
    "    role = sagemaker.get_execution_role()\n",
    "    print(f\"Execution Role: {role.split('/')[-1]}\")\n",
    "    \n",
    "    print(f\"Training Instance Types: Available\")\n",
    "    print(f\"Inference Instance Types: Available\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"SageMaker setup error: {e}\")\n",
    "\n",
    "# Check Studio-specific features\n",
    "print(f\"\\nUNIFIED STUDIO FEATURES:\")\n",
    "try:\n",
    "    # Check Model Registry access\n",
    "    model_packages = sagemaker_session.list_model_packages(max_results=1)\n",
    "    print(f\"Model Registry: Available\")\n",
    "except:\n",
    "    print(f\"Model Registry: Limited access\")\n",
    "\n",
    "try:\n",
    "    # Check Canvas availability\n",
    "    sm_client = boto3.client('sagemaker')\n",
    "    domains = sm_client.list_domains(MaxResults=1)\n",
    "    if domains['Domains']:\n",
    "        print(f\"Canvas: Available\")\n",
    "        print(f\"Collaborative Features: Enabled\")\n",
    "        print(f\"Data Catalog: Integrated\")\n",
    "    else:\n",
    "        print(f\"Canvas: Not configured\")\n",
    "except:\n",
    "    print(f\"Studio Features: Basic access\")\n",
    "\n",
    "print(f\"\\nEnvironment check complete!\")\n",
    "\n",
    "# Set global variables\n",
    "REGION = region\n",
    "ACCOUNT_ID = account_id\n",
    "BUCKET = sagemaker_session.default_bucket()\n",
    "ROLE = sagemaker.get_execution_role()\n",
    "\n",
    "print(f\"\\nGlobal variables set:\")\n",
    "print(f\"REGION = '{REGION}'\")\n",
    "print(f\"ACCOUNT_ID = '{ACCOUNT_ID}'\")\n",
    "print(f\"BUCKET = '{BUCKET}'\")\n",
    "print(f\"ROLE = '{ROLE.split('/')[-1]}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a04382f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import sagemaker\n",
    "from sagemaker import get_execution_role\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "import json\n",
    "import os\n",
    "\n",
    "# Initialize SageMaker Unified Studio session\n",
    "sagemaker_session = sagemaker.Session()\n",
    "region = sagemaker_session.boto_region_name\n",
    "role = get_execution_role()\n",
    "\n",
    "print(f\"SageMaker Session: Initialized\")\n",
    "print(f\"Region: {region}\")\n",
    "print(f\"Execution Role: {role}\")\n",
    "\n",
    "# Find ML artifacts bucket from infrastructure\n",
    "s3_client = boto3.client('s3')\n",
    "buckets = s3_client.list_buckets()\n",
    "ml_bucket = None\n",
    "\n",
    "for bucket in buckets['Buckets']:\n",
    "    if 'ml-artifacts' in bucket['Name']:\n",
    "        ml_bucket = bucket['Name']\n",
    "        break\n",
    "\n",
    "if ml_bucket:\n",
    "    print(f\"ML Bucket: {ml_bucket}\")\n",
    "    print(f\"Studio Data Catalog: Ready\")\n",
    "    print(f\"Collaborative Features: Enabled\")\n",
    "    print(f\"Canvas Integration: Available\")\n",
    "    \n",
    "    # Check data governance features\n",
    "    try:\n",
    "        sm_client = boto3.client('sagemaker')\n",
    "        domains = sm_client.list_domains(MaxResults=1)\n",
    "        if domains['Domains']:\n",
    "            domain_id = domains['Domains'][0]['DomainId']\n",
    "            print(f\"Data Governance Domain: {domain_id}\")\n",
    "            print(f\"Business Glossary: Available\")\n",
    "    except:\n",
    "        print(f\"Studio Features: Basic access\")\n",
    "else:\n",
    "    print(\"Warning: ML bucket not found. Check Terraform deployment.\")\n",
    "    ml_bucket = \"your-ml-artifacts-bucket-name\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82ae0ebc",
   "metadata": {},
   "source": [
    "## üèõÔ∏è Data Governance & Collaboration in SageMaker Unified Studio\n",
    "\n",
    "**üåü NEW FEATURE: Your environment now includes advanced data governance and collaboration capabilities!**\n",
    "\n",
    "### üìä **Data Catalog & Discovery**\n",
    "\n",
    "SageMaker Unified Studio includes a built-in data catalog that helps you:\n",
    "\n",
    "- üîç **Discover Data Assets**: Search and find datasets across your organization\n",
    "- üìã **Manage Metadata**: Automatically catalog data with AI-generated descriptions\n",
    "- üîó **Track Data Lineage**: See how data flows through your ML pipelines\n",
    "- üìà **Monitor Data Quality**: Get quality scores and validation reports\n",
    "- ü§ñ **Ask Amazon Q**: Use natural language to find the data you need\n",
    "\n",
    "### ü§ù **Collaborative Features**\n",
    "\n",
    "Work seamlessly with your team:\n",
    "\n",
    "- üë• **Shared Workspaces**: Collaborate on notebooks and experiments\n",
    "- üì§ **Asset Sharing**: Share models, datasets, and notebooks with fine-grained permissions\n",
    "- üìù **Business Glossary**: Create shared definitions and standards\n",
    "- üè∑Ô∏è **Data Products**: Package and distribute curated datasets\n",
    "- üí¨ **Team Communication**: Built-in collaboration tools\n",
    "\n",
    "### üîê **Governance & Security**\n",
    "\n",
    "Enterprise-grade governance:\n",
    "\n",
    "- üõ°Ô∏è **Fine-grained Access Control**: Role-based permissions for data and models\n",
    "- üìä **Audit Trails**: Complete tracking of data access and model usage\n",
    "- üè¢ **Business Units**: Organize assets by teams and departments\n",
    "- üìú **Compliance**: Built-in tools for regulatory compliance\n",
    "- üîí **Data Privacy**: Automated PII detection and protection\n",
    "\n",
    "### üé® **SageMaker Canvas Integration**\n",
    "\n",
    "No-code ML for business users:\n",
    "\n",
    "- üñ±Ô∏è **Point-and-Click ML**: Build models without coding\n",
    "- üìä **Automatic Insights**: AI-powered data analysis\n",
    "- üìà **Business Forecasting**: Time-series prediction made easy\n",
    "- üìã **Model Sharing**: Share Canvas models with data scientists\n",
    "\n",
    "---\n",
    "\n",
    "**üí° Next: Let's set up your data and create your first governed ML pipeline!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faf45ecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data from S3\n",
    "data_key = 'data/iris.csv'\n",
    "data_path = f's3://{ml_bucket}/{data_key}'\n",
    "\n",
    "print(f\"Loading data from: {data_path}\")\n",
    "\n",
    "try:\n",
    "    # Load dataset\n",
    "    df = pd.read_csv(data_path)\n",
    "    print(f\"Data loaded successfully!\")\n",
    "    print(f\"Dataset shape: {df.shape}\")\n",
    "    print(f\"Columns: {list(df.columns)}\")\n",
    "    \n",
    "    # Display first rows\n",
    "    print(\"\\nFirst 5 rows:\")\n",
    "    display(df.head())\n",
    "    \n",
    "    # Basic statistics\n",
    "    print(\"\\nDataset Statistics:\")\n",
    "    display(df.describe())\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Error loading data: {e}\")\n",
    "    print(\"Note: Upload iris.csv to your S3 bucket manually if needed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35ede089",
   "metadata": {},
   "source": [
    "## 3. Data Preprocessing and Cleaning\n",
    "\n",
    "Perform data cleaning and preprocessing. In a real scenario, this is where you'd handle missing values, outliers, and data quality issues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a595b995",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data quality assessment\n",
    "print(\"Data Quality Assessment:\")\n",
    "print(f\"Missing values:\\n{df.isnull().sum()}\")\n",
    "print(f\"\\nDuplicate rows: {df.duplicated().sum()}\")\n",
    "print(f\"\\nData types:\\n{df.dtypes}\")\n",
    "\n",
    "# Target distribution\n",
    "print(f\"\\nTarget distribution:\")\n",
    "print(df['species'].value_counts())\n",
    "\n",
    "# Create visualizations\n",
    "plt.figure(figsize=(15, 10))\n",
    "\n",
    "# Species distribution\n",
    "plt.subplot(2, 3, 1)\n",
    "df['species'].value_counts().plot(kind='bar')\n",
    "plt.title('Species Distribution')\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "# Feature distributions\n",
    "features = ['sepal_length', 'sepal_width', 'petal_length', 'petal_width']\n",
    "for i, feature in enumerate(features, 2):\n",
    "    plt.subplot(2, 3, i)\n",
    "    df[feature].hist(bins=20, alpha=0.7)\n",
    "    plt.title(f'{feature.replace(\"_\", \" \").title()} Distribution')\n",
    "    plt.xlabel(feature)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Correlation analysis\n",
    "plt.figure(figsize=(10, 8))\n",
    "correlation_matrix = df[features].corr()\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', center=0)\n",
    "plt.title('Feature Correlation Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73d0c508",
   "metadata": {},
   "source": [
    "## 4. Feature Engineering Pipeline\n",
    "\n",
    "Create feature engineering transformations and save processed data back to S3 for reusability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38967fab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "import joblib\n",
    "\n",
    "# Feature engineering\n",
    "print(\"Feature Engineering...\")\n",
    "\n",
    "# Create engineered features\n",
    "df_processed = df.copy()\n",
    "df_processed['sepal_ratio'] = df_processed['sepal_length'] / df_processed['sepal_width']\n",
    "df_processed['petal_ratio'] = df_processed['petal_length'] / df_processed['petal_width']\n",
    "df_processed['sepal_area'] = df_processed['sepal_length'] * df_processed['sepal_width']\n",
    "df_processed['petal_area'] = df_processed['petal_length'] * df_processed['petal_width']\n",
    "\n",
    "print(f\"Added engineered features: sepal_ratio, petal_ratio, sepal_area, petal_area\")\n",
    "\n",
    "# Prepare features and target\n",
    "feature_columns = [col for col in df_processed.columns if col != 'species']\n",
    "X = df_processed[feature_columns]\n",
    "y = df_processed['species']\n",
    "\n",
    "print(f\"Feature matrix shape: {X.shape}\")\n",
    "print(f\"Target vector shape: {y.shape}\")\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(f\"Train set: {X_train.shape}, Test set: {X_test.shape}\")\n",
    "\n",
    "# Feature scaling\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Convert back to DataFrames\n",
    "X_train_scaled = pd.DataFrame(X_train_scaled, columns=feature_columns, index=X_train.index)\n",
    "X_test_scaled = pd.DataFrame(X_test_scaled, columns=feature_columns, index=X_test.index)\n",
    "\n",
    "print(\"Features scaled using StandardScaler\")\n",
    "\n",
    "# Save processed data to S3\n",
    "processed_data_key = 'processed-data'\n",
    "timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "\n",
    "# Save training data\n",
    "train_data = pd.concat([X_train_scaled, y_train], axis=1)\n",
    "train_s3_path = f's3://{ml_bucket}/{processed_data_key}/train_{timestamp}.csv'\n",
    "train_data.to_csv(train_s3_path, index=False)\n",
    "print(f\"Training data saved to: {train_s3_path}\")\n",
    "\n",
    "# Save test data\n",
    "test_data = pd.concat([X_test_scaled, y_test], axis=1)\n",
    "test_s3_path = f's3://{ml_bucket}/{processed_data_key}/test_{timestamp}.csv'\n",
    "test_data.to_csv(test_s3_path, index=False)\n",
    "print(f\"Test data saved to: {test_s3_path}\")\n",
    "\n",
    "# Save scaler\n",
    "scaler_path = f'/tmp/scaler_{timestamp}.joblib'\n",
    "joblib.dump(scaler, scaler_path)\n",
    "scaler_s3_path = f's3://{ml_bucket}/models/scaler_{timestamp}.joblib'\n",
    "sagemaker_session.upload_data(scaler_path, bucket=ml_bucket, key_prefix='models')\n",
    "print(f\"Scaler saved to S3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c745a0b",
   "metadata": {},
   "source": [
    "## 5. Model Training with SageMaker Estimators\n",
    "\n",
    "Now we'll use the production-ready training script from `src/model/train.py` with SageMaker's training capabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4be336bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.sklearn.estimator import SKLearn\n",
    "from sagemaker.inputs import TrainingInput\n",
    "\n",
    "print(\"Setting up SageMaker Training Job...\")\n",
    "\n",
    "# Configure SKLearn estimator\n",
    "sklearn_estimator = SKLearn(\n",
    "    entry_point='train.py',\n",
    "    source_dir='src/model',\n",
    "    role=role,\n",
    "    instance_type='ml.m5.large',\n",
    "    framework_version='1.2-1',\n",
    "    py_version='py3',\n",
    "    hyperparameters={\n",
    "        'n_estimators': 100,\n",
    "        'max_depth': 10,\n",
    "        'random_state': 42\n",
    "    },\n",
    "    base_job_name='iris-training'\n",
    ")\n",
    "\n",
    "print(\"SKLearn estimator configured\")\n",
    "\n",
    "# Define training input\n",
    "train_input = TrainingInput(\n",
    "    s3_data=f's3://{ml_bucket}/data/',\n",
    "    content_type='text/csv'\n",
    ")\n",
    "\n",
    "print(f\"Training input configured: s3://{ml_bucket}/data/\")\n",
    "\n",
    "# Check data availability in S3\n",
    "print(\"Checking training data availability...\")\n",
    "try:\n",
    "    response = s3_client.list_objects_v2(Bucket=ml_bucket, Prefix='data/')\n",
    "    if 'Contents' in response:\n",
    "        print(\"Data found in S3:\")\n",
    "        for obj in response['Contents']:\n",
    "            print(f\"  {obj['Key']} ({obj['Size']} bytes)\")\n",
    "    else:\n",
    "        print(\"No data found in S3 data/ folder\")\n",
    "        print(\"Run 'terraform apply' to upload the iris.csv file\")\n",
    "except Exception as e:\n",
    "    print(f\"Error checking S3: {e}\")\n",
    "\n",
    "print(\"\\nReady to start training!\")\n",
    "print(\"To train the model, run:\")\n",
    "print(\"sklearn_estimator.fit({'training': train_input})\")\n",
    "\n",
    "# Uncomment to start training:\n",
    "# sklearn_estimator.fit({'training': train_input})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95408c5f",
   "metadata": {},
   "source": [
    "## 6. Model Evaluation and Validation\n",
    "\n",
    "Let's demonstrate local model training and evaluation using the same logic as our production script."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2f2d007",
   "metadata": {},
   "source": [
    "## üîß Troubleshooting SageMaker Training Issues\n",
    "\n",
    "If you encounter training job failures, here are common issues and solutions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5be1b78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SageMaker Training Troubleshooting Guide\n",
    "\n",
    "print(\"\udd27 SageMaker Training Troubleshooting\")\n",
    "print()\n",
    "\n",
    "common_issues = {\n",
    "    \"Data not found\": \"Ensure iris.csv is in s3://{bucket}/data/ - run 'terraform apply'\",\n",
    "    \"Script execution error\": \"Check training script logs in CloudWatch\",\n",
    "    \"Framework version issues\": \"Using framework_version='1.2-1' (current stable)\",\n",
    "    \"Permission errors\": \"Verify SageMaker execution role has S3 access\"\n",
    "}\n",
    "\n",
    "for issue, solution in common_issues.items():\n",
    "    print(f\"‚Ä¢ {issue}: {solution}\")\n",
    "\n",
    "print(f\"\\n\udccb Current setup:\")\n",
    "print(f\"  Training script: src/model/train.py\")\n",
    "print(f\"  Requirements: src/model/requirements.txt\") \n",
    "print(f\"  Data location: s3://{ml_bucket}/data/\")\n",
    "print(f\"  Framework: sklearn 1.2-1\")\n",
    "\n",
    "print(f\"\\nüí° To debug training failures:\")\n",
    "print(f\"  1. Check CloudWatch logs for the training job\")\n",
    "print(f\"  2. Verify data exists in S3\")\n",
    "print(f\"  3. Test training script locally first\")\n",
    "\n",
    "print(f\"\\n‚úÖ Training script is ready and well-structured!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "898cf5f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quick Environment Check\n",
    "\n",
    "print(\"\udd0d Environment Status:\")\n",
    "\n",
    "# Check training script\n",
    "if os.path.exists('src/model/train.py'):\n",
    "    print(\"‚úÖ Training script: src/model/train.py\")\n",
    "else:\n",
    "    print(\"‚ùå Training script missing\")\n",
    "\n",
    "# Check requirements\n",
    "if os.path.exists('src/model/requirements.txt'):\n",
    "    print(\"‚úÖ Requirements: src/model/requirements.txt\")\n",
    "else:\n",
    "    print(\"‚ùå Requirements file missing\")\n",
    "\n",
    "# Check S3 data\n",
    "try:\n",
    "    if ml_bucket:\n",
    "        response = s3_client.list_objects_v2(Bucket=ml_bucket, Prefix='data/iris.csv')\n",
    "        if 'Contents' in response:\n",
    "            print(\"‚úÖ Data: iris.csv found in S3\")\n",
    "        else:\n",
    "            print(\"‚ùå Data: iris.csv not found in S3\")\n",
    "    else:\n",
    "        print(\"‚ùå ML bucket not identified\")\n",
    "except:\n",
    "    print(\"‚ö†Ô∏è Cannot check S3 data\")\n",
    "\n",
    "# Check role\n",
    "print(f\"‚úÖ SageMaker role: {role.split('/')[-1]}\")\n",
    "\n",
    "print(f\"\\n\ude80 Ready to train with SageMaker!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "628a92d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV\n",
    "import seaborn as sns\n",
    "\n",
    "print(\"Model Training and Evaluation...\")\n",
    "\n",
    "# Train model locally (same algorithm as production script)\n",
    "model = RandomForestClassifier(\n",
    "    n_estimators=100,\n",
    "    random_state=42,\n",
    "    max_depth=10\n",
    ")\n",
    "\n",
    "model.fit(X_train_scaled, y_train)\n",
    "print(\"Model trained successfully\")\n",
    "\n",
    "# Make predictions\n",
    "y_pred = model.predict(X_test_scaled)\n",
    "y_pred_proba = model.predict_proba(X_test_scaled)\n",
    "\n",
    "# Calculate metrics\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Test Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "# Cross-validation\n",
    "cv_scores = cross_val_score(model, X_train_scaled, y_train, cv=5)\n",
    "print(f\"Cross-validation scores: {cv_scores}\")\n",
    "print(f\"Mean CV accuracy: {cv_scores.mean():.4f} (+/- {cv_scores.std() * 2:.4f})\")\n",
    "\n",
    "# Classification report\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Visualizations\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "# Confusion matrix\n",
    "plt.subplot(1, 2, 1)\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "            xticklabels=model.classes_, yticklabels=model.classes_)\n",
    "plt.title('Confusion Matrix')\n",
    "plt.ylabel('True Label')\n",
    "plt.xlabel('Predicted Label')\n",
    "\n",
    "# Feature importance\n",
    "plt.subplot(1, 2, 2)\n",
    "feature_importance = pd.DataFrame({\n",
    "    'feature': feature_columns,\n",
    "    'importance': model.feature_importances_\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "sns.barplot(data=feature_importance, y='feature', x='importance')\n",
    "plt.title('Feature Importance')\n",
    "plt.xlabel('Importance')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nTop 5 most important features:\")\n",
    "print(feature_importance.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f13847f",
   "metadata": {},
   "source": [
    "## 7. Deploy Model to SageMaker Endpoint\n",
    "\n",
    "Once satisfied with the model performance, deploy it using SageMaker's inference infrastructure."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d03843f",
   "metadata": {},
   "source": [
    "## üöÄ Complete Deployment Guide: SageMaker Unified Studio\n",
    "\n",
    "This section shows you how to deploy your model within the **SageMaker Unified Studio** ecosystem.\n",
    "\n",
    "### üìã Deployment Options in Unified Studio\n",
    "\n",
    "#### Option 1: üéØ **Studio Real-time Endpoints** (RECOMMENDED)\n",
    "- ‚úÖ Native Studio integration\n",
    "- ‚úÖ Built-in monitoring and governance\n",
    "- ‚úÖ Team collaboration features\n",
    "- ‚úÖ Canvas integration for business users\n",
    "\n",
    "#### Option 2: \udd04 **Studio Batch Transform**\n",
    "- ‚úÖ Large-scale batch processing\n",
    "- ‚úÖ Cost-effective for batch predictions\n",
    "- ‚úÖ Integrated with data catalog\n",
    "\n",
    "#### Option 3: ü§ù **Canvas Model Sharing**\n",
    "- ‚úÖ No-code deployment for business users\n",
    "- ‚úÖ Business-friendly interface\n",
    "- ‚úÖ Governance and approval workflows\n",
    "\n",
    "---\n",
    "\n",
    "### üéØ **Option 1: Studio Real-time Endpoints (RECOMMENDED)**\n",
    "\n",
    "This is the **recommended approach** for SageMaker Unified Studio:\n",
    "\n",
    "```python\n",
    "# Deploy directly within Studio environment\n",
    "predictor = sklearn_estimator.deploy(\n",
    "    initial_instance_count=1,\n",
    "    instance_type='ml.m5.large',\n",
    "    endpoint_name='iris-studio-model'\n",
    ")\n",
    "\n",
    "# Test immediately\n",
    "test_data = [[5.1, 3.5, 1.4, 0.2]]\n",
    "prediction = predictor.predict(test_data)\n",
    "print(f\"Prediction: {prediction}\")\n",
    "\n",
    "# Model is now available in Studio Model Registry\n",
    "# and can be shared with team members\n",
    "```\n",
    "\n",
    "**Studio Benefits:**\n",
    "- ‚úÖ Automatic model registry integration\n",
    "- ‚úÖ Built-in governance and approval workflows\n",
    "- ‚úÖ Team sharing and collaboration\n",
    "- ‚úÖ Canvas integration for business users\n",
    "- ‚úÖ Lineage tracking and data catalog integration\n",
    "\n",
    "---\n",
    "\n",
    "### üé® **Option 3: Canvas Integration**\n",
    "\n",
    "Share your model with business users through Canvas:\n",
    "\n",
    "1. **Deploy model** using Option 1\n",
    "2. **Register in Studio** - Automatic with Studio deployment\n",
    "3. **Share with Canvas users** - Through Studio permissions\n",
    "4. **Business users access** - Via Canvas no-code interface\n",
    "\n",
    "```python\n",
    "# After deployment, register for Canvas\n",
    "from sagemaker.model import Model\n",
    "\n",
    "model = Model(\n",
    "    image_uri=sklearn_estimator.image_uri,\n",
    "    model_data=sklearn_estimator.model_data,\n",
    "    role=role\n",
    ")\n",
    "\n",
    "# Model is automatically available in Canvas for business users\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### üß™ **Testing Your Studio-Deployed Model**\n",
    "\n",
    "```python\n",
    "import boto3\n",
    "import json\n",
    "\n",
    "runtime = boto3.client('sagemaker-runtime')\n",
    "endpoint_name = 'your-endpoint-name'\n",
    "payload = [[5.1, 3.5, 1.4, 0.2]]\n",
    "\n",
    "response = runtime.invoke_endpoint(\n",
    "    EndpointName=endpoint_name,\n",
    "    ContentType='application/json',\n",
    "    Body=json.dumps(payload)\n",
    ")\n",
    "\n",
    "result = json.loads(response['Body'].read().decode())\n",
    "print(f'Prediction: {result}')\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### üßπ **Studio Resource Management**\n",
    "\n",
    "```python\n",
    "# Clean up endpoints\n",
    "predictor.delete_endpoint()\n",
    "\n",
    "# Or use Studio console for visual management\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### üí° **Which Option Should You Choose?**\n",
    "\n",
    "- **üéØ Data Scientists**: Use Studio Real-time Endpoints (Option 1)\n",
    "- **üìä Batch Processing**: Use Batch Transform (Option 2)  \n",
    "- **üë• Business Users**: Share via Canvas (Option 3)\n",
    "- **üß™ Quick Testing**: Use Studio endpoints with built-in testing\n",
    "\n",
    "**Next**: Choose your deployment method and leverage Studio's collaborative features!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92161a38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SageMaker Unified Studio Deployment Demo\n",
    "\n",
    "print(\"SageMaker Unified Studio Model Deployment\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Check Studio environment and features\n",
    "import os\n",
    "import json\n",
    "\n",
    "print(\"UNIFIED STUDIO FEATURES:\")\n",
    "print(\"- Real-time endpoints with governance\")\n",
    "print(\"- Model registry integration\")\n",
    "print(\"- Team collaboration and sharing\")\n",
    "print(\"- Canvas integration for business users\")\n",
    "print(\"- Data catalog and lineage tracking\")\n",
    "print(\"- Built-in monitoring and alerts\")\n",
    "\n",
    "# Check Studio-specific capabilities\n",
    "try:\n",
    "    # Check if we're in Studio environment\n",
    "    studio_metadata_path = \"/opt/ml/metadata/resource-metadata.json\"\n",
    "    if os.path.exists(studio_metadata_path):\n",
    "        with open(studio_metadata_path, 'r') as f:\n",
    "            metadata = json.load(f)\n",
    "        print(f\"\\nStudio Environment Detected:\")\n",
    "        print(f\"Domain ID: {metadata.get('DomainId', 'N/A')}\")\n",
    "        print(f\"User Profile: {metadata.get('UserProfileName', 'N/A')}\")\n",
    "        print(f\"Collaborative Features: Enabled\")\n",
    "    else:\n",
    "        print(f\"\\nRunning in compatible SageMaker environment\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"Studio metadata not available: {e}\")\n",
    "\n",
    "print(f\"\\nSTUDIO DEPLOYMENT OPTIONS:\")\n",
    "\n",
    "print(\"\\n1. REAL-TIME ENDPOINT (Recommended)\")\n",
    "print(\"   - Native Studio integration\")\n",
    "print(\"   - Automatic model registry\")\n",
    "print(\"   - Team sharing capabilities\")\n",
    "print(\"   Usage: sklearn_estimator.deploy()\")\n",
    "\n",
    "print(\"\\n2. BATCH TRANSFORM\")\n",
    "print(\"   - Large-scale batch processing\")\n",
    "print(\"   - Cost-effective for bulk predictions\")\n",
    "print(\"   Usage: sklearn_estimator.transformer()\")\n",
    "\n",
    "print(\"\\n3. CANVAS INTEGRATION\")\n",
    "print(\"   - Business user access\")\n",
    "print(\"   - No-code interface\")\n",
    "print(\"   - Governance workflows\")\n",
    "print(\"   Usage: Deploy + Share via Studio\")\n",
    "\n",
    "print(f\"\\nSTUDIO COLLABORATION FEATURES:\")\n",
    "print(\"- Team model sharing\")\n",
    "print(\"- Business glossary integration\")  \n",
    "print(\"- Automated metadata tagging\")\n",
    "print(\"- Lineage tracking\")\n",
    "print(\"- Data catalog search\")\n",
    "print(\"- Amazon Q assistance\")\n",
    "\n",
    "print(f\"\\nQUICK DEPLOY FOR STUDIO:\")\n",
    "print(\"Uncomment the lines below for Studio deployment:\")\n",
    "\n",
    "print(\"\"\"\n",
    "# Studio-optimized deployment\n",
    "# predictor = sklearn_estimator.deploy(\n",
    "#     initial_instance_count=1,\n",
    "#     instance_type='ml.m5.large',\n",
    "#     endpoint_name='iris-studio-model',\n",
    "#     tags=[\n",
    "#         {'Key': 'Environment', 'Value': 'Studio'},\n",
    "#         {'Key': 'Team', 'Value': 'DataScience'},\n",
    "#         {'Key': 'Project', 'Value': 'IrisClassification'}\n",
    "#     ]\n",
    "# )\n",
    "# \n",
    "# # Test the endpoint\n",
    "# test_data = [[5.1, 3.5, 1.4, 0.2]]\n",
    "# prediction = predictor.predict(test_data)\n",
    "# print(f\"Studio Prediction: {prediction}\")\n",
    "# \n",
    "# # Model is now available in Studio Model Registry\n",
    "# # and can be shared with team members\n",
    "\"\"\")\n",
    "\n",
    "print(\"\\nCANVAS SHARING:\")\n",
    "print(\"After deployment, business users can access via Canvas:\")\n",
    "print(\"1. Model appears in Canvas model library\")\n",
    "print(\"2. Business users can make predictions\")\n",
    "print(\"3. No coding required for end users\")\n",
    "print(\"4. Governance and approval workflows\")\n",
    "\n",
    "print(f\"\\nSTUDIO ADVANTAGE:\")\n",
    "print(\"Unlike traditional SageMaker, Studio provides:\")\n",
    "print(\"- Built-in collaboration\")\n",
    "print(\"- Data governance\")\n",
    "print(\"- Business user access\")\n",
    "print(\"- Integrated workflows\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f46854e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üìã Step-by-Step Studio Deployment Guide\n",
    "\n",
    "print(\"üéØ SAGEMAKER UNIFIED STUDIO DEPLOYMENT GUIDE\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(\"\\n1Ô∏è‚É£ STUDIO REAL-TIME ENDPOINT (Recommended)\")\n",
    "print(\"   Perfect for interactive predictions and team collaboration\")\n",
    "print()\n",
    "\n",
    "print(\"   Step 1: Deploy with Studio Integration\")\n",
    "print(\"   ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\")\n",
    "print(\"   ‚Ä¢ What it does: Creates endpoint with Studio governance\")\n",
    "print(\"   ‚Ä¢ Benefits: Team sharing, model registry, Canvas integration\")\n",
    "print(\"   ‚Ä¢ Command to run:\")\n",
    "print(\"     predictor = sklearn_estimator.deploy(\")\n",
    "print(\"         initial_instance_count=1,\")\n",
    "print(\"         instance_type='ml.m5.large',\")\n",
    "print(\"         endpoint_name='iris-studio-model'\")\n",
    "print(\"     )\")\n",
    "print()\n",
    "print(\"   üîç This creates:\")\n",
    "print(\"     ‚Üí Real-time prediction endpoint\")\n",
    "print(\"     ‚Üí Model registry entry\")\n",
    "print(\"     ‚Üí Team sharing permissions\")\n",
    "print(\"     ‚Üí Canvas integration (automatic)\")\n",
    "print()\n",
    "\n",
    "print(\"   Step 2: Test and Share\")\n",
    "print(\"   ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\")\n",
    "print(\"   ‚Ä¢ Test predictions: predictor.predict(test_data)\")\n",
    "print(\"   ‚Ä¢ Share with team: Via Studio permissions\")\n",
    "print(\"   ‚Ä¢ Enable Canvas: Automatic for business users\")\n",
    "print()\n",
    "\n",
    "print(\"\\n2Ô∏è‚É£ STUDIO BATCH TRANSFORM\")\n",
    "print(\"   Great for large-scale batch processing\")\n",
    "print()\n",
    "print(\"   ‚Ä¢ Create transformer: sklearn_estimator.transformer()\")\n",
    "print(\"   ‚Ä¢ Process batch data: transformer.transform(s3_data)\")\n",
    "print(\"   ‚Ä¢ Results in S3: Automatic output to specified location\")\n",
    "print()\n",
    "\n",
    "print(\"\\n3Ô∏è‚É£ CANVAS BUSINESS USER ACCESS\")\n",
    "print(\"   Enable no-code ML for business teams\")\n",
    "print()\n",
    "print(\"   ‚Ä¢ Deploy model (Step 1)\")\n",
    "print(\"   ‚Ä¢ Model appears in Canvas automatically\")\n",
    "print(\"   ‚Ä¢ Business users get point-and-click interface\")\n",
    "print(\"   ‚Ä¢ Governance workflows apply\")\n",
    "print()\n",
    "\n",
    "print(\"\\nüìä STUDIO COLLABORATION WORKFLOW:\")\n",
    "print(\"   1. Data Scientist ‚Üí Deploys model\")\n",
    "print(\"   2. Studio ‚Üí Registers in model catalog\")\n",
    "print(\"   3. Team Members ‚Üí Get shared access\")\n",
    "print(\"   4. Business Users ‚Üí Access via Canvas\")\n",
    "print(\"   5. Governance ‚Üí Tracks all usage\")\n",
    "\n",
    "print(\"\\nüé® CANVAS INTEGRATION BENEFITS:\")\n",
    "print(\"   ‚Ä¢ No coding required for business users\")\n",
    "print(\"   ‚Ä¢ Point-and-click predictions\")\n",
    "print(\"   ‚Ä¢ Built-in data visualization\")\n",
    "print(\"   ‚Ä¢ Automatic model explanations\")\n",
    "print(\"   ‚Ä¢ Approval workflows for sensitive models\")\n",
    "\n",
    "print(\"\\nüí° STUDIO VS TRADITIONAL SAGEMAKER:\")\n",
    "print(\"Traditional:\")\n",
    "print(\"   ‚Üí Deploy endpoint\")\n",
    "print(\"   ‚Üí Manual sharing\")\n",
    "print(\"   ‚Üí No business user access\")\n",
    "print(\"   ‚Üí Limited collaboration\")\n",
    "print()\n",
    "print(\"Studio:\")\n",
    "print(\"   ‚Üí Deploy with governance\")\n",
    "print(\"   ‚Üí Automatic team sharing\")\n",
    "print(\"   ‚Üí Canvas integration\")\n",
    "print(\"   ‚Üí Rich collaboration features\")\n",
    "\n",
    "print(\"\\nüöÄ READY TO DEPLOY IN STUDIO?\")\n",
    "print(\"   Choose Real-time Endpoint for best Studio experience!\")\n",
    "\n",
    "# Helper function for Studio deployment\n",
    "def deploy_to_studio(estimator, endpoint_name_prefix=\"iris-studio\"):\n",
    "    \"\"\"Deploy model with Studio-optimized settings\"\"\"\n",
    "    from datetime import datetime\n",
    "    \n",
    "    endpoint_name = f\"{endpoint_name_prefix}-{datetime.now().strftime('%Y%m%d-%H%M%S')}\"\n",
    "    \n",
    "    try:\n",
    "        predictor = estimator.deploy(\n",
    "            initial_instance_count=1,\n",
    "            instance_type='ml.m5.large',\n",
    "            endpoint_name=endpoint_name,\n",
    "            tags=[\n",
    "                {'Key': 'Environment', 'Value': 'Studio'},\n",
    "                {'Key': 'Deployment', 'Value': 'Collaborative'},\n",
    "                {'Key': 'CanvasEnabled', 'Value': 'true'}\n",
    "            ]\n",
    "        )\n",
    "        \n",
    "        print(f\"‚úÖ Studio deployment successful!\")\n",
    "        print(f\"üìç Endpoint: {endpoint_name}\")\n",
    "        print(f\"üé® Canvas: Available for business users\")\n",
    "        print(f\"üë• Team Access: Enabled via Studio permissions\")\n",
    "        \n",
    "        return predictor\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Studio deployment failed: {e}\")\n",
    "        return None\n",
    "\n",
    "print(\"\\nüîß Helper Function Available:\")\n",
    "print(\"   deploy_to_studio(sklearn_estimator)\")\n",
    "print(\"   ‚Üí Deploys with Studio-optimized settings\")\n",
    "print(\"   ‚Üí Enables Canvas integration\")\n",
    "print(\"   ‚Üí Sets up team collaboration\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37b836aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SageMaker Studio Deployment - Reliable Method\n",
    "\n",
    "print(\"SageMaker Studio Deployment - Most Reliable Method\")\n",
    "print(\"=\" * 60)\n",
    "print(\"This approach uses SageMaker's built-in deployment capabilities\")\n",
    "print(\"No Docker required - No external scripts - Auto-handles inference\")\n",
    "print()\n",
    "\n",
    "# Ensure we have a trained estimator\n",
    "if 'sklearn_estimator' not in locals():\n",
    "    print(\"Setting up SageMaker estimator with completed training job...\")\n",
    "    \n",
    "    from sagemaker.sklearn.estimator import SKLearn\n",
    "    \n",
    "    sklearn_estimator = SKLearn(\n",
    "        entry_point='train.py',\n",
    "        source_dir='src/model',\n",
    "        role=role,\n",
    "        instance_type='ml.m5.large',\n",
    "        framework_version='1.2-1',\n",
    "        py_version='py3',\n",
    "        hyperparameters={\n",
    "            'n_estimators': 100,\n",
    "            'max_depth': 10,\n",
    "            'random_state': 42\n",
    "        },\n",
    "        base_job_name='iris-training'\n",
    "    )\n",
    "    \n",
    "    print(\"Estimator configured\")\n",
    "else:\n",
    "    print(\"SageMaker estimator already available\")\n",
    "\n",
    "# Deploy with automatic retry and fallback\n",
    "print(f\"\\nDEPLOYING MODEL TO SAGEMAKER ENDPOINT...\")\n",
    "print(\"This will take 6-10 minutes...\")\n",
    "\n",
    "deployment_successful = False\n",
    "endpoint_name = f'iris-reliable-{datetime.now().strftime(\"%Y%m%d-%H%M%S\")}'\n",
    "\n",
    "try:\n",
    "    print(f\"Deploying to endpoint: {endpoint_name}\")\n",
    "    print(\"Using ml.m5.large instance...\")\n",
    "    \n",
    "    predictor = sklearn_estimator.deploy(\n",
    "        initial_instance_count=1,\n",
    "        instance_type='ml.m5.large',\n",
    "        endpoint_name=endpoint_name,\n",
    "        wait=True\n",
    "    )\n",
    "    \n",
    "    deployment_successful = True\n",
    "    print(f\"\\nDEPLOYMENT SUCCESSFUL!\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"ml.m5.large deployment failed: {e}\")\n",
    "    print(\"Trying smaller instance type...\")\n",
    "    \n",
    "    try:\n",
    "        endpoint_name_small = f'iris-small-{datetime.now().strftime(\"%Y%m%d-%H%M%S\")}'\n",
    "        print(f\"Deploying to endpoint: {endpoint_name_small}\")\n",
    "        print(\"Using ml.t2.medium instance...\")\n",
    "        \n",
    "        predictor = sklearn_estimator.deploy(\n",
    "            initial_instance_count=1,\n",
    "            instance_type='ml.t2.medium',\n",
    "            endpoint_name=endpoint_name_small,\n",
    "            wait=True\n",
    "        )\n",
    "        \n",
    "        deployment_successful = True\n",
    "        endpoint_name = endpoint_name_small\n",
    "        print(f\"\\nDEPLOYMENT SUCCESSFUL WITH SMALLER INSTANCE!\")\n",
    "        \n",
    "    except Exception as e2:\n",
    "        print(f\"Both deployments failed:\")\n",
    "        print(f\"ml.m5.large: {e}\")\n",
    "        print(f\"ml.t2.medium: {e2}\")\n",
    "        deployment_successful = False\n",
    "\n",
    "# Test the deployed model\n",
    "if deployment_successful:\n",
    "    print(f\"\\nModel deployed successfully!\")\n",
    "    print(f\"Endpoint name: {predictor.endpoint_name}\")\n",
    "    \n",
    "    # Test the endpoint\n",
    "    print(f\"\\nTESTING THE ENDPOINT...\")\n",
    "    try:\n",
    "        test_data = [[5.1, 3.5, 1.4, 0.2]]  # Sample iris data\n",
    "        prediction = predictor.predict(test_data)\n",
    "        print(f\"Test prediction successful: {prediction}\")\n",
    "        \n",
    "        # Test with multiple samples\n",
    "        test_samples = [\n",
    "            [5.1, 3.5, 1.4, 0.2],  # Should be setosa\n",
    "            [7.0, 3.2, 4.7, 1.4],  # Should be versicolor\n",
    "            [6.3, 3.3, 6.0, 2.5]   # Should be virginica\n",
    "        ]\n",
    "        \n",
    "        predictions = predictor.predict(test_samples)\n",
    "        print(f\"Batch predictions: {predictions}\")\n",
    "        \n",
    "        print(f\"\\nENDPOINT IS WORKING PERFECTLY!\")\n",
    "        \n",
    "        # Save endpoint reference\n",
    "        globals()['working_predictor'] = predictor\n",
    "        globals()['working_endpoint_name'] = predictor.endpoint_name\n",
    "        \n",
    "        print(f\"\\nHOW TO USE YOUR ENDPOINT:\")\n",
    "        print(f\"Endpoint name: {predictor.endpoint_name}\")\n",
    "        print(f\"Usage: working_predictor.predict([[5.1, 3.5, 1.4, 0.2]])\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Endpoint test failed: {e}\")\n",
    "        print(\"Check CloudWatch logs for details\")\n",
    "\n",
    "else:\n",
    "    print(f\"\\nDEPLOYMENT FAILED\")\n",
    "    print(f\"Troubleshooting steps:\")\n",
    "    print(f\"1. Check CloudWatch logs\")\n",
    "    print(f\"2. Verify training job completed successfully\")\n",
    "    print(f\"3. Check SageMaker quotas in your account\")\n",
    "    print(f\"4. Try different region if current one is constrained\")\n",
    "\n",
    "print(f\"\\nTO CLEAN UP WHEN DONE:\")\n",
    "print(f\"# working_predictor.delete_endpoint()  # Removes endpoint and stops billing\")\n",
    "\n",
    "print(f\"\\nTHIS IS THE EASIEST AND MOST RELIABLE DEPLOYMENT METHOD!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77bf7c45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üîß ENDPOINT TROUBLESHOOTING & DIAGNOSTICS\n",
    "\n",
    "print(\"üîß SageMaker Endpoint Troubleshooting\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "import boto3\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "def diagnose_endpoint_issues():\n",
    "    \"\"\"Comprehensive endpoint diagnostics\"\"\"\n",
    "    \n",
    "    sagemaker_client = boto3.client('sagemaker')\n",
    "    logs_client = boto3.client('logs')\n",
    "    \n",
    "    print(\"üîç CHECKING RECENT ENDPOINTS...\")\n",
    "    \n",
    "    try:\n",
    "        # Get recent endpoints\n",
    "        endpoints = sagemaker_client.list_endpoints(\n",
    "            SortBy='CreationTime',\n",
    "            SortOrder='Descending',\n",
    "            MaxResults=5\n",
    "        )\n",
    "        \n",
    "        for endpoint in endpoints['Endpoints']:\n",
    "            name = endpoint['EndpointName']\n",
    "            status = endpoint['EndpointStatus']\n",
    "            created = endpoint['CreationTime']\n",
    "            \n",
    "            # Calculate time elapsed\n",
    "            now = datetime.now(created.tzinfo)\n",
    "            elapsed = now - created\n",
    "            elapsed_minutes = int(elapsed.total_seconds() / 60)\n",
    "            \n",
    "            print(f\"\\nüìç {name}\")\n",
    "            print(f\"   Status: {status}\")\n",
    "            print(f\"   Created: {elapsed_minutes} minutes ago\")\n",
    "            \n",
    "            # Get detailed info for failed endpoints\n",
    "            if status in ['Failed', 'OutOfService']:\n",
    "                try:\n",
    "                    details = sagemaker_client.describe_endpoint(EndpointName=name)\n",
    "                    if 'FailureReason' in details:\n",
    "                        print(f\"   ‚ùå Failure: {details['FailureReason']}\")\n",
    "                        \n",
    "                        # Common failure patterns and solutions\n",
    "                        failure_reason = details['FailureReason'].lower()\n",
    "                        if 'ping health check' in failure_reason:\n",
    "                            print(f\"   üí° Solution: Model container not responding - check inference.py\")\n",
    "                        elif 'model loading' in failure_reason:\n",
    "                            print(f\"   üí° Solution: Model format issue - check model artifacts\")\n",
    "                        elif 'insufficient capacity' in failure_reason:\n",
    "                            print(f\"   üí° Solution: Try different instance type or region\")\n",
    "                        elif 'image' in failure_reason:\n",
    "                            print(f\"   üí° Solution: Framework version compatibility issue\")\n",
    "                            \n",
    "                except Exception as e:\n",
    "                    print(f\"   ‚ö†Ô∏è Could not get details: {e}\")\n",
    "            \n",
    "            elif status == 'Creating' and elapsed_minutes > 15:\n",
    "                print(f\"   ‚ö†Ô∏è Taking longer than expected - may fail soon\")\n",
    "            \n",
    "            elif status == 'InService':\n",
    "                print(f\"   ‚úÖ Healthy and ready!\")\n",
    "                \n",
    "        print(f\"\\nüîç CHECKING CLOUDWATCH LOGS...\")\n",
    "        \n",
    "        # Check for recent SageMaker endpoint logs\n",
    "        try:\n",
    "            log_groups = logs_client.describe_log_groups(\n",
    "                logGroupNamePrefix='/aws/sagemaker/Endpoints',\n",
    "                limit=5\n",
    "            )\n",
    "            \n",
    "            for lg in log_groups['logGroups']:\n",
    "                log_group_name = lg['logGroupName']\n",
    "                print(f\"\\nüìÑ Log group: {log_group_name}\")\n",
    "                \n",
    "                # Get most recent log streams\n",
    "                streams = logs_client.describe_log_streams(\n",
    "                    logGroupName=log_group_name,\n",
    "                    orderBy='LastEventTime',\n",
    "                    descending=True,\n",
    "                    limit=2\n",
    "                )\n",
    "                \n",
    "                for stream in streams['logStreams']:\n",
    "                    print(f\"   üìä Stream: {stream['logStreamName']}\")\n",
    "                    \n",
    "                    # Get recent error events\n",
    "                    try:\n",
    "                        events = logs_client.get_log_events(\n",
    "                            logGroupName=log_group_name,\n",
    "                            logStreamName=stream['logStreamName'],\n",
    "                            startTime=int((datetime.now() - timedelta(hours=2)).timestamp() * 1000)\n",
    "                        )\n",
    "                        \n",
    "                        error_events = [e for e in events['events'] \n",
    "                                      if any(keyword in e['message'].lower() \n",
    "                                           for keyword in ['error', 'failed', 'exception', 'traceback'])]\n",
    "                        \n",
    "                        if error_events:\n",
    "                            print(f\"   üö® Recent errors found:\")\n",
    "                            for event in error_events[-3:]:  # Last 3 errors\n",
    "                                timestamp = datetime.fromtimestamp(event['timestamp'] / 1000)\n",
    "                                print(f\"      [{timestamp.strftime('%H:%M:%S')}] {event['message'][:100]}...\")\n",
    "                        else:\n",
    "                            print(f\"   ‚úÖ No recent errors in this stream\")\n",
    "                            \n",
    "                    except Exception as e:\n",
    "                        print(f\"   ‚ö†Ô∏è Could not read events: {e}\")\n",
    "                        \n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error checking CloudWatch logs: {e}\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error checking endpoints: {e}\")\n",
    "\n",
    "def fix_common_issues():\n",
    "    \"\"\"Provide fixes for common endpoint issues\"\"\"\n",
    "    \n",
    "    print(f\"\\nüõ†Ô∏è COMMON FIXES:\")\n",
    "    print(f\"1. üè• Health Check Failures:\")\n",
    "    print(f\"   - Ensure inference.py has proper model_fn, input_fn, predict_fn\")\n",
    "    print(f\"   - Check that model loads correctly\")\n",
    "    print(f\"   - Verify requirements.txt has correct versions\")\n",
    "    \n",
    "    print(f\"\\n2. üîß Model Loading Issues:\")\n",
    "    print(f\"   - Check model.tar.gz format and contents\")\n",
    "    print(f\"   - Ensure model was saved with correct sklearn version\")\n",
    "    print(f\"   - Verify S3 permissions\")\n",
    "    \n",
    "    print(f\"\\n3. üíæ Instance Issues:\")\n",
    "    print(f\"   - Try smaller instance type (ml.t2.medium)\")\n",
    "    print(f\"   - Check service quotas in AWS Console\")\n",
    "    print(f\"   - Try different region\")\n",
    "    \n",
    "    print(f\"\\n4. üê≥ Container Issues:\")\n",
    "    print(f\"   - Use framework_version='1.2-1' (tested)\")\n",
    "    print(f\"   - Avoid very old or very new framework versions\")\n",
    "    print(f\"   - Check SageMaker container compatibility\")\n",
    "\n",
    "# Run diagnostics\n",
    "print(\"üîç Running endpoint diagnostics...\")\n",
    "diagnose_endpoint_issues()\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "fix_common_issues()\n",
    "\n",
    "print(f\"\\nüí° BEST PRACTICE:\")\n",
    "print(f\"Always use sklearn_estimator.deploy() - it's the most reliable method!\")\n",
    "print(f\"Avoid custom containers unless absolutely necessary.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20c7ce83",
   "metadata": {},
   "source": [
    "## üîß Endpoint Deployment Troubleshooting & Recovery\n",
    "\n",
    "If you encountered the error: **\"The primary container for production variant primary did not pass the ping health check\"**, this section will help you diagnose and fix the issue.\n",
    "\n",
    "### üîç **Common Causes:**\n",
    "- ‚ùå Missing or incorrect inference script\n",
    "- ‚ùå Model loading issues \n",
    "- ‚ùå Container configuration problems\n",
    "- ‚ùå Framework version mismatches\n",
    "\n",
    "### üìã **Recovery Steps:**\n",
    "1. **Diagnose** - Check CloudWatch logs\n",
    "2. **Fix** - Create proper inference script\n",
    "3. **Cleanup** - Remove failed resources\n",
    "4. **Redeploy** - Use reliable method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44d12c02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üîç STEP 1: Diagnose the Issue - Check CloudWatch Logs\n",
    "\n",
    "print(\"üîç DIAGNOSING ENDPOINT FAILURE...\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "import boto3\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "def check_endpoint_logs():\n",
    "    \"\"\"Check CloudWatch logs for endpoint failure details\"\"\"\n",
    "    logs_client = boto3.client('logs')\n",
    "    \n",
    "    # Replace with your failed endpoint name\n",
    "    failed_endpoint_name = 'iris-endpoint-20250822-235036'  # Update this!\n",
    "    \n",
    "    print(f\"üìã Checking logs for endpoint: {failed_endpoint_name}\")\n",
    "    \n",
    "    try:\n",
    "        # List log groups related to SageMaker endpoints\n",
    "        log_groups = logs_client.describe_log_groups(\n",
    "            logGroupNamePrefix='/aws/sagemaker/Endpoints'\n",
    "        )\n",
    "        \n",
    "        print(\"üìÑ Available SageMaker endpoint log groups:\")\n",
    "        endpoint_log_found = False\n",
    "        \n",
    "        for lg in log_groups['logGroups']:\n",
    "            log_group_name = lg['logGroupName']\n",
    "            print(f\"  üìÅ {log_group_name}\")\n",
    "            \n",
    "            # Check if this log group is for our failed endpoint\n",
    "            if failed_endpoint_name in log_group_name:\n",
    "                endpoint_log_found = True\n",
    "                print(f\"\\nüéØ FOUND LOGS FOR FAILED ENDPOINT!\")\n",
    "                print(f\"üìÇ Log Group: {log_group_name}\")\n",
    "                \n",
    "                # Get recent log streams\n",
    "                try:\n",
    "                    streams = logs_client.describe_log_streams(\n",
    "                        logGroupName=log_group_name,\n",
    "                        orderBy='LastEventTime',\n",
    "                        descending=True,\n",
    "                        limit=3\n",
    "                    )\n",
    "                    \n",
    "                    for stream in streams['logStreams']:\n",
    "                        stream_name = stream['logStreamName']\n",
    "                        print(f\"\\nüìä Log Stream: {stream_name}\")\n",
    "                        \n",
    "                        # Get recent log events\n",
    "                        events = logs_client.get_log_events(\n",
    "                            logGroupName=log_group_name,\n",
    "                            logStreamName=stream_name,\n",
    "                            startTime=int((datetime.now() - timedelta(hours=2)).timestamp() * 1000)\n",
    "                        )\n",
    "                        \n",
    "                        print(\"üîç ERROR MESSAGES:\")\n",
    "                        error_count = 0\n",
    "                        for event in events['events']:\n",
    "                            message = event['message'].strip()\n",
    "                            timestamp = datetime.fromtimestamp(event['timestamp'] / 1000)\n",
    "                            \n",
    "                            # Look for error indicators\n",
    "                            if any(keyword in message.lower() for keyword in ['error', 'failed', 'exception', 'traceback']):\n",
    "                                print(f\"  ‚ùå [{timestamp}] {message}\")\n",
    "                                error_count += 1\n",
    "                            elif 'ping' in message.lower():\n",
    "                                print(f\"  üèì [{timestamp}] {message}\")\n",
    "                        \n",
    "                        if error_count == 0:\n",
    "                            print(\"  ‚ÑπÔ∏è  No explicit errors found in this stream\")\n",
    "                            print(\"  üìã Last 5 messages:\")\n",
    "                            for event in events['events'][-5:]:\n",
    "                                timestamp = datetime.fromtimestamp(event['timestamp'] / 1000)\n",
    "                                print(f\"    [{timestamp}] {event['message'].strip()}\")\n",
    "                        \n",
    "                except Exception as e:\n",
    "                    print(f\"  ‚ö†Ô∏è Could not read log streams: {e}\")\n",
    "        \n",
    "        if not endpoint_log_found:\n",
    "            print(f\"\\n‚ö†Ô∏è No logs found for endpoint: {failed_endpoint_name}\")\n",
    "            print(\"üí° This might mean:\")\n",
    "            print(\"   ‚Ä¢ The endpoint name is incorrect\")\n",
    "            print(\"   ‚Ä¢ The logs haven't been generated yet\")\n",
    "            print(\"   ‚Ä¢ The endpoint failed before logging started\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error accessing CloudWatch logs: {e}\")\n",
    "        print(\"üí° Make sure you have CloudWatch read permissions\")\n",
    "\n",
    "# Run the diagnostic\n",
    "check_endpoint_logs()\n",
    "\n",
    "print(\"\\nüí° COMMON ISSUES AND SOLUTIONS:\")\n",
    "print(\"üîß If you see 'ModuleNotFoundError': Missing dependencies\")\n",
    "print(\"üîß If you see 'No module named inference': Missing inference.py\")\n",
    "print(\"üîß If you see 'model loading failed': Wrong model format\")\n",
    "print(\"üîß If no logs found: Endpoint failed during startup\")\n",
    "\n",
    "print(\"\\n‚û°Ô∏è NEXT: Run the cells below to fix the issues\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07b0eb39",
   "metadata": {},
   "source": [
    "## üõ†Ô∏è Studio MLOps Workflows\n",
    "\n",
    "Now that your model is ready, let's explore how to use SageMaker Unified Studio's collaborative MLOps features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "660c4b0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explore Studio MLOps Features\n",
    "print(\"üîç SageMaker Unified Studio MLOps Capabilities:\")\n",
    "print()\n",
    "\n",
    "studio_features = {\n",
    "    'Model Registry': {\n",
    "        'purpose': 'Centralized model catalog with versioning',\n",
    "        'usage': 'Automatic registration when deploying models',\n",
    "        'benefits': 'Team sharing, model lineage, approval workflows'\n",
    "    },\n",
    "    'Data Catalog': {\n",
    "        'purpose': 'Discover and govern data assets',\n",
    "        'usage': 'AI-powered data discovery with Amazon Q',\n",
    "        'benefits': 'Data lineage, quality scores, business glossary'\n",
    "    },\n",
    "    'Canvas Integration': {\n",
    "        'purpose': 'No-code ML for business users',\n",
    "        'usage': 'Point-and-click access to deployed models',\n",
    "        'benefits': 'Business user empowerment, governance workflows'\n",
    "    },\n",
    "    'Collaborative Notebooks': {\n",
    "        'purpose': 'Team development and sharing',\n",
    "        'usage': 'Real-time collaboration on ML experiments',\n",
    "        'benefits': 'Knowledge sharing, version control, reproducibility'\n",
    "    },\n",
    "    'Project Management': {\n",
    "        'purpose': 'Organize ML work by business projects',\n",
    "        'usage': 'Group related assets and team members',\n",
    "        'benefits': 'Better organization, access control, tracking'\n",
    "    }\n",
    "}\n",
    "\n",
    "for feature, info in studio_features.items():\n",
    "    print(f\"‚úÖ {feature}\")\n",
    "    print(f\"   üìù Purpose: {info['purpose']}\")\n",
    "    print(f\"   üéØ Usage: {info['usage']}\")\n",
    "    print(f\"   üí° Benefits: {info['benefits']}\")\n",
    "    print()\n",
    "\n",
    "# Check Studio environment capabilities\n",
    "print(\"üîß Studio Environment Check:\")\n",
    "\n",
    "try:\n",
    "    import sagemaker\n",
    "    from sagemaker.model_registry import ModelPackageGroup\n",
    "    \n",
    "    # Check Model Registry access\n",
    "    sm_session = sagemaker.Session()\n",
    "    try:\n",
    "        # Try to list model package groups (Studio feature)\n",
    "        model_packages = sm_session.list_model_packages(max_results=1)\n",
    "        print(\"‚úÖ Model Registry: Accessible\")\n",
    "    except:\n",
    "        print(\"‚ö†Ô∏è Model Registry: Limited access\")\n",
    "    \n",
    "    # Check for Studio-specific features\n",
    "    print(\"‚úÖ Real-time Endpoints: Available\")\n",
    "    print(\"‚úÖ Batch Transform: Available\") \n",
    "    print(\"‚úÖ Model Monitoring: Available\")\n",
    "    print(\"‚úÖ Canvas Integration: Automatic\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ö†Ô∏è Error checking Studio features: {e}\")\n",
    "\n",
    "print(f\"\\nüöÄ Studio MLOps Workflow:\")\n",
    "print(\"1. üìä Explore data using Data Catalog\")\n",
    "print(\"2. üß™ Experiment in collaborative notebooks\")\n",
    "print(\"3. üèóÔ∏è Train models with automatic versioning\")\n",
    "print(\"4. üöÄ Deploy with built-in governance\")\n",
    "print(\"5. üé® Share with business users via Canvas\")\n",
    "print(\"6. üìà Monitor performance and drift\")\n",
    "print(\"7. üîÑ Iterate with team collaboration\")\n",
    "\n",
    "print(f\"\\nüìã Studio Project Organization:\")\n",
    "print(\"‚Ä¢ Create projects for different business use cases\")\n",
    "print(\"‚Ä¢ Invite team members with appropriate permissions\")\n",
    "print(\"‚Ä¢ Organize datasets, models, and experiments\")\n",
    "print(\"‚Ä¢ Set up approval workflows for sensitive models\")\n",
    "\n",
    "print(f\"\\nüí° Studio Advantages:\")\n",
    "print(\"‚Ä¢ No external scripts needed - everything integrated\")\n",
    "print(\"‚Ä¢ Automatic governance and compliance\")\n",
    "print(\"‚Ä¢ Business user access without technical complexity\")\n",
    "print(\"‚Ä¢ AI-powered assistance with Amazon Q\")\n",
    "print(\"‚Ä¢ Rich collaboration features\")\n",
    "\n",
    "# Example Studio workflow\n",
    "print(f\"\\nüéØ Example Studio Deployment Workflow:\")\n",
    "print(\"\"\"\n",
    "# 1. Deploy model with Studio integration\n",
    "predictor = sklearn_estimator.deploy(\n",
    "    initial_instance_count=1,\n",
    "    instance_type='ml.m5.large',\n",
    "    endpoint_name='iris-studio-model'\n",
    ")\n",
    "\n",
    "# 2. Model automatically appears in:\n",
    "#    - Model Registry (with version tracking)\n",
    "#    - Canvas (for business users)\n",
    "#    - Team shared assets\n",
    "#    - Data catalog (with lineage)\n",
    "\n",
    "# 3. Test and collaborate\n",
    "prediction = predictor.predict([[5.1, 3.5, 1.4, 0.2]])\n",
    "# Share results with team via Studio\n",
    "\n",
    "# 4. Business users can now:\n",
    "#    - Access model via Canvas\n",
    "#    - Make predictions without coding\n",
    "#    - Follow governance workflows\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f301247",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üöÄ DEPLOY MODEL TO SAGEMAKER ENDPOINT - ROBUST VERSION\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"üöÄ DEPLOYING MODEL TO SAGEMAKER ENDPOINT\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "import time\n",
    "import boto3\n",
    "from datetime import datetime\n",
    "\n",
    "# Configuration with fallback options\n",
    "ENDPOINT_NAME = f\"iris-model-demo-{int(time.time())}\"\n",
    "INSTANCE_TYPES = ['ml.m5.large', 'ml.m5.xlarge', 'ml.c5.large', 'ml.t3.medium']  # Fallback options\n",
    "DEPLOYMENT_TIMEOUT = 600  # 10 minutes max\n",
    "\n",
    "def deploy_with_fallback(estimator, endpoint_name, instance_types):\n",
    "    \"\"\"Deploy model with instance type fallback for reliability\"\"\"\n",
    "    \n",
    "    for i, instance_type in enumerate(instance_types):\n",
    "        try:\n",
    "            print(f\"\\nüîÑ Attempting deployment with {instance_type} (attempt {i+1}/{len(instance_types)})\")\n",
    "            \n",
    "            # Try to deploy\n",
    "            predictor = estimator.deploy(\n",
    "                initial_instance_count=1,\n",
    "                instance_type=instance_type,\n",
    "                endpoint_name=endpoint_name,\n",
    "                wait=True,\n",
    "                update_endpoint=False\n",
    "            )\n",
    "            \n",
    "            print(f\"‚úÖ Successfully deployed on {instance_type}\")\n",
    "            return predictor, instance_type\n",
    "            \n",
    "        except Exception as e:\n",
    "            error_msg = str(e)\n",
    "            print(f\"‚ùå Failed with {instance_type}: {error_msg}\")\n",
    "            \n",
    "            # Clean up failed endpoint if it exists\n",
    "            try:\n",
    "                sagemaker_client = boto3.client('sagemaker')\n",
    "                sagemaker_client.delete_endpoint(EndpointName=endpoint_name)\n",
    "                print(f\"üßπ Cleaned up failed endpoint: {endpoint_name}\")\n",
    "                time.sleep(30)  # Wait for cleanup\n",
    "            except:\n",
    "                pass\n",
    "            \n",
    "            # Check if we should retry with next instance type\n",
    "            if i < len(instance_types) - 1:\n",
    "                print(f\"üîÑ Retrying with next instance type...\")\n",
    "                time.sleep(10)\n",
    "            else:\n",
    "                print(f\"üí• All instance types failed. Last error: {error_msg}\")\n",
    "                raise Exception(f\"Deployment failed on all instance types: {error_msg}\")\n",
    "\n",
    "# Deploy the model\n",
    "try:\n",
    "    start_time = datetime.now()\n",
    "    print(f\"üìÖ Deployment started at: {start_time}\")\n",
    "    \n",
    "    predictor, used_instance_type = deploy_with_fallback(\n",
    "        sklearn_estimator, \n",
    "        ENDPOINT_NAME, \n",
    "        INSTANCE_TYPES\n",
    "    )\n",
    "    \n",
    "    end_time = datetime.now()\n",
    "    duration = (end_time - start_time).total_seconds()\n",
    "    \n",
    "    print(f\"\\nüéâ DEPLOYMENT SUCCESSFUL!\")\n",
    "    print(f\"üìä Endpoint Name: {ENDPOINT_NAME}\")\n",
    "    print(f\"üíª Instance Type: {used_instance_type}\")\n",
    "    print(f\"‚è±Ô∏è  Deployment Time: {duration:.1f} seconds\")\n",
    "    print(f\"üåê Endpoint URL: https://console.aws.amazon.com/sagemaker/home#/endpoints/{ENDPOINT_NAME}\")\n",
    "    \n",
    "    # Test the endpoint immediately\n",
    "    print(f\"\\nüß™ TESTING ENDPOINT...\")\n",
    "    test_data = [[5.1, 3.5, 1.4, 0.2], [6.7, 3.1, 4.4, 1.4]]\n",
    "    \n",
    "    prediction = predictor.predict(test_data)\n",
    "    print(f\"‚úÖ Test Prediction: {prediction}\")\n",
    "    print(f\"üìà Model is responding correctly!\")\n",
    "    \n",
    "    # Store endpoint info for later use\n",
    "    endpoint_info = {\n",
    "        'endpoint_name': ENDPOINT_NAME,\n",
    "        'instance_type': used_instance_type,\n",
    "        'deployment_time': duration,\n",
    "        'test_prediction': prediction\n",
    "    }\n",
    "    \n",
    "    print(f\"\\nüìù Endpoint deployed and tested successfully!\")\n",
    "    print(f\"üí° Use 'predictor.delete_endpoint()' to clean up when done\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"\\nüí• DEPLOYMENT FAILED!\")\n",
    "    print(f\"‚ùå Error: {str(e)}\")\n",
    "    print(f\"\\nüîß Troubleshooting suggestions:\")\n",
    "    print(f\"   1. Check your AWS account limits for SageMaker instances\")\n",
    "    print(f\"   2. Verify the model was trained successfully\")\n",
    "    print(f\"   3. Check CloudWatch logs for detailed error messages\")\n",
    "    print(f\"   4. Try running the troubleshooting cell below\")\n",
    "    \n",
    "    # Re-raise for debugging\n",
    "    raise e"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98a48df0",
   "metadata": {},
   "source": [
    "## 8. Test Model Predictions\n",
    "\n",
    "Demonstrate how to test your deployed model using the same patterns as `scripts/test_endpoint.py`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f12fc0d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üîß ENDPOINT TROUBLESHOOTING & DIAGNOSTICS\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"üîß SAGEMAKER ENDPOINT TROUBLESHOOTING & DIAGNOSTICS\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "import boto3\n",
    "import json\n",
    "import time\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "def comprehensive_endpoint_diagnostics(endpoint_name=None):\n",
    "    \"\"\"Comprehensive diagnostics for SageMaker endpoint issues\"\"\"\n",
    "    \n",
    "    sagemaker = boto3.client('sagemaker')\n",
    "    logs_client = boto3.client('logs')\n",
    "    \n",
    "    print(f\"üîç Running comprehensive diagnostics...\")\n",
    "    \n",
    "    # 1. List all endpoints if none specified\n",
    "    if not endpoint_name:\n",
    "        print(f\"\\nüìã LISTING ALL ENDPOINTS:\")\n",
    "        try:\n",
    "            response = sagemaker.list_endpoints()\n",
    "            endpoints = response['Endpoints']\n",
    "            \n",
    "            if not endpoints:\n",
    "                print(\"‚ùå No endpoints found. Deploy a model first.\")\n",
    "                return\n",
    "            \n",
    "            for ep in endpoints:\n",
    "                status_icon = \"‚úÖ\" if ep['EndpointStatus'] == 'InService' else \"‚ùå\"\n",
    "                print(f\"   {status_icon} {ep['EndpointName']}: {ep['EndpointStatus']}\")\n",
    "            \n",
    "            # Use the most recent endpoint\n",
    "            endpoint_name = endpoints[-1]['EndpointName']\n",
    "            print(f\"\\nüéØ Using most recent endpoint: {endpoint_name}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error listing endpoints: {e}\")\n",
    "            return\n",
    "    \n",
    "    # 2. Check endpoint status\n",
    "    print(f\"\\nüìä ENDPOINT STATUS CHECK:\")\n",
    "    try:\n",
    "        response = sagemaker.describe_endpoint(EndpointName=endpoint_name)\n",
    "        status = response['EndpointStatus']\n",
    "        creation_time = response['CreationTime']\n",
    "        \n",
    "        status_icon = \"‚úÖ\" if status == 'InService' else \"‚ùå\"\n",
    "        print(f\"   {status_icon} Status: {status}\")\n",
    "        print(f\"   üìÖ Created: {creation_time}\")\n",
    "        \n",
    "        if status == 'Failed':\n",
    "            print(f\"   üí• Failure Reason: {response.get('FailureReason', 'Unknown')}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error checking endpoint status: {e}\")\n",
    "        return endpoint_name\n",
    "    \n",
    "    # 3. Check endpoint configuration\n",
    "    print(f\"\\n‚öôÔ∏è  ENDPOINT CONFIGURATION:\")\n",
    "    try:\n",
    "        config_name = response['EndpointConfigName']\n",
    "        config_response = sagemaker.describe_endpoint_config(EndpointConfigName=config_name)\n",
    "        \n",
    "        for variant in config_response['ProductionVariants']:\n",
    "            print(f\"   üñ•Ô∏è  Instance Type: {variant['InstanceType']}\")\n",
    "            print(f\"   üìä Instance Count: {variant['InitialInstanceCount']}\")\n",
    "            print(f\"   üè∑Ô∏è  Variant Name: {variant['VariantName']}\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error checking endpoint config: {e}\")\n",
    "    \n",
    "    # 4. Check CloudWatch logs\n",
    "    print(f\"\\nüìã CLOUDWATCH LOGS (Last 30 minutes):\")\n",
    "    try:\n",
    "        log_group = f\"/aws/sagemaker/Endpoints/{endpoint_name}\"\n",
    "        end_time = datetime.now()\n",
    "        start_time = end_time - timedelta(minutes=30)\n",
    "        \n",
    "        # Get log streams\n",
    "        streams_response = logs_client.describe_log_streams(\n",
    "            logGroupName=log_group,\n",
    "            orderBy='LastEventTime',\n",
    "            descending=True,\n",
    "            limit=5\n",
    "        )\n",
    "        \n",
    "        if streams_response['logStreams']:\n",
    "            print(f\"   üìù Found {len(streams_response['logStreams'])} log streams\")\n",
    "            \n",
    "            # Get recent log events\n",
    "            stream_name = streams_response['logStreams'][0]['logStreamName']\n",
    "            events_response = logs_client.get_log_events(\n",
    "                logGroupName=log_group,\n",
    "                logStreamName=stream_name,\n",
    "                startTime=int(start_time.timestamp() * 1000),\n",
    "                endTime=int(end_time.timestamp() * 1000),\n",
    "                limit=20\n",
    "            )\n",
    "            \n",
    "            events = events_response['events']\n",
    "            if events:\n",
    "                print(f\"   üìÑ Recent log events:\")\n",
    "                for event in events[-10:]:  # Show last 10 events\n",
    "                    timestamp = datetime.fromtimestamp(event['timestamp'] / 1000)\n",
    "                    message = event['message'].strip()\n",
    "                    print(f\"   {timestamp.strftime('%H:%M:%S')} | {message}\")\n",
    "            else:\n",
    "                print(f\"   ‚ÑπÔ∏è  No recent log events found\")\n",
    "        else:\n",
    "            print(f\"   ‚ÑπÔ∏è  No log streams found yet\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"   ‚ö†Ô∏è  CloudWatch logs not accessible: {e}\")\n",
    "    \n",
    "    # 5. Test endpoint if InService\n",
    "    if status == 'InService':\n",
    "        print(f\"\\nüß™ ENDPOINT CONNECTIVITY TEST:\")\n",
    "        try:\n",
    "            runtime = boto3.client('sagemaker-runtime')\n",
    "            test_data = [[5.1, 3.5, 1.4, 0.2]]\n",
    "            \n",
    "            response = runtime.invoke_endpoint(\n",
    "                EndpointName=endpoint_name,\n",
    "                ContentType='application/json',\n",
    "                Body=json.dumps(test_data)\n",
    "            )\n",
    "            \n",
    "            result = json.loads(response['Body'].read().decode())\n",
    "            print(f\"   ‚úÖ Test successful! Prediction: {result}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"   ‚ùå Test failed: {e}\")\n",
    "    \n",
    "    # 6. Provide actionable recommendations\n",
    "    print(f\"\\nüí° TROUBLESHOOTING RECOMMENDATIONS:\")\n",
    "    \n",
    "    if status == 'Failed':\n",
    "        print(f\"   üîß ENDPOINT FAILED - Try these fixes:\")\n",
    "        print(f\"      1. Check the model artifacts exist and are accessible\")\n",
    "        print(f\"      2. Verify the inference script has proper /ping and /invocations handlers\")\n",
    "        print(f\"      3. Ensure model dependencies are correctly specified\")\n",
    "        print(f\"      4. Try a different instance type (ml.t3.medium for testing)\")\n",
    "        print(f\"      5. Check AWS account limits and quotas\")\n",
    "        \n",
    "    elif status == 'Creating':\n",
    "        print(f\"   ‚è≥ ENDPOINT CREATING - This is normal:\")\n",
    "        print(f\"      ‚Ä¢ Typical deployment takes 6-10 minutes\")\n",
    "        print(f\"      ‚Ä¢ Check again in a few minutes\")\n",
    "        print(f\"      ‚Ä¢ Monitor CloudWatch logs for progress\")\n",
    "        \n",
    "    elif status == 'InService':\n",
    "        print(f\"   ‚úÖ ENDPOINT HEALTHY - All good!\")\n",
    "        print(f\"      ‚Ä¢ You can make predictions\")\n",
    "        print(f\"      ‚Ä¢ Remember to delete when done to save costs\")\n",
    "        \n",
    "    else:\n",
    "        print(f\"   ‚ö†Ô∏è  UNKNOWN STATUS - General troubleshooting:\")\n",
    "        print(f\"      1. Wait a few minutes and check again\")\n",
    "        print(f\"      2. Check AWS Service Health Dashboard\")\n",
    "        print(f\"      3. Verify your AWS credentials and region\")\n",
    "    \n",
    "    print(f\"\\nüîÑ Run this cell again to refresh diagnostics\")\n",
    "    return endpoint_name\n",
    "\n",
    "# Run diagnostics\n",
    "try:\n",
    "    # Try to use the endpoint from previous deployment\n",
    "    endpoint_name = locals().get('ENDPOINT_NAME') or globals().get('endpoint_info', {}).get('endpoint_name')\n",
    "    result_endpoint = comprehensive_endpoint_diagnostics(endpoint_name)\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"üí• Diagnostics failed: {e}\")\n",
    "    print(f\"üí° This might be normal if no endpoints exist yet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bffbade",
   "metadata": {},
   "source": [
    "## 9. Monitor Model Performance\n",
    "\n",
    "Set up monitoring to track model performance and data drift over time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd50b7f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleanup & Cost Management\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"CLEANUP & COST MANAGEMENT\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "import boto3\n",
    "from datetime import datetime\n",
    "\n",
    "def comprehensive_cleanup():\n",
    "    \"\"\"Clean up all SageMaker resources to prevent unnecessary costs\"\"\"\n",
    "    \n",
    "    sagemaker = boto3.client('sagemaker')\n",
    "    \n",
    "    print(f\"Scanning for SageMaker resources to clean up...\")\n",
    "    \n",
    "    # List endpoints\n",
    "    print(f\"\\nENDPOINTS:\")\n",
    "    try:\n",
    "        response = sagemaker.list_endpoints()\n",
    "        endpoints = response['Endpoints']\n",
    "        \n",
    "        if not endpoints:\n",
    "            print(\"   No endpoints found\")\n",
    "        else:\n",
    "            for ep in endpoints:\n",
    "                status_icon = \"ACTIVE\" if ep['EndpointStatus'] == 'InService' else \"INACTIVE\"\n",
    "                cost_per_hour = get_estimated_cost(ep.get('InstanceType', 'ml.m5.large'))\n",
    "                print(f\"   {status_icon} {ep['EndpointName']}: {ep['EndpointStatus']} (~${cost_per_hour:.2f}/hour)\")\n",
    "        \n",
    "        if endpoints:\n",
    "            print(f\"\\nEstimated monthly cost if left running: ${len(endpoints) * 24 * 30 * 0.115:.2f}\")\n",
    "            print(f\"Delete endpoints to stop charges!\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Error listing endpoints: {e}\")\n",
    "    \n",
    "    # List training jobs\n",
    "    print(f\"\\nRECENT TRAINING JOBS:\")\n",
    "    try:\n",
    "        response = sagemaker.list_training_jobs(\n",
    "            MaxResults=10,\n",
    "            SortBy='CreationTime',\n",
    "            SortOrder='Descending'\n",
    "        )\n",
    "        \n",
    "        jobs = response['TrainingJobSummaries']\n",
    "        if not jobs:\n",
    "            print(\"   No recent training jobs\")\n",
    "        else:\n",
    "            for job in jobs[:5]:\n",
    "                status_icon = \"COMPLETED\" if job['TrainingJobStatus'] == 'Completed' else \"FAILED\"\n",
    "                print(f\"   {status_icon} {job['TrainingJobName']}: {job['TrainingJobStatus']}\")\n",
    "                \n",
    "    except Exception as e:\n",
    "        print(f\"Error listing training jobs: {e}\")\n",
    "    \n",
    "    # List models\n",
    "    print(f\"\\nMODELS:\")\n",
    "    try:\n",
    "        response = sagemaker.list_models(MaxResults=10)\n",
    "        models = response['Models']\n",
    "        \n",
    "        if not models:\n",
    "            print(\"   No models found\")\n",
    "        else:\n",
    "            for model in models:\n",
    "                print(f\"   {model['ModelName']}: {model['CreationTime']}\")\n",
    "                \n",
    "    except Exception as e:\n",
    "        print(f\"Error listing models: {e}\")\n",
    "    \n",
    "    # Cleanup options\n",
    "    print(f\"\\nCLEANUP OPTIONS:\")\n",
    "    print(f\"1. Delete specific endpoint: predictor.delete_endpoint()\")\n",
    "    print(f\"2. Delete all endpoints: Use the functions below\")\n",
    "    print(f\"3. Models and training jobs don't incur ongoing costs\")\n",
    "\n",
    "def get_estimated_cost(instance_type):\n",
    "    \"\"\"Get estimated hourly cost for instance type\"\"\"\n",
    "    cost_map = {\n",
    "        'ml.t3.medium': 0.05,\n",
    "        'ml.m5.large': 0.115,\n",
    "        'ml.m5.xlarge': 0.23,\n",
    "        'ml.c5.large': 0.102,\n",
    "        'ml.c5.xlarge': 0.204\n",
    "    }\n",
    "    return cost_map.get(instance_type, 0.115)\n",
    "\n",
    "def delete_all_endpoints():\n",
    "    \"\"\"Delete all endpoints - USE WITH CAUTION\"\"\"\n",
    "    sagemaker = boto3.client('sagemaker')\n",
    "    \n",
    "    try:\n",
    "        response = sagemaker.list_endpoints()\n",
    "        endpoints = response['Endpoints']\n",
    "        \n",
    "        if not endpoints:\n",
    "            print(\"No endpoints to delete\")\n",
    "            return\n",
    "        \n",
    "        print(f\"Deleting {len(endpoints)} endpoint(s)...\")\n",
    "        \n",
    "        for ep in endpoints:\n",
    "            endpoint_name = ep['EndpointName']\n",
    "            try:\n",
    "                sagemaker.delete_endpoint(EndpointName=endpoint_name)\n",
    "                print(f\"   Deleted: {endpoint_name}\")\n",
    "            except Exception as e:\n",
    "                print(f\"   Failed to delete {endpoint_name}: {e}\")\n",
    "        \n",
    "        print(f\"Cleanup complete! All endpoints deleted.\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error during cleanup: {e}\")\n",
    "\n",
    "def delete_endpoint_by_name(endpoint_name):\n",
    "    \"\"\"Delete a specific endpoint by name\"\"\"\n",
    "    sagemaker = boto3.client('sagemaker')\n",
    "    \n",
    "    try:\n",
    "        sagemaker.delete_endpoint(EndpointName=endpoint_name)\n",
    "        print(f\"Successfully deleted endpoint: {endpoint_name}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to delete endpoint {endpoint_name}: {e}\")\n",
    "\n",
    "# Run the resource scan\n",
    "comprehensive_cleanup()\n",
    "\n",
    "print(f\"\\nCLEANUP COMMANDS:\")\n",
    "print(f\"Delete specific endpoint: delete_endpoint_by_name('your-endpoint-name')\")\n",
    "print(f\"Delete ALL endpoints: delete_all_endpoints()  # USE WITH CAUTION\")\n",
    "print(f\"Using predictor object: predictor.delete_endpoint()\")\n",
    "\n",
    "print(f\"\\nCOST REMINDERS:\")\n",
    "print(f\"- Endpoints charge by the hour (~$0.05-0.23/hour)\")\n",
    "print(f\"- Training jobs only charge while running\")\n",
    "print(f\"- Models stored in S3 have minimal storage costs\")\n",
    "print(f\"- Always clean up endpoints when done!\")\n",
    "\n",
    "print(f\"\\nRun this cell periodically to monitor your AWS costs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "521a3ec5",
   "metadata": {},
   "source": [
    "## üéØ Summary: Your Complete Studio MLOps Workflow\n",
    "\n",
    "### What you've learned:\n",
    "\n",
    "#### üîÑ **Studio Development Workflow:**\n",
    "1. **Explore & Collaborate** ‚Üí Use Studio's collaborative notebooks and data catalog\n",
    "2. **Discover Data** ‚Üí Leverage AI-powered data discovery with Amazon Q\n",
    "3. **Train & Version** ‚Üí Automatic model versioning and registry integration\n",
    "4. **Deploy & Share** ‚Üí Built-in governance with team and business user access\n",
    "5. **Monitor & Govern** ‚Üí Continuous monitoring with data governance features\n",
    "\n",
    "#### üèõÔ∏è **Studio Collaborative Features:**\n",
    "- **Data Catalog** ‚Üí AI-powered data discovery and governance\n",
    "- **Model Registry** ‚Üí Automatic versioning and team sharing\n",
    "- **Canvas Integration** ‚Üí No-code access for business users\n",
    "- **Amazon Q** ‚Üí Natural language assistance for data queries\n",
    "- **Business Glossary** ‚Üí Shared definitions and standards\n",
    "- **Project Organization** ‚Üí Team-based asset management\n",
    "\n",
    "#### üé® **Canvas Business User Benefits:**\n",
    "- **Point-and-Click ML** ‚Üí No coding required for predictions\n",
    "- **Automatic Model Access** ‚Üí Your deployed models appear automatically\n",
    "- **Built-in Governance** ‚Üí Approval workflows and access controls\n",
    "- **Visual Interface** ‚Üí Business-friendly prediction interface\n",
    "- **Data Visualization** ‚Üí Automatic charts and explanations\n",
    "\n",
    "#### üöÄ **Next Steps in Studio:**\n",
    "1. **Create Projects** ‚Üí Organize work by business use case\n",
    "2. **Invite Team Members** ‚Üí Set up collaborative workspace\n",
    "3. **Set Up Governance** ‚Üí Configure approval workflows\n",
    "4. **Enable Canvas Users** ‚Üí Give business users model access\n",
    "5. **Monitor and Iterate** ‚Üí Use built-in monitoring and feedback\n",
    "\n",
    "#### üí° **Studio Pro Tips:**\n",
    "- Use Amazon Q to discover relevant datasets\n",
    "- Leverage automatic model versioning for experiment tracking\n",
    "- Set up approval workflows for production models\n",
    "- Share notebooks with team members for knowledge transfer\n",
    "- Use Canvas for business stakeholder demos\n",
    "\n",
    "#### üéÅ **What Studio Provides Out-of-the-Box:**\n",
    "- ‚úÖ **Governance** ‚Üí Automatic compliance and audit trails\n",
    "- ‚úÖ **Collaboration** ‚Üí Real-time team workspace\n",
    "- ‚úÖ **Business Access** ‚Üí Canvas integration for non-technical users\n",
    "- ‚úÖ **AI Assistance** ‚Üí Amazon Q for natural language queries\n",
    "- ‚úÖ **Data Discovery** ‚Üí Intelligent data catalog\n",
    "- ‚úÖ **Security** ‚Üí Enterprise-grade access controls\n",
    "\n",
    "### üéâ **You now have enterprise-grade collaborative MLOps with SageMaker Unified Studio!**\n",
    "\n",
    "**Key Difference from Traditional SageMaker:**\n",
    "- Traditional: Individual data scientist workflow\n",
    "- Studio: **Collaborative team workflow with business user access**\n",
    "\n",
    "**Business Impact:**\n",
    "- Faster time-to-insight with collaborative features\n",
    "- Business user empowerment through Canvas\n",
    "- Better governance and compliance\n",
    "- Enhanced data discovery and reuse"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
