{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "abbd8875",
   "metadata": {},
   "source": [
    "# ğŸ‰ Welcome to SageMaker Unified Studio!\n",
    "\n",
    "**âœ¨ UPGRADED INFRASTRUCTURE: This project now uses SageMaker Unified Studio instead of traditional notebook instances!**\n",
    "\n",
    "## ğŸš€ **What's New in Your Environment:**\n",
    "\n",
    "### ğŸŒŸ **SageMaker Unified Studio Features:**\n",
    "- **ğŸ¤ Collaborative Environment**: Work with your team in shared domains\n",
    "- **ğŸ“Š Data Governance**: Built-in data catalog and governance capabilities  \n",
    "- **ğŸ¨ SageMaker Canvas**: No-code ML for business users\n",
    "- **ğŸ¤– Generative AI**: Integrated with Amazon Bedrock for AI assistance\n",
    "- **ğŸ“ˆ Advanced Analytics**: R/Python support with RStudio integration\n",
    "- **ğŸ”’ Enterprise Security**: Fine-grained access controls and data lineage\n",
    "\n",
    "### ğŸ”§ **Environment Details:**\n",
    "- **Domain Type**: SageMaker Unified Studio Domain\n",
    "- **User Profiles**: Multiple users with role-based access\n",
    "- **Data Storage**: S3-backed with automatic synchronization\n",
    "- **Instance Types**: Auto-scaling based on workload\n",
    "- **Collaboration**: Shared notebooks and data assets\n",
    "\n",
    "### ğŸ¯ **How to Use This Notebook:**\n",
    "1. **Launch from Studio**: This notebook is optimized for SageMaker Studio\n",
    "2. **Follow the Workflow**: Complete ML pipeline with governance features\n",
    "3. **Collaborate**: Share notebooks and models with your team\n",
    "4. **Use Data Catalog**: Discover and manage data assets\n",
    "5. **Deploy with Confidence**: Production-ready deployment workflows\n",
    "\n",
    "---\n",
    "\n",
    "**ğŸ’¡ Ready to get started? Follow the complete workflow below!**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2988459d",
   "metadata": {},
   "source": [
    "# ğŸš€ Data Scientist MLOps Workflow Guide\n",
    "\n",
    "## Overview\n",
    "This notebook demonstrates how to leverage the deployed MLOps infrastructure for your complete data science workflow. The infrastructure provides:\n",
    "\n",
    "- **SageMaker Notebook Instance** - Your development environment\n",
    "- **S3 Bucket** - Data and model artifact storage\n",
    "- **ECR Repository** - Container image registry\n",
    "- **Lambda Functions** - Pipeline orchestration\n",
    "- **IAM Roles** - Secure access management\n",
    "\n",
    "\n",
    "### ğŸ“ `src/` folder structure:\n",
    "- `src/model/train.py` - Production-ready training script\n",
    "- `src/model/inference.py` - Model serving logic\n",
    "- `src/container/` - Docker containerization for custom algorithms\n",
    "- `src/lambda/` - Pipeline automation functions\n",
    "\n",
    "### ğŸ“ `scripts/` folder structure:\n",
    "- `scripts/build_and_push.sh` - Build and deploy model containers\n",
    "- `scripts/deploy.sh` - Deploy models to production\n",
    "- `scripts/test_endpoint.py` - Test deployed models\n",
    "- `scripts/cleanup.sh` - Clean up resources"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2601532f",
   "metadata": {},
   "source": [
    "## 1. Connect to AWS SageMaker Environment\n",
    "\n",
    "First, let's establish connection to your deployed infrastructure and verify access to resources."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0b61b15",
   "metadata": {},
   "source": [
    "## ğŸ› ï¸ Project Setup and Scripts Availability\n",
    "\n",
    "This section ensures you have access to all the MLOps scripts and source code in your SageMaker environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02c713ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ” ENVIRONMENT CHECK - SAGEMAKER UNIFIED STUDIO\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"ğŸ” SAGEMAKER UNIFIED STUDIO ENVIRONMENT CHECK\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "import boto3\n",
    "import sagemaker\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import os\n",
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "# Basic environment information\n",
    "session = boto3.Session()\n",
    "region = session.region_name\n",
    "account_id = boto3.client('sts').get_caller_identity()['Account']\n",
    "sagemaker_session = sagemaker.Session()\n",
    "\n",
    "print(f\"âœ… AWS Account: {account_id}\")\n",
    "print(f\"âœ… AWS Region: {region}\")\n",
    "print(f\"âœ… SageMaker Session: {sagemaker_session}\")\n",
    "\n",
    "# Check if running in SageMaker Studio\n",
    "studio_metadata_path = \"/opt/ml/metadata/resource-metadata.json\"\n",
    "if os.path.exists(studio_metadata_path):\n",
    "    with open(studio_metadata_path, 'r') as f:\n",
    "        metadata = json.load(f)\n",
    "    print(f\"ğŸ  Environment: SageMaker Studio\")\n",
    "    print(f\"ğŸ¯ Domain ID: {metadata.get('DomainId', 'N/A')}\")\n",
    "    print(f\"\udc64 User Profile: {metadata.get('UserProfileName', 'N/A')}\")\n",
    "    print(f\"ğŸ’» Instance Type: {metadata.get('ResourceArn', 'N/A').split('/')[-1] if metadata.get('ResourceArn') else 'N/A'}\")\n",
    "else:\n",
    "    print(f\"ğŸ  Environment: Traditional SageMaker Notebook Instance\")\n",
    "\n",
    "# Package versions\n",
    "print(f\"\\nğŸ“¦ PACKAGE VERSIONS:\")\n",
    "print(f\"   ğŸ“Š SageMaker SDK: {sagemaker.__version__}\")\n",
    "print(f\"   ğŸ¼ Pandas: {pd.__version__}\")\n",
    "print(f\"   ğŸ”¢ NumPy: {np.__version__}\")\n",
    "print(f\"   ğŸ¤– Scikit-learn: {sklearn.__version__}\")\n",
    "\n",
    "# Check SageMaker capabilities\n",
    "print(f\"\\nğŸš€ SAGEMAKER CAPABILITIES:\")\n",
    "try:\n",
    "    # Check default bucket\n",
    "    bucket = sagemaker_session.default_bucket()\n",
    "    print(f\"   ğŸ“¦ Default S3 Bucket: {bucket}\")\n",
    "    \n",
    "    # Check execution role\n",
    "    role = sagemaker.get_execution_role()\n",
    "    print(f\"   ğŸ” Execution Role: {role.split('/')[-1]}\")\n",
    "    \n",
    "    # Check available instance types for training\n",
    "    print(f\"   ğŸ‹ï¸ Training Instance Types: ml.m5.large, ml.m5.xlarge (and more)\")\n",
    "    print(f\"   ğŸ¯ Inference Instance Types: ml.t2.medium, ml.m5.large (and more)\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"   âš ï¸ SageMaker setup incomplete: {e}\")\n",
    "\n",
    "# Check data governance capabilities (Studio-specific)\n",
    "print(f\"\\nğŸ›ï¸ DATA GOVERNANCE & STUDIO FEATURES:\")\n",
    "try:\n",
    "    # Check if we can access SageMaker Model Registry\n",
    "    model_packages = sagemaker_session.list_model_packages(max_results=1)\n",
    "    print(f\"   ğŸ“‹ Model Registry: âœ… Accessible\")\n",
    "except:\n",
    "    print(f\"   ğŸ“‹ Model Registry: âš ï¸ Limited access\")\n",
    "\n",
    "try:\n",
    "    # Check if Canvas is available (Studio feature)\n",
    "    sm_client = boto3.client('sagemaker')\n",
    "    domains = sm_client.list_domains(MaxResults=1)\n",
    "    if domains['Domains']:\n",
    "        print(f\"   ğŸ¨ SageMaker Canvas: âœ… Available\")\n",
    "        print(f\"   ğŸ¤ Collaborative Features: âœ… Enabled\")\n",
    "        print(f\"   ğŸ“Š Data Catalog: âœ… Integrated\")\n",
    "    else:\n",
    "        print(f\"   ğŸ¨ SageMaker Canvas: âŒ Not configured\")\n",
    "except:\n",
    "    print(f\"   ğŸ¨ Studio Features: âš ï¸ Limited access\")\n",
    "\n",
    "# Project file structure check\n",
    "print(f\"\\nğŸ“ PROJECT FILE STRUCTURE:\")\n",
    "project_dirs = ['scripts', 'src', 'data']\n",
    "for dir_name in project_dirs:\n",
    "    if os.path.exists(f\"./project-files/{dir_name}\"):\n",
    "        files = os.listdir(f\"./project-files/{dir_name}\")\n",
    "        print(f\"   \udcc2 {dir_name}/: âœ… ({len(files)} files)\")\n",
    "    elif os.path.exists(f\"./{dir_name}\"):\n",
    "        files = os.listdir(f\"./{dir_name}\")\n",
    "        print(f\"   ğŸ“‚ {dir_name}/: âœ… ({len(files)} files)\")\n",
    "    else:\n",
    "        print(f\"   ğŸ“‚ {dir_name}/: âš ï¸ Not found (will be created)\")\n",
    "\n",
    "print(f\"\\nğŸ‰ Environment check complete!\")\n",
    "print(f\"ğŸ’¡ You're ready to start your ML workflow in SageMaker Unified Studio!\")\n",
    "\n",
    "# Set global variables for the notebook\n",
    "REGION = region\n",
    "ACCOUNT_ID = account_id\n",
    "BUCKET = sagemaker_session.default_bucket()\n",
    "ROLE = sagemaker.get_execution_role()\n",
    "\n",
    "print(f\"\\nğŸ”§ Global variables set:\")\n",
    "print(f\"   REGION = '{REGION}'\")\n",
    "print(f\"   ACCOUNT_ID = '{ACCOUNT_ID}'\")\n",
    "print(f\"   BUCKET = '{BUCKET}'\")\n",
    "print(f\"   ROLE = '{ROLE.split('/')[-1]}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a04382f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import sagemaker\n",
    "from sagemaker import get_execution_role\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "import json\n",
    "import os\n",
    "\n",
    "# Initialize SageMaker session\n",
    "sagemaker_session = sagemaker.Session()\n",
    "region = sagemaker_session.boto_region_name\n",
    "role = get_execution_role()\n",
    "\n",
    "print(f\"âœ… SageMaker Session initialized\")\n",
    "print(f\"ğŸ“ Region: {region}\")\n",
    "print(f\"ğŸ” Execution Role: {role}\")\n",
    "\n",
    "# Get S3 bucket from infrastructure (replace with your actual bucket name)\n",
    "# This should match the bucket created by Terraform\n",
    "s3_client = boto3.client('s3')\n",
    "buckets = s3_client.list_buckets()\n",
    "ml_bucket = None\n",
    "\n",
    "for bucket in buckets['Buckets']:\n",
    "    if 'ml-artifacts' in bucket['Name']:  # Match your Terraform bucket naming\n",
    "        ml_bucket = bucket['Name']\n",
    "        break\n",
    "\n",
    "if ml_bucket:\n",
    "    print(f\"ğŸª£ Found ML Bucket: {ml_bucket}\")\n",
    "    \n",
    "    # Setup project files automatically\n",
    "    print(\"\\nğŸ”§ Setting up project files...\")\n",
    "    setup_project_files(ml_bucket)\n",
    "    \n",
    "    # Re-check project structure\n",
    "    print(\"\\nğŸ“ Updated project structure:\")\n",
    "    for dir_path in ['scripts', 'src/model', 'src/container', 'src/lambda']:\n",
    "        if os.path.exists(dir_path):\n",
    "            files = os.listdir(dir_path)\n",
    "            print(f\"  {dir_path}: {files}\")\n",
    "        else:\n",
    "            print(f\"  {dir_path}: Not available\")\n",
    "            \n",
    "else:\n",
    "    print(\"âš ï¸ ML bucket not found. Please check your Terraform deployment.\")\n",
    "    # Fallback - you can manually set the bucket name here\n",
    "    ml_bucket = \"your-ml-artifacts-bucket-name\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82ae0ebc",
   "metadata": {},
   "source": [
    "## ğŸ›ï¸ Data Governance & Collaboration in SageMaker Unified Studio\n",
    "\n",
    "**ğŸŒŸ NEW FEATURE: Your environment now includes advanced data governance and collaboration capabilities!**\n",
    "\n",
    "### ğŸ“Š **Data Catalog & Discovery**\n",
    "\n",
    "SageMaker Unified Studio includes a built-in data catalog that helps you:\n",
    "\n",
    "- ğŸ” **Discover Data Assets**: Search and find datasets across your organization\n",
    "- ğŸ“‹ **Manage Metadata**: Automatically catalog data with AI-generated descriptions\n",
    "- ğŸ”— **Track Data Lineage**: See how data flows through your ML pipelines\n",
    "- ğŸ“ˆ **Monitor Data Quality**: Get quality scores and validation reports\n",
    "- ğŸ¤– **Ask Amazon Q**: Use natural language to find the data you need\n",
    "\n",
    "### ğŸ¤ **Collaborative Features**\n",
    "\n",
    "Work seamlessly with your team:\n",
    "\n",
    "- ğŸ‘¥ **Shared Workspaces**: Collaborate on notebooks and experiments\n",
    "- ğŸ“¤ **Asset Sharing**: Share models, datasets, and notebooks with fine-grained permissions\n",
    "- ğŸ“ **Business Glossary**: Create shared definitions and standards\n",
    "- ğŸ·ï¸ **Data Products**: Package and distribute curated datasets\n",
    "- ğŸ’¬ **Team Communication**: Built-in collaboration tools\n",
    "\n",
    "### ğŸ” **Governance & Security**\n",
    "\n",
    "Enterprise-grade governance:\n",
    "\n",
    "- ğŸ›¡ï¸ **Fine-grained Access Control**: Role-based permissions for data and models\n",
    "- ğŸ“Š **Audit Trails**: Complete tracking of data access and model usage\n",
    "- ğŸ¢ **Business Units**: Organize assets by teams and departments\n",
    "- ğŸ“œ **Compliance**: Built-in tools for regulatory compliance\n",
    "- ğŸ”’ **Data Privacy**: Automated PII detection and protection\n",
    "\n",
    "### ğŸ¨ **SageMaker Canvas Integration**\n",
    "\n",
    "No-code ML for business users:\n",
    "\n",
    "- ğŸ–±ï¸ **Point-and-Click ML**: Build models without coding\n",
    "- ğŸ“Š **Automatic Insights**: AI-powered data analysis\n",
    "- ğŸ“ˆ **Business Forecasting**: Time-series prediction made easy\n",
    "- ğŸ“‹ **Model Sharing**: Share Canvas models with data scientists\n",
    "\n",
    "---\n",
    "\n",
    "**ğŸ’¡ Next: Let's set up your data and create your first governed ML pipeline!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faf45ecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data from S3\n",
    "data_key = 'data/iris.csv'\n",
    "data_path = f's3://{ml_bucket}/{data_key}'\n",
    "\n",
    "print(f\"ğŸ“¥ Loading data from: {data_path}\")\n",
    "\n",
    "try:\n",
    "    # Load dataset\n",
    "    df = pd.read_csv(data_path)\n",
    "    print(f\"âœ… Data loaded successfully!\")\n",
    "    print(f\"ğŸ“Š Dataset shape: {df.shape}\")\n",
    "    print(f\"ğŸ“‹ Columns: {list(df.columns)}\")\n",
    "    \n",
    "    # Display first few rows\n",
    "    print(\"\\nğŸ” First 5 rows:\")\n",
    "    display(df.head())\n",
    "    \n",
    "    # Basic statistics\n",
    "    print(\"\\nğŸ“ˆ Dataset Statistics:\")\n",
    "    display(df.describe())\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"âŒ Error loading data: {e}\")\n",
    "    print(\"ğŸ’¡ You may need to upload the iris.csv file to your S3 bucket manually\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35ede089",
   "metadata": {},
   "source": [
    "## 3. Data Preprocessing and Cleaning\n",
    "\n",
    "Perform data cleaning and preprocessing. In a real scenario, this is where you'd handle missing values, outliers, and data quality issues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a595b995",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data quality checks\n",
    "print(\"ğŸ” Data Quality Assessment:\")\n",
    "print(f\"Missing values:\\n{df.isnull().sum()}\")\n",
    "print(f\"\\nDuplicate rows: {df.duplicated().sum()}\")\n",
    "print(f\"\\nData types:\\n{df.dtypes}\")\n",
    "\n",
    "# Check target distribution\n",
    "print(f\"\\nğŸ¯ Target distribution:\")\n",
    "print(df['species'].value_counts())\n",
    "\n",
    "# Visualization\n",
    "plt.figure(figsize=(15, 10))\n",
    "\n",
    "# Distribution plots\n",
    "plt.subplot(2, 3, 1)\n",
    "df['species'].value_counts().plot(kind='bar')\n",
    "plt.title('Species Distribution')\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "# Feature distributions\n",
    "features = ['sepal_length', 'sepal_width', 'petal_length', 'petal_width']\n",
    "for i, feature in enumerate(features, 2):\n",
    "    plt.subplot(2, 3, i)\n",
    "    df[feature].hist(bins=20, alpha=0.7)\n",
    "    plt.title(f'{feature.replace(\"_\", \" \").title()} Distribution')\n",
    "    plt.xlabel(feature)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Correlation matrix\n",
    "plt.figure(figsize=(10, 8))\n",
    "correlation_matrix = df[features].corr()\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', center=0)\n",
    "plt.title('Feature Correlation Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73d0c508",
   "metadata": {},
   "source": [
    "## 4. Feature Engineering Pipeline\n",
    "\n",
    "Create feature engineering transformations and save processed data back to S3 for reusability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38967fab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "import joblib\n",
    "\n",
    "# Feature engineering\n",
    "print(\"âš™ï¸ Feature Engineering...\")\n",
    "\n",
    "# Create additional features\n",
    "df_processed = df.copy()\n",
    "df_processed['sepal_ratio'] = df_processed['sepal_length'] / df_processed['sepal_width']\n",
    "df_processed['petal_ratio'] = df_processed['petal_length'] / df_processed['petal_width']\n",
    "df_processed['sepal_area'] = df_processed['sepal_length'] * df_processed['sepal_width']\n",
    "df_processed['petal_area'] = df_processed['petal_length'] * df_processed['petal_width']\n",
    "\n",
    "print(f\"âœ… Added engineered features: {['sepal_ratio', 'petal_ratio', 'sepal_area', 'petal_area']}\")\n",
    "\n",
    "# Separate features and target\n",
    "feature_columns = [col for col in df_processed.columns if col != 'species']\n",
    "X = df_processed[feature_columns]\n",
    "y = df_processed['species']\n",
    "\n",
    "print(f\"ğŸ“Š Feature matrix shape: {X.shape}\")\n",
    "print(f\"ğŸ¯ Target vector shape: {y.shape}\")\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(f\"ğŸ”„ Train set: {X_train.shape}, Test set: {X_test.shape}\")\n",
    "\n",
    "# Scale features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Convert back to DataFrames for easier handling\n",
    "X_train_scaled = pd.DataFrame(X_train_scaled, columns=feature_columns, index=X_train.index)\n",
    "X_test_scaled = pd.DataFrame(X_test_scaled, columns=feature_columns, index=X_test.index)\n",
    "\n",
    "print(\"âœ… Features scaled using StandardScaler\")\n",
    "\n",
    "# Save processed data to S3\n",
    "processed_data_key = 'processed-data'\n",
    "timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "\n",
    "# Save training data\n",
    "train_data = pd.concat([X_train_scaled, y_train], axis=1)\n",
    "train_s3_path = f's3://{ml_bucket}/{processed_data_key}/train_{timestamp}.csv'\n",
    "train_data.to_csv(train_s3_path, index=False)\n",
    "print(f\"ğŸ’¾ Training data saved to: {train_s3_path}\")\n",
    "\n",
    "# Save test data\n",
    "test_data = pd.concat([X_test_scaled, y_test], axis=1)\n",
    "test_s3_path = f's3://{ml_bucket}/{processed_data_key}/test_{timestamp}.csv'\n",
    "test_data.to_csv(test_s3_path, index=False)\n",
    "print(f\"ğŸ’¾ Test data saved to: {test_s3_path}\")\n",
    "\n",
    "# Save scaler for later use\n",
    "scaler_path = f'/tmp/scaler_{timestamp}.joblib'\n",
    "joblib.dump(scaler, scaler_path)\n",
    "scaler_s3_path = f's3://{ml_bucket}/models/scaler_{timestamp}.joblib'\n",
    "sagemaker_session.upload_data(scaler_path, bucket=ml_bucket, key_prefix='models')\n",
    "print(f\"ğŸ’¾ Scaler saved to: {scaler_s3_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c745a0b",
   "metadata": {},
   "source": [
    "## 5. Model Training with SageMaker Estimators\n",
    "\n",
    "Now we'll use the production-ready training script from `src/model/train.py` with SageMaker's training capabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4be336bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.sklearn.estimator import SKLearn\n",
    "from sagemaker.inputs import TrainingInput\n",
    "\n",
    "print(\"ğŸš€ Setting up SageMaker Training Job...\")\n",
    "\n",
    "# Configure the SKLearn estimator\n",
    "sklearn_estimator = SKLearn(\n",
    "    entry_point='train.py',\n",
    "    source_dir='src/model',\n",
    "    role=role,\n",
    "    instance_type='ml.m5.large',\n",
    "    framework_version='1.2-1',\n",
    "    py_version='py3',\n",
    "    hyperparameters={\n",
    "        'n_estimators': 100,\n",
    "        'max_depth': 10,\n",
    "        'random_state': 42\n",
    "    },\n",
    "    base_job_name='iris-training'\n",
    ")\n",
    "\n",
    "print(\"âœ… SKLearn estimator configured\")\n",
    "\n",
    "# Define training input\n",
    "train_input = TrainingInput(\n",
    "    s3_data=f's3://{ml_bucket}/data/',\n",
    "    content_type='text/csv'\n",
    ")\n",
    "\n",
    "print(f\"ğŸ“¥ Training input configured: s3://{ml_bucket}/data/\")\n",
    "\n",
    "# Check if data exists in S3\n",
    "print(\"ğŸ” Checking training data availability...\")\n",
    "try:\n",
    "    response = s3_client.list_objects_v2(Bucket=ml_bucket, Prefix='data/')\n",
    "    if 'Contents' in response:\n",
    "        print(\"âœ… Data found in S3:\")\n",
    "        for obj in response['Contents']:\n",
    "            print(f\"  ğŸ“„ {obj['Key']} ({obj['Size']} bytes)\")\n",
    "    else:\n",
    "        print(\"âŒ No data found in S3 data/ folder\")\n",
    "        print(\"ğŸ’¡ Run 'terraform apply' to upload the iris.csv file\")\n",
    "except Exception as e:\n",
    "    print(f\"âš ï¸ Error checking S3: {e}\")\n",
    "\n",
    "print(\"\\nğŸ¯ Ready to start training!\")\n",
    "print(\"To train the model, uncomment and run:\")\n",
    "print(\"# sklearn_estimator.fit({'training': train_input})\")\n",
    "\n",
    "# Uncomment the line below when you're ready to start training:\n",
    "# sklearn_estimator.fit({'training': train_input})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95408c5f",
   "metadata": {},
   "source": [
    "## 6. Model Evaluation and Validation\n",
    "\n",
    "Let's demonstrate local model training and evaluation using the same logic as our production script."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2f2d007",
   "metadata": {},
   "source": [
    "## ğŸ”§ Troubleshooting SageMaker Training Issues\n",
    "\n",
    "If you encounter training job failures, here are common issues and solutions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5be1b78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SageMaker Training Troubleshooting Guide\n",
    "\n",
    "print(\"\udd27 SageMaker Training Troubleshooting\")\n",
    "print()\n",
    "\n",
    "common_issues = {\n",
    "    \"Data not found\": \"Ensure iris.csv is in s3://{bucket}/data/ - run 'terraform apply'\",\n",
    "    \"Script execution error\": \"Check training script logs in CloudWatch\",\n",
    "    \"Framework version issues\": \"Using framework_version='1.2-1' (current stable)\",\n",
    "    \"Permission errors\": \"Verify SageMaker execution role has S3 access\"\n",
    "}\n",
    "\n",
    "for issue, solution in common_issues.items():\n",
    "    print(f\"â€¢ {issue}: {solution}\")\n",
    "\n",
    "print(f\"\\n\udccb Current setup:\")\n",
    "print(f\"  Training script: src/model/train.py\")\n",
    "print(f\"  Requirements: src/model/requirements.txt\") \n",
    "print(f\"  Data location: s3://{ml_bucket}/data/\")\n",
    "print(f\"  Framework: sklearn 1.2-1\")\n",
    "\n",
    "print(f\"\\nğŸ’¡ To debug training failures:\")\n",
    "print(f\"  1. Check CloudWatch logs for the training job\")\n",
    "print(f\"  2. Verify data exists in S3\")\n",
    "print(f\"  3. Test training script locally first\")\n",
    "\n",
    "print(f\"\\nâœ… Training script is ready and well-structured!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "898cf5f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quick Environment Check\n",
    "\n",
    "print(\"\udd0d Environment Status:\")\n",
    "\n",
    "# Check training script\n",
    "if os.path.exists('src/model/train.py'):\n",
    "    print(\"âœ… Training script: src/model/train.py\")\n",
    "else:\n",
    "    print(\"âŒ Training script missing\")\n",
    "\n",
    "# Check requirements\n",
    "if os.path.exists('src/model/requirements.txt'):\n",
    "    print(\"âœ… Requirements: src/model/requirements.txt\")\n",
    "else:\n",
    "    print(\"âŒ Requirements file missing\")\n",
    "\n",
    "# Check S3 data\n",
    "try:\n",
    "    if ml_bucket:\n",
    "        response = s3_client.list_objects_v2(Bucket=ml_bucket, Prefix='data/iris.csv')\n",
    "        if 'Contents' in response:\n",
    "            print(\"âœ… Data: iris.csv found in S3\")\n",
    "        else:\n",
    "            print(\"âŒ Data: iris.csv not found in S3\")\n",
    "    else:\n",
    "        print(\"âŒ ML bucket not identified\")\n",
    "except:\n",
    "    print(\"âš ï¸ Cannot check S3 data\")\n",
    "\n",
    "# Check role\n",
    "print(f\"âœ… SageMaker role: {role.split('/')[-1]}\")\n",
    "\n",
    "print(f\"\\n\ude80 Ready to train with SageMaker!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "628a92d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV\n",
    "import seaborn as sns\n",
    "\n",
    "print(\"ğŸ”¬ Model Training and Evaluation...\")\n",
    "\n",
    "# Train model locally (same algorithm as production script)\n",
    "model = RandomForestClassifier(\n",
    "    n_estimators=100,\n",
    "    random_state=42,\n",
    "    max_depth=10\n",
    ")\n",
    "\n",
    "model.fit(X_train_scaled, y_train)\n",
    "print(\"âœ… Model trained successfully\")\n",
    "\n",
    "# Make predictions\n",
    "y_pred = model.predict(X_test_scaled)\n",
    "y_pred_proba = model.predict_proba(X_test_scaled)\n",
    "\n",
    "# Calculate metrics\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"ğŸ¯ Test Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "# Cross-validation\n",
    "cv_scores = cross_val_score(model, X_train_scaled, y_train, cv=5)\n",
    "print(f\"ğŸ“Š Cross-validation scores: {cv_scores}\")\n",
    "print(f\"ğŸ“Š Mean CV accuracy: {cv_scores.mean():.4f} (+/- {cv_scores.std() * 2:.4f})\")\n",
    "\n",
    "# Classification report\n",
    "print(\"\\nğŸ“‹ Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Confusion matrix\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "            xticklabels=model.classes_, yticklabels=model.classes_)\n",
    "plt.title('Confusion Matrix')\n",
    "plt.ylabel('True Label')\n",
    "plt.xlabel('Predicted Label')\n",
    "\n",
    "# Feature importance\n",
    "plt.subplot(1, 2, 2)\n",
    "feature_importance = pd.DataFrame({\n",
    "    'feature': feature_columns,\n",
    "    'importance': model.feature_importances_\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "sns.barplot(data=feature_importance, y='feature', x='importance')\n",
    "plt.title('Feature Importance')\n",
    "plt.xlabel('Importance')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nğŸ” Top 5 most important features:\")\n",
    "print(feature_importance.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f13847f",
   "metadata": {},
   "source": [
    "## 7. Deploy Model to SageMaker Endpoint\n",
    "\n",
    "Once satisfied with the model performance, deploy it using SageMaker's inference infrastructure."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d03843f",
   "metadata": {},
   "source": [
    "## ğŸš€ Complete Deployment Guide: Using the MLOps Scripts\n",
    "\n",
    "This section shows you exactly how to deploy your model. You have **multiple options** depending on your environment and requirements.\n",
    "\n",
    "### ğŸ“‹ Overview of Deployment Options\n",
    "\n",
    "#### Option 1: ğŸ¯ **SageMaker-Only Deployment** (RECOMMENDED for SageMaker)\n",
    "- âœ… Works entirely within SageMaker notebook\n",
    "- âœ… No external dependencies required\n",
    "- âœ… Uses `sklearn_estimator.deploy()`\n",
    "- âœ… Perfect for development and testing\n",
    "\n",
    "#### Option 2: ğŸ³ **Containerized Deployment** (Production-Ready)\n",
    "- ğŸ—ï¸ Requires Docker and ECR access\n",
    "- ğŸ—ï¸ Best for production environments\n",
    "- ğŸ—ï¸ **Scripts**: `build_and_push.sh` â†’ `deploy.sh`\n",
    "- âš ï¸ **Note**: Scripts now auto-discover resources if Terraform folder not available\n",
    "\n",
    "#### Option 3: ğŸ”§ **Step Functions Pipeline** (Enterprise)\n",
    "- ğŸ—ï¸ Orchestrated deployment via AWS Step Functions\n",
    "- ğŸ—ï¸ Includes monitoring and rollback\n",
    "- ğŸ—ï¸ **Script**: `deploy.sh`\n",
    "\n",
    "---\n",
    "\n",
    "### ğŸ¯ **Option 1: SageMaker-Only Deployment (EASIEST)**\n",
    "\n",
    "This is the **recommended approach** for SageMaker notebook users:\n",
    "\n",
    "```python\n",
    "# Deploy directly from your trained estimator\n",
    "predictor = sklearn_estimator.deploy(\n",
    "    initial_instance_count=1,\n",
    "    instance_type='ml.m5.large',\n",
    "    endpoint_name='iris-model-demo'\n",
    ")\n",
    "\n",
    "# Test immediately\n",
    "test_data = [[5.1, 3.5, 1.4, 0.2]]\n",
    "prediction = predictor.predict(test_data)\n",
    "print(f\"Prediction: {prediction}\")\n",
    "\n",
    "# Clean up when done\n",
    "predictor.delete_endpoint()\n",
    "```\n",
    "\n",
    "**Benefits:**\n",
    "- âœ… No external scripts needed\n",
    "- âœ… Works entirely in SageMaker\n",
    "- âœ… Immediate testing capability\n",
    "- âœ… Easy cleanup\n",
    "\n",
    "---\n",
    "\n",
    "### \udee0ï¸ **Option 2: Production Deployment with Docker**\n",
    "\n",
    "**âš ï¸ Updated**: Scripts now work in SageMaker environment!\n",
    "\n",
    "#### Step 1: Build and Push Container Image\n",
    "\n",
    "```bash\n",
    "# The script now auto-discovers ECR repository\n",
    "cd scripts\n",
    "./build_and_push.sh\n",
    "```\n",
    "\n",
    "**What this script does:**\n",
    "- ğŸ” Auto-discovers ECR repository from AWS CLI\n",
    "- âœ… Logs into Amazon ECR\n",
    "- âœ… Builds Docker image from `src/container/Dockerfile`\n",
    "- âœ… Tags and pushes image to ECR\n",
    "\n",
    "#### Step 2: Deploy Using Step Functions\n",
    "\n",
    "```bash\n",
    "# The script now auto-discovers Step Functions\n",
    "./deploy.sh\n",
    "```\n",
    "\n",
    "**What this script does:**\n",
    "- ğŸ” Auto-discovers Step Functions from AWS CLI\n",
    "- âœ… Starts deployment execution\n",
    "- âœ… Monitors progress\n",
    "- âœ… Creates SageMaker endpoint\n",
    "\n",
    "---\n",
    "\n",
    "### ğŸ§ª **Testing Your Deployed Model**\n",
    "\n",
    "Once deployed with any method:\n",
    "\n",
    "```python\n",
    "import boto3\n",
    "import json\n",
    "\n",
    "runtime = boto3.client('sagemaker-runtime')\n",
    "endpoint_name = 'your-endpoint-name'\n",
    "payload = [[5.1, 3.5, 1.4, 0.2]]\n",
    "\n",
    "response = runtime.invoke_endpoint(\n",
    "    EndpointName=endpoint_name,\n",
    "    ContentType='application/json',\n",
    "    Body=json.dumps(payload)\n",
    ")\n",
    "\n",
    "result = json.loads(response['Body'].read().decode())\n",
    "print(f'Prediction: {result}')\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### ğŸ§¹ **Cleanup Resources**\n",
    "\n",
    "**For SageMaker-Only deployments:**\n",
    "```python\n",
    "predictor.delete_endpoint()\n",
    "```\n",
    "\n",
    "**For Docker/Step Functions deployments:**\n",
    "```bash\n",
    "cd scripts\n",
    "./cleanup.sh\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### ğŸ’¡ **Which Option Should You Choose?**\n",
    "\n",
    "- **ğŸ¯ In SageMaker Notebook**: Use Option 1 (SageMaker-Only)\n",
    "- **ğŸ­ Production Environment**: Use Option 2 (Docker + Step Functions)\n",
    "- **ğŸ§ª Quick Testing**: Use Option 1\n",
    "- **\udd04 CI/CD Pipeline**: Use Option 2\n",
    "\n",
    "**Next**: Choose your deployment method and follow the steps below!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92161a38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸš€ Deployment Demo: Let's Deploy Your Model!\n",
    "\n",
    "print(\"ğŸš€ SageMaker Model Deployment Options\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Check if we have the required scripts\n",
    "import os\n",
    "import subprocess\n",
    "\n",
    "scripts_available = []\n",
    "required_scripts = ['build_and_push.sh', 'deploy.sh', 'test_endpoint.py', 'cleanup.sh']\n",
    "\n",
    "for script in required_scripts:\n",
    "    script_path = f'scripts/{script}'\n",
    "    if os.path.exists(script_path):\n",
    "        scripts_available.append(script)\n",
    "        print(f\"âœ… {script}\")\n",
    "    else:\n",
    "        print(f\"âŒ {script} - Not found\")\n",
    "\n",
    "print(f\"\\nğŸ“Š Scripts available: {len(scripts_available)}/{len(required_scripts)}\")\n",
    "\n",
    "if len(scripts_available) == len(required_scripts):\n",
    "    print(\"ğŸ‰ All deployment scripts are ready!\")\n",
    "    \n",
    "    print(\"\\nğŸ› ï¸ OPTION 1: Production Deployment (Recommended)\")\n",
    "    print(\"   Step 1: Build and push Docker image\")\n",
    "    print(\"   Command: cd scripts && ./build_and_push.sh\")\n",
    "    print(\"   \")\n",
    "    print(\"   Step 2: Deploy using Step Functions\")\n",
    "    print(\"   Command: cd scripts && ./deploy.sh\")\n",
    "    print(\"   \")\n",
    "    print(\"   Step 3: Test your endpoint\")\n",
    "    print(\"   Command: cd scripts && python test_endpoint.py --endpoint-name YOUR_ENDPOINT\")\n",
    "    \n",
    "    print(\"\\nğŸ¯ OPTION 2: Quick Notebook Deployment\")\n",
    "    print(\"   Use the sklearn_estimator.deploy() method below\")\n",
    "    \n",
    "    print(\"\\nğŸ’¡ Choose Option 1 for production, Option 2 for quick testing\")\n",
    "    \n",
    "else:\n",
    "    print(\"âš ï¸ Some scripts are missing. They should be available in your SageMaker environment.\")\n",
    "    print(\"   Make sure you've run 'terraform apply' to set up the infrastructure.\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"ğŸ“‹ Deployment Checklist:\")\n",
    "print(\"â˜ Model trained successfully\")\n",
    "print(\"â˜ Scripts available\")\n",
    "print(\"â˜ AWS credentials configured\")\n",
    "print(\"â˜ ECR repository exists (from Terraform)\")\n",
    "print(\"â˜ Docker installed (for Option 1)\")\n",
    "\n",
    "# Quick deployment option for testing\n",
    "print(\"\\nğŸš€ QUICK DEPLOY (Option 2):\")\n",
    "print(\"Uncomment the lines below for immediate deployment:\")\n",
    "\n",
    "print(\"\"\"\n",
    "# Quick deployment for testing\n",
    "# predictor = sklearn_estimator.deploy(\n",
    "#     initial_instance_count=1,\n",
    "#     instance_type='ml.m5.large',\n",
    "#     endpoint_name='iris-quick-test'\n",
    "# )\n",
    "# \n",
    "# # Test the endpoint\n",
    "# test_data = [[5.1, 3.5, 1.4, 0.2]]\n",
    "# prediction = predictor.predict(test_data)\n",
    "# print(f\"Prediction: {prediction}\")\n",
    "# \n",
    "# # Remember to clean up when done:\n",
    "# # predictor.delete_endpoint()\n",
    "\"\"\")\n",
    "\n",
    "print(\"\\nğŸ³ PRODUCTION DEPLOY (Option 1):\")\n",
    "print(\"Run these commands in terminal:\")\n",
    "print(\"   cd scripts\")\n",
    "print(\"   ./build_and_push.sh\")\n",
    "print(\"   ./deploy.sh\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f46854e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ“‹ Step-by-Step Deployment Instructions\n",
    "\n",
    "print(\"ğŸ¯ STEP-BY-STEP DEPLOYMENT GUIDE\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "print(\"\\n1ï¸âƒ£ PRODUCTION DEPLOYMENT (build_and_push.sh + deploy.sh)\")\n",
    "print(\"   This is the recommended approach for production systems\")\n",
    "print()\n",
    "\n",
    "print(\"   Step 1: Build and Push Docker Image\")\n",
    "print(\"   â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\")\n",
    "print(\"   â€¢ What it does: Creates a Docker container with your model\")\n",
    "print(\"   â€¢ Requirements: Docker installed, ECR repository from Terraform\")\n",
    "print(\"   â€¢ Command to run:\")\n",
    "print(\"     cd scripts\")\n",
    "print(\"     ./build_and_push.sh\")\n",
    "print()\n",
    "print(\"   ğŸ” This script will:\")\n",
    "print(\"     â†’ Login to Amazon ECR\")\n",
    "print(\"     â†’ Build Docker image using src/container/Dockerfile\")\n",
    "print(\"     â†’ Tag and push image to ECR repository\")\n",
    "print(\"     â†’ Clean up local images (optional)\")\n",
    "print()\n",
    "\n",
    "print(\"   Step 2: Deploy Using Step Functions\")\n",
    "print(\"   â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\")\n",
    "print(\"   â€¢ What it does: Orchestrates deployment via AWS Step Functions\")\n",
    "print(\"   â€¢ Requirements: Step Functions from Terraform\")\n",
    "print(\"   â€¢ Command to run:\")\n",
    "print(\"     ./deploy.sh\")\n",
    "print()\n",
    "print(\"   ğŸ” This script will:\")\n",
    "print(\"     â†’ Start Step Functions execution\")\n",
    "print(\"     â†’ Monitor deployment progress\")\n",
    "print(\"     â†’ Create SageMaker endpoint\")\n",
    "print(\"     â†’ Show endpoint testing instructions\")\n",
    "print()\n",
    "\n",
    "print(\"   Step 3: Test Your Endpoint\")\n",
    "print(\"   â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\")\n",
    "print(\"   â€¢ Command to run:\")\n",
    "print(\"     python test_endpoint.py --endpoint-name YOUR_ENDPOINT_NAME\")\n",
    "print()\n",
    "\n",
    "print(\"\\n2ï¸âƒ£ QUICK DEPLOYMENT (sklearn_estimator.deploy())\")\n",
    "print(\"   Good for testing and experimentation\")\n",
    "print()\n",
    "print(\"   â€¢ Uncomment the code in the cell above\")\n",
    "print(\"   â€¢ Runs directly from this notebook\")\n",
    "print(\"   â€¢ Faster but less production-ready\")\n",
    "print()\n",
    "\n",
    "print(\"\\n3ï¸âƒ£ CLEANUP (cleanup.sh)\")\n",
    "print(\"   Run this when you're done to avoid AWS charges\")\n",
    "print()\n",
    "print(\"   â€¢ Command to run:\")\n",
    "print(\"     ./cleanup.sh\")\n",
    "print(\"   â€¢ Removes endpoints, models, and billable resources\")\n",
    "print()\n",
    "\n",
    "print(\"ğŸ’¡ RECOMMENDATION:\")\n",
    "print(\"   â€¢ For learning/testing: Use Quick Deployment (#2)\")\n",
    "print(\"   â€¢ For production: Use Production Deployment (#1)\")\n",
    "print(\"   â€¢ Always cleanup when done (#3)\")\n",
    "\n",
    "print(\"\\nğŸš€ READY TO START?\")\n",
    "print(\"   Choose your deployment method and run the commands!\")\n",
    "\n",
    "# Helper function to run scripts from notebook\n",
    "def run_deployment_script(script_name):\n",
    "    \"\"\"Helper function to run deployment scripts from notebook\"\"\"\n",
    "    print(f\"Running {script_name}...\")\n",
    "    try:\n",
    "        result = subprocess.run(\n",
    "            f\"cd scripts && ./{script_name}\", \n",
    "            shell=True, \n",
    "            capture_output=True, \n",
    "            text=True\n",
    "        )\n",
    "        print(\"STDOUT:\")\n",
    "        print(result.stdout)\n",
    "        if result.stderr:\n",
    "            print(\"STDERR:\")\n",
    "            print(result.stderr)\n",
    "        return result.returncode == 0\n",
    "    except Exception as e:\n",
    "        print(f\"Error running {script_name}: {e}\")\n",
    "        return False\n",
    "\n",
    "print(\"\\nğŸ”§ Helper Functions Available:\")\n",
    "print(\"   run_deployment_script('build_and_push.sh')\")\n",
    "print(\"   run_deployment_script('deploy.sh')\")\n",
    "print(\"   run_deployment_script('cleanup.sh')\")\n",
    "print()\n",
    "print(\"ğŸ’¡ You can use these functions or run scripts directly in terminal\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37b836aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ¯ SAGEMAKER-ONLY DEPLOYMENT (RECOMMENDED APPROACH)\n",
    "\n",
    "print(\"ğŸ¯ SageMaker-Only Deployment - Most Reliable Method\")\n",
    "print(\"=\"*60)\n",
    "print(\"This approach uses SageMaker's built-in deployment capabilities\")\n",
    "print(\"âœ… No Docker required  âœ… No external scripts  âœ… Auto-handles inference\")\n",
    "print()\n",
    "\n",
    "# Step 1: Ensure we have a trained estimator\n",
    "if 'sklearn_estimator' not in locals():\n",
    "    print(\"ğŸ”§ Setting up SageMaker estimator with completed training job...\")\n",
    "    \n",
    "    from sagemaker.sklearn.estimator import SKLearn\n",
    "    \n",
    "    sklearn_estimator = SKLearn(\n",
    "        entry_point='train.py',\n",
    "        source_dir='src/model',\n",
    "        role=role,\n",
    "        instance_type='ml.m5.large',\n",
    "        framework_version='1.2-1',\n",
    "        py_version='py3',\n",
    "        hyperparameters={\n",
    "            'n_estimators': 100,\n",
    "            'max_depth': 10,\n",
    "            'random_state': 42\n",
    "        },\n",
    "        base_job_name='iris-training'\n",
    "    )\n",
    "    \n",
    "    # Point to the completed training job\n",
    "    sklearn_estimator.model_data = 's3://sagemaker-us-east-1-590184049545/iris-training-2025-08-22-23-22-58-706/output/model.tar.gz'\n",
    "    print(\"âœ… Estimator configured with existing model artifacts\")\n",
    "else:\n",
    "    print(\"âœ… SageMaker estimator already available\")\n",
    "\n",
    "print(f\"\\nğŸ“¦ Model artifacts: {sklearn_estimator.model_data}\")\n",
    "\n",
    "# Step 2: Deploy with automatic retry and fallback\n",
    "print(\"\\nğŸš€ DEPLOYING MODEL TO SAGEMAKER ENDPOINT...\")\n",
    "print(\"This will take 6-10 minutes...\")\n",
    "\n",
    "deployment_successful = False\n",
    "endpoint_name = f'iris-reliable-{datetime.now().strftime(\"%Y%m%d-%H%M%S\")}'\n",
    "\n",
    "try:\n",
    "    print(f\"ğŸ“ Deploying to endpoint: {endpoint_name}\")\n",
    "    print(\"â±ï¸ Using ml.m5.large instance...\")\n",
    "    \n",
    "    predictor = sklearn_estimator.deploy(\n",
    "        initial_instance_count=1,\n",
    "        instance_type='ml.m5.large',\n",
    "        endpoint_name=endpoint_name,\n",
    "        wait=True  # Wait for deployment to complete\n",
    "    )\n",
    "    \n",
    "    deployment_successful = True\n",
    "    print(f\"\\n\udf89 DEPLOYMENT SUCCESSFUL!\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"âš ï¸ ml.m5.large deployment failed: {e}\")\n",
    "    print(\"\udd04 Trying smaller instance type...\")\n",
    "    \n",
    "    try:\n",
    "        endpoint_name_small = f'iris-small-{datetime.now().strftime(\"%Y%m%d-%H%M%S\")}'\n",
    "        print(f\"ğŸ“ Deploying to endpoint: {endpoint_name_small}\")\n",
    "        print(\"â±ï¸ Using ml.t2.medium instance...\")\n",
    "        \n",
    "        predictor = sklearn_estimator.deploy(\n",
    "            initial_instance_count=1,\n",
    "            instance_type='ml.t2.medium',\n",
    "            endpoint_name=endpoint_name_small,\n",
    "            wait=True\n",
    "        )\n",
    "        \n",
    "        deployment_successful = True\n",
    "        endpoint_name = endpoint_name_small\n",
    "        print(f\"\\nğŸ‰ DEPLOYMENT SUCCESSFUL WITH SMALLER INSTANCE!\")\n",
    "        \n",
    "    except Exception as e2:\n",
    "        print(f\"âŒ Both deployments failed:\")\n",
    "        print(f\"   ml.m5.large: {e}\")\n",
    "        print(f\"   ml.t2.medium: {e2}\")\n",
    "        deployment_successful = False\n",
    "\n",
    "# Step 3: Test the deployed model\n",
    "if deployment_successful:\n",
    "    print(f\"\\nâœ… Model deployed successfully!\")\n",
    "    print(f\"\udccd Endpoint name: {predictor.endpoint_name}\")\n",
    "    print(f\"ğŸ“ Instance type: {predictor.endpoint_name.split('-')[1] if 'small' in predictor.endpoint_name else 'ml.m5.large'}\")\n",
    "    \n",
    "    # Test the endpoint\n",
    "    print(f\"\\nğŸ§ª TESTING THE ENDPOINT...\")\n",
    "    try:\n",
    "        test_data = [[5.1, 3.5, 1.4, 0.2]]  # Sample iris data\n",
    "        prediction = predictor.predict(test_data)\n",
    "        print(f\"ğŸ¯ Test prediction successful: {prediction}\")\n",
    "        \n",
    "        # Test with multiple samples\n",
    "        test_samples = [\n",
    "            [5.1, 3.5, 1.4, 0.2],  # Should be setosa\n",
    "            [7.0, 3.2, 4.7, 1.4],  # Should be versicolor\n",
    "            [6.3, 3.3, 6.0, 2.5]   # Should be virginica\n",
    "        ]\n",
    "        \n",
    "        predictions = predictor.predict(test_samples)\n",
    "        print(f\"ğŸ¯ Batch predictions: {predictions}\")\n",
    "        \n",
    "        print(f\"\\nğŸ‰ ENDPOINT IS WORKING PERFECTLY!\")\n",
    "        \n",
    "        # Save endpoint reference\n",
    "        globals()['working_predictor'] = predictor\n",
    "        globals()['working_endpoint_name'] = predictor.endpoint_name\n",
    "        \n",
    "        print(f\"\\nğŸ“‹ HOW TO USE YOUR ENDPOINT:\")\n",
    "        print(f\"   Endpoint name: {predictor.endpoint_name}\")\n",
    "        print(f\"   Usage: working_predictor.predict([[5.1, 3.5, 1.4, 0.2]])\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Endpoint test failed: {e}\")\n",
    "        print(\"ğŸ’¡ Check CloudWatch logs for details\")\n",
    "\n",
    "else:\n",
    "    print(f\"\\nâŒ DEPLOYMENT FAILED\")\n",
    "    print(f\"ğŸ’¡ Troubleshooting steps:\")\n",
    "    print(f\"   1. Check CloudWatch logs\")\n",
    "    print(f\"   2. Verify training job completed successfully\")\n",
    "    print(f\"   3. Check SageMaker quotas in your account\")\n",
    "    print(f\"   4. Try different region if current one is constrained\")\n",
    "\n",
    "print(f\"\\nğŸ§¹ TO CLEAN UP WHEN DONE:\")\n",
    "print(f\"# working_predictor.delete_endpoint()  # Removes endpoint and stops billing\")\n",
    "\n",
    "print(f\"\\nğŸ’¡ THIS IS THE EASIEST AND MOST RELIABLE DEPLOYMENT METHOD!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77bf7c45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ”§ ENDPOINT TROUBLESHOOTING & DIAGNOSTICS\n",
    "\n",
    "print(\"ğŸ”§ SageMaker Endpoint Troubleshooting\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "import boto3\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "def diagnose_endpoint_issues():\n",
    "    \"\"\"Comprehensive endpoint diagnostics\"\"\"\n",
    "    \n",
    "    sagemaker_client = boto3.client('sagemaker')\n",
    "    logs_client = boto3.client('logs')\n",
    "    \n",
    "    print(\"ğŸ” CHECKING RECENT ENDPOINTS...\")\n",
    "    \n",
    "    try:\n",
    "        # Get recent endpoints\n",
    "        endpoints = sagemaker_client.list_endpoints(\n",
    "            SortBy='CreationTime',\n",
    "            SortOrder='Descending',\n",
    "            MaxResults=5\n",
    "        )\n",
    "        \n",
    "        for endpoint in endpoints['Endpoints']:\n",
    "            name = endpoint['EndpointName']\n",
    "            status = endpoint['EndpointStatus']\n",
    "            created = endpoint['CreationTime']\n",
    "            \n",
    "            # Calculate time elapsed\n",
    "            now = datetime.now(created.tzinfo)\n",
    "            elapsed = now - created\n",
    "            elapsed_minutes = int(elapsed.total_seconds() / 60)\n",
    "            \n",
    "            print(f\"\\nğŸ“ {name}\")\n",
    "            print(f\"   Status: {status}\")\n",
    "            print(f\"   Created: {elapsed_minutes} minutes ago\")\n",
    "            \n",
    "            # Get detailed info for failed endpoints\n",
    "            if status in ['Failed', 'OutOfService']:\n",
    "                try:\n",
    "                    details = sagemaker_client.describe_endpoint(EndpointName=name)\n",
    "                    if 'FailureReason' in details:\n",
    "                        print(f\"   âŒ Failure: {details['FailureReason']}\")\n",
    "                        \n",
    "                        # Common failure patterns and solutions\n",
    "                        failure_reason = details['FailureReason'].lower()\n",
    "                        if 'ping health check' in failure_reason:\n",
    "                            print(f\"   ğŸ’¡ Solution: Model container not responding - check inference.py\")\n",
    "                        elif 'model loading' in failure_reason:\n",
    "                            print(f\"   ğŸ’¡ Solution: Model format issue - check model artifacts\")\n",
    "                        elif 'insufficient capacity' in failure_reason:\n",
    "                            print(f\"   ğŸ’¡ Solution: Try different instance type or region\")\n",
    "                        elif 'image' in failure_reason:\n",
    "                            print(f\"   ğŸ’¡ Solution: Framework version compatibility issue\")\n",
    "                            \n",
    "                except Exception as e:\n",
    "                    print(f\"   âš ï¸ Could not get details: {e}\")\n",
    "            \n",
    "            elif status == 'Creating' and elapsed_minutes > 15:\n",
    "                print(f\"   âš ï¸ Taking longer than expected - may fail soon\")\n",
    "            \n",
    "            elif status == 'InService':\n",
    "                print(f\"   âœ… Healthy and ready!\")\n",
    "                \n",
    "        print(f\"\\nğŸ” CHECKING CLOUDWATCH LOGS...\")\n",
    "        \n",
    "        # Check for recent SageMaker endpoint logs\n",
    "        try:\n",
    "            log_groups = logs_client.describe_log_groups(\n",
    "                logGroupNamePrefix='/aws/sagemaker/Endpoints',\n",
    "                limit=5\n",
    "            )\n",
    "            \n",
    "            for lg in log_groups['logGroups']:\n",
    "                log_group_name = lg['logGroupName']\n",
    "                print(f\"\\nğŸ“„ Log group: {log_group_name}\")\n",
    "                \n",
    "                # Get most recent log streams\n",
    "                streams = logs_client.describe_log_streams(\n",
    "                    logGroupName=log_group_name,\n",
    "                    orderBy='LastEventTime',\n",
    "                    descending=True,\n",
    "                    limit=2\n",
    "                )\n",
    "                \n",
    "                for stream in streams['logStreams']:\n",
    "                    print(f\"   ğŸ“Š Stream: {stream['logStreamName']}\")\n",
    "                    \n",
    "                    # Get recent error events\n",
    "                    try:\n",
    "                        events = logs_client.get_log_events(\n",
    "                            logGroupName=log_group_name,\n",
    "                            logStreamName=stream['logStreamName'],\n",
    "                            startTime=int((datetime.now() - timedelta(hours=2)).timestamp() * 1000)\n",
    "                        )\n",
    "                        \n",
    "                        error_events = [e for e in events['events'] \n",
    "                                      if any(keyword in e['message'].lower() \n",
    "                                           for keyword in ['error', 'failed', 'exception', 'traceback'])]\n",
    "                        \n",
    "                        if error_events:\n",
    "                            print(f\"   ğŸš¨ Recent errors found:\")\n",
    "                            for event in error_events[-3:]:  # Last 3 errors\n",
    "                                timestamp = datetime.fromtimestamp(event['timestamp'] / 1000)\n",
    "                                print(f\"      [{timestamp.strftime('%H:%M:%S')}] {event['message'][:100]}...\")\n",
    "                        else:\n",
    "                            print(f\"   âœ… No recent errors in this stream\")\n",
    "                            \n",
    "                    except Exception as e:\n",
    "                        print(f\"   âš ï¸ Could not read events: {e}\")\n",
    "                        \n",
    "        except Exception as e:\n",
    "            print(f\"âŒ Error checking CloudWatch logs: {e}\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Error checking endpoints: {e}\")\n",
    "\n",
    "def fix_common_issues():\n",
    "    \"\"\"Provide fixes for common endpoint issues\"\"\"\n",
    "    \n",
    "    print(f\"\\nğŸ› ï¸ COMMON FIXES:\")\n",
    "    print(f\"1. ğŸ¥ Health Check Failures:\")\n",
    "    print(f\"   - Ensure inference.py has proper model_fn, input_fn, predict_fn\")\n",
    "    print(f\"   - Check that model loads correctly\")\n",
    "    print(f\"   - Verify requirements.txt has correct versions\")\n",
    "    \n",
    "    print(f\"\\n2. ğŸ”§ Model Loading Issues:\")\n",
    "    print(f\"   - Check model.tar.gz format and contents\")\n",
    "    print(f\"   - Ensure model was saved with correct sklearn version\")\n",
    "    print(f\"   - Verify S3 permissions\")\n",
    "    \n",
    "    print(f\"\\n3. ğŸ’¾ Instance Issues:\")\n",
    "    print(f\"   - Try smaller instance type (ml.t2.medium)\")\n",
    "    print(f\"   - Check service quotas in AWS Console\")\n",
    "    print(f\"   - Try different region\")\n",
    "    \n",
    "    print(f\"\\n4. ğŸ³ Container Issues:\")\n",
    "    print(f\"   - Use framework_version='1.2-1' (tested)\")\n",
    "    print(f\"   - Avoid very old or very new framework versions\")\n",
    "    print(f\"   - Check SageMaker container compatibility\")\n",
    "\n",
    "# Run diagnostics\n",
    "print(\"ğŸ” Running endpoint diagnostics...\")\n",
    "diagnose_endpoint_issues()\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "fix_common_issues()\n",
    "\n",
    "print(f\"\\nğŸ’¡ BEST PRACTICE:\")\n",
    "print(f\"Always use sklearn_estimator.deploy() - it's the most reliable method!\")\n",
    "print(f\"Avoid custom containers unless absolutely necessary.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20c7ce83",
   "metadata": {},
   "source": [
    "## ğŸ”§ Endpoint Deployment Troubleshooting & Recovery\n",
    "\n",
    "If you encountered the error: **\"The primary container for production variant primary did not pass the ping health check\"**, this section will help you diagnose and fix the issue.\n",
    "\n",
    "### ğŸ” **Common Causes:**\n",
    "- âŒ Missing or incorrect inference script\n",
    "- âŒ Model loading issues \n",
    "- âŒ Container configuration problems\n",
    "- âŒ Framework version mismatches\n",
    "\n",
    "### ğŸ“‹ **Recovery Steps:**\n",
    "1. **Diagnose** - Check CloudWatch logs\n",
    "2. **Fix** - Create proper inference script\n",
    "3. **Cleanup** - Remove failed resources\n",
    "4. **Redeploy** - Use reliable method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44d12c02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ” STEP 1: Diagnose the Issue - Check CloudWatch Logs\n",
    "\n",
    "print(\"ğŸ” DIAGNOSING ENDPOINT FAILURE...\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "import boto3\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "def check_endpoint_logs():\n",
    "    \"\"\"Check CloudWatch logs for endpoint failure details\"\"\"\n",
    "    logs_client = boto3.client('logs')\n",
    "    \n",
    "    # Replace with your failed endpoint name\n",
    "    failed_endpoint_name = 'iris-endpoint-20250822-235036'  # Update this!\n",
    "    \n",
    "    print(f\"ğŸ“‹ Checking logs for endpoint: {failed_endpoint_name}\")\n",
    "    \n",
    "    try:\n",
    "        # List log groups related to SageMaker endpoints\n",
    "        log_groups = logs_client.describe_log_groups(\n",
    "            logGroupNamePrefix='/aws/sagemaker/Endpoints'\n",
    "        )\n",
    "        \n",
    "        print(\"ğŸ“„ Available SageMaker endpoint log groups:\")\n",
    "        endpoint_log_found = False\n",
    "        \n",
    "        for lg in log_groups['logGroups']:\n",
    "            log_group_name = lg['logGroupName']\n",
    "            print(f\"  ğŸ“ {log_group_name}\")\n",
    "            \n",
    "            # Check if this log group is for our failed endpoint\n",
    "            if failed_endpoint_name in log_group_name:\n",
    "                endpoint_log_found = True\n",
    "                print(f\"\\nğŸ¯ FOUND LOGS FOR FAILED ENDPOINT!\")\n",
    "                print(f\"ğŸ“‚ Log Group: {log_group_name}\")\n",
    "                \n",
    "                # Get recent log streams\n",
    "                try:\n",
    "                    streams = logs_client.describe_log_streams(\n",
    "                        logGroupName=log_group_name,\n",
    "                        orderBy='LastEventTime',\n",
    "                        descending=True,\n",
    "                        limit=3\n",
    "                    )\n",
    "                    \n",
    "                    for stream in streams['logStreams']:\n",
    "                        stream_name = stream['logStreamName']\n",
    "                        print(f\"\\nğŸ“Š Log Stream: {stream_name}\")\n",
    "                        \n",
    "                        # Get recent log events\n",
    "                        events = logs_client.get_log_events(\n",
    "                            logGroupName=log_group_name,\n",
    "                            logStreamName=stream_name,\n",
    "                            startTime=int((datetime.now() - timedelta(hours=2)).timestamp() * 1000)\n",
    "                        )\n",
    "                        \n",
    "                        print(\"ğŸ” ERROR MESSAGES:\")\n",
    "                        error_count = 0\n",
    "                        for event in events['events']:\n",
    "                            message = event['message'].strip()\n",
    "                            timestamp = datetime.fromtimestamp(event['timestamp'] / 1000)\n",
    "                            \n",
    "                            # Look for error indicators\n",
    "                            if any(keyword in message.lower() for keyword in ['error', 'failed', 'exception', 'traceback']):\n",
    "                                print(f\"  âŒ [{timestamp}] {message}\")\n",
    "                                error_count += 1\n",
    "                            elif 'ping' in message.lower():\n",
    "                                print(f\"  ğŸ“ [{timestamp}] {message}\")\n",
    "                        \n",
    "                        if error_count == 0:\n",
    "                            print(\"  â„¹ï¸  No explicit errors found in this stream\")\n",
    "                            print(\"  ğŸ“‹ Last 5 messages:\")\n",
    "                            for event in events['events'][-5:]:\n",
    "                                timestamp = datetime.fromtimestamp(event['timestamp'] / 1000)\n",
    "                                print(f\"    [{timestamp}] {event['message'].strip()}\")\n",
    "                        \n",
    "                except Exception as e:\n",
    "                    print(f\"  âš ï¸ Could not read log streams: {e}\")\n",
    "        \n",
    "        if not endpoint_log_found:\n",
    "            print(f\"\\nâš ï¸ No logs found for endpoint: {failed_endpoint_name}\")\n",
    "            print(\"ğŸ’¡ This might mean:\")\n",
    "            print(\"   â€¢ The endpoint name is incorrect\")\n",
    "            print(\"   â€¢ The logs haven't been generated yet\")\n",
    "            print(\"   â€¢ The endpoint failed before logging started\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Error accessing CloudWatch logs: {e}\")\n",
    "        print(\"ğŸ’¡ Make sure you have CloudWatch read permissions\")\n",
    "\n",
    "# Run the diagnostic\n",
    "check_endpoint_logs()\n",
    "\n",
    "print(\"\\nğŸ’¡ COMMON ISSUES AND SOLUTIONS:\")\n",
    "print(\"ğŸ”§ If you see 'ModuleNotFoundError': Missing dependencies\")\n",
    "print(\"ğŸ”§ If you see 'No module named inference': Missing inference.py\")\n",
    "print(\"ğŸ”§ If you see 'model loading failed': Wrong model format\")\n",
    "print(\"ğŸ”§ If no logs found: Endpoint failed during startup\")\n",
    "\n",
    "print(\"\\nâ¡ï¸ NEXT: Run the cells below to fix the issues\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07b0eb39",
   "metadata": {},
   "source": [
    "## ğŸ› ï¸ Using MLOps Scripts\n",
    "\n",
    "Now that your model is ready, let's explore how to use the MLOps scripts that are available in your environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "660c4b0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explore available scripts\n",
    "print(\"ğŸ” Available MLOps Scripts:\")\n",
    "print()\n",
    "\n",
    "scripts_info = {\n",
    "    'build_and_push.sh': {\n",
    "        'purpose': 'Build Docker container and push to ECR',\n",
    "        'usage': 'Used for containerizing your model for production deployment',\n",
    "        'when': 'After model training, before deployment to production'\n",
    "    },\n",
    "    'deploy.sh': {\n",
    "        'purpose': 'Deploy model to SageMaker endpoint using Step Functions',\n",
    "        'usage': 'Orchestrates the complete deployment pipeline',\n",
    "        'when': 'When ready to deploy model to production'\n",
    "    },\n",
    "    'test_endpoint.py': {\n",
    "        'purpose': 'Test deployed SageMaker endpoints',\n",
    "        'usage': 'Automated testing of model predictions',\n",
    "        'when': 'After deployment to validate model is working'\n",
    "    },\n",
    "    'cleanup.sh': {\n",
    "        'purpose': 'Clean up AWS resources to save costs',\n",
    "        'usage': 'Removes endpoints, models, and other billable resources',\n",
    "        'when': 'When done with experimentation or deployment'\n",
    "    }\n",
    "}\n",
    "\n",
    "# Check which scripts are available\n",
    "available_scripts = []\n",
    "if os.path.exists('scripts'):\n",
    "    available_scripts = os.listdir('scripts')\n",
    "\n",
    "for script, info in scripts_info.items():\n",
    "    status = \"âœ… Available\" if script in available_scripts else \"âŒ Missing\"\n",
    "    print(f\"{status} {script}\")\n",
    "    print(f\"   ğŸ“ Purpose: {info['purpose']}\")\n",
    "    print(f\"   ğŸ¯ Usage: {info['usage']}\")\n",
    "    print(f\"   â° When: {info['when']}\")\n",
    "    print()\n",
    "\n",
    "# Show how to run scripts\n",
    "if available_scripts:\n",
    "    print(\"ğŸš€ How to use scripts:\")\n",
    "    print()\n",
    "    print(\"1. ğŸ“¦ Build and containerize your model:\")\n",
    "    print(\"   !cd scripts && ./build_and_push.sh\")\n",
    "    print()\n",
    "    print(\"2. ğŸš€ Deploy to production:\")\n",
    "    print(\"   !cd scripts && ./deploy.sh\")\n",
    "    print()\n",
    "    print(\"3. ğŸ§ª Test your endpoint:\")\n",
    "    print(\"   !cd scripts && python test_endpoint.py --endpoint-name your-endpoint\")\n",
    "    print()\n",
    "    print(\"4. ğŸ§¹ Clean up resources:\")\n",
    "    print(\"   !cd scripts && ./cleanup.sh\")\n",
    "    print()\n",
    "    \n",
    "    # Example: Show the contents of test_endpoint.py if available\n",
    "    test_script_path = 'scripts/test_endpoint.py'\n",
    "    if os.path.exists(test_script_path):\n",
    "        print(\"ğŸ“‹ Example: test_endpoint.py usage:\")\n",
    "        with open(test_script_path, 'r') as f:\n",
    "            lines = f.readlines()[:20]  # Show first 20 lines\n",
    "            print(\"\".join(lines))\n",
    "            if len(f.readlines()) > 20:\n",
    "                print(\"... (truncated)\")\n",
    "\n",
    "else:\n",
    "    print(\"âš ï¸ Scripts not found. They will be downloaded automatically when you apply Terraform changes.\")\n",
    "    print(\"   Or you can manually download them from your S3 bucket.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f301247",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸš€ DEPLOY MODEL TO SAGEMAKER ENDPOINT - ROBUST VERSION\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"ğŸš€ DEPLOYING MODEL TO SAGEMAKER ENDPOINT\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "import time\n",
    "import boto3\n",
    "from datetime import datetime\n",
    "\n",
    "# Configuration with fallback options\n",
    "ENDPOINT_NAME = f\"iris-model-demo-{int(time.time())}\"\n",
    "INSTANCE_TYPES = ['ml.m5.large', 'ml.m5.xlarge', 'ml.c5.large', 'ml.t3.medium']  # Fallback options\n",
    "DEPLOYMENT_TIMEOUT = 600  # 10 minutes max\n",
    "\n",
    "def deploy_with_fallback(estimator, endpoint_name, instance_types):\n",
    "    \"\"\"Deploy model with instance type fallback for reliability\"\"\"\n",
    "    \n",
    "    for i, instance_type in enumerate(instance_types):\n",
    "        try:\n",
    "            print(f\"\\nğŸ”„ Attempting deployment with {instance_type} (attempt {i+1}/{len(instance_types)})\")\n",
    "            \n",
    "            # Try to deploy\n",
    "            predictor = estimator.deploy(\n",
    "                initial_instance_count=1,\n",
    "                instance_type=instance_type,\n",
    "                endpoint_name=endpoint_name,\n",
    "                wait=True,\n",
    "                update_endpoint=False\n",
    "            )\n",
    "            \n",
    "            print(f\"âœ… Successfully deployed on {instance_type}\")\n",
    "            return predictor, instance_type\n",
    "            \n",
    "        except Exception as e:\n",
    "            error_msg = str(e)\n",
    "            print(f\"âŒ Failed with {instance_type}: {error_msg}\")\n",
    "            \n",
    "            # Clean up failed endpoint if it exists\n",
    "            try:\n",
    "                sagemaker_client = boto3.client('sagemaker')\n",
    "                sagemaker_client.delete_endpoint(EndpointName=endpoint_name)\n",
    "                print(f\"ğŸ§¹ Cleaned up failed endpoint: {endpoint_name}\")\n",
    "                time.sleep(30)  # Wait for cleanup\n",
    "            except:\n",
    "                pass\n",
    "            \n",
    "            # Check if we should retry with next instance type\n",
    "            if i < len(instance_types) - 1:\n",
    "                print(f\"ğŸ”„ Retrying with next instance type...\")\n",
    "                time.sleep(10)\n",
    "            else:\n",
    "                print(f\"ğŸ’¥ All instance types failed. Last error: {error_msg}\")\n",
    "                raise Exception(f\"Deployment failed on all instance types: {error_msg}\")\n",
    "\n",
    "# Deploy the model\n",
    "try:\n",
    "    start_time = datetime.now()\n",
    "    print(f\"ğŸ“… Deployment started at: {start_time}\")\n",
    "    \n",
    "    predictor, used_instance_type = deploy_with_fallback(\n",
    "        sklearn_estimator, \n",
    "        ENDPOINT_NAME, \n",
    "        INSTANCE_TYPES\n",
    "    )\n",
    "    \n",
    "    end_time = datetime.now()\n",
    "    duration = (end_time - start_time).total_seconds()\n",
    "    \n",
    "    print(f\"\\nğŸ‰ DEPLOYMENT SUCCESSFUL!\")\n",
    "    print(f\"ğŸ“Š Endpoint Name: {ENDPOINT_NAME}\")\n",
    "    print(f\"ğŸ’» Instance Type: {used_instance_type}\")\n",
    "    print(f\"â±ï¸  Deployment Time: {duration:.1f} seconds\")\n",
    "    print(f\"ğŸŒ Endpoint URL: https://console.aws.amazon.com/sagemaker/home#/endpoints/{ENDPOINT_NAME}\")\n",
    "    \n",
    "    # Test the endpoint immediately\n",
    "    print(f\"\\nğŸ§ª TESTING ENDPOINT...\")\n",
    "    test_data = [[5.1, 3.5, 1.4, 0.2], [6.7, 3.1, 4.4, 1.4]]\n",
    "    \n",
    "    prediction = predictor.predict(test_data)\n",
    "    print(f\"âœ… Test Prediction: {prediction}\")\n",
    "    print(f\"ğŸ“ˆ Model is responding correctly!\")\n",
    "    \n",
    "    # Store endpoint info for later use\n",
    "    endpoint_info = {\n",
    "        'endpoint_name': ENDPOINT_NAME,\n",
    "        'instance_type': used_instance_type,\n",
    "        'deployment_time': duration,\n",
    "        'test_prediction': prediction\n",
    "    }\n",
    "    \n",
    "    print(f\"\\nğŸ“ Endpoint deployed and tested successfully!\")\n",
    "    print(f\"ğŸ’¡ Use 'predictor.delete_endpoint()' to clean up when done\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"\\nğŸ’¥ DEPLOYMENT FAILED!\")\n",
    "    print(f\"âŒ Error: {str(e)}\")\n",
    "    print(f\"\\nğŸ”§ Troubleshooting suggestions:\")\n",
    "    print(f\"   1. Check your AWS account limits for SageMaker instances\")\n",
    "    print(f\"   2. Verify the model was trained successfully\")\n",
    "    print(f\"   3. Check CloudWatch logs for detailed error messages\")\n",
    "    print(f\"   4. Try running the troubleshooting cell below\")\n",
    "    \n",
    "    # Re-raise for debugging\n",
    "    raise e"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98a48df0",
   "metadata": {},
   "source": [
    "## 8. Test Model Predictions\n",
    "\n",
    "Demonstrate how to test your deployed model using the same patterns as `scripts/test_endpoint.py`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f12fc0d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ”§ ENDPOINT TROUBLESHOOTING & DIAGNOSTICS\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"ğŸ”§ SAGEMAKER ENDPOINT TROUBLESHOOTING & DIAGNOSTICS\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "import boto3\n",
    "import json\n",
    "import time\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "def comprehensive_endpoint_diagnostics(endpoint_name=None):\n",
    "    \"\"\"Comprehensive diagnostics for SageMaker endpoint issues\"\"\"\n",
    "    \n",
    "    sagemaker = boto3.client('sagemaker')\n",
    "    logs_client = boto3.client('logs')\n",
    "    \n",
    "    print(f\"ğŸ” Running comprehensive diagnostics...\")\n",
    "    \n",
    "    # 1. List all endpoints if none specified\n",
    "    if not endpoint_name:\n",
    "        print(f\"\\nğŸ“‹ LISTING ALL ENDPOINTS:\")\n",
    "        try:\n",
    "            response = sagemaker.list_endpoints()\n",
    "            endpoints = response['Endpoints']\n",
    "            \n",
    "            if not endpoints:\n",
    "                print(\"âŒ No endpoints found. Deploy a model first.\")\n",
    "                return\n",
    "            \n",
    "            for ep in endpoints:\n",
    "                status_icon = \"âœ…\" if ep['EndpointStatus'] == 'InService' else \"âŒ\"\n",
    "                print(f\"   {status_icon} {ep['EndpointName']}: {ep['EndpointStatus']}\")\n",
    "            \n",
    "            # Use the most recent endpoint\n",
    "            endpoint_name = endpoints[-1]['EndpointName']\n",
    "            print(f\"\\nğŸ¯ Using most recent endpoint: {endpoint_name}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"âŒ Error listing endpoints: {e}\")\n",
    "            return\n",
    "    \n",
    "    # 2. Check endpoint status\n",
    "    print(f\"\\nğŸ“Š ENDPOINT STATUS CHECK:\")\n",
    "    try:\n",
    "        response = sagemaker.describe_endpoint(EndpointName=endpoint_name)\n",
    "        status = response['EndpointStatus']\n",
    "        creation_time = response['CreationTime']\n",
    "        \n",
    "        status_icon = \"âœ…\" if status == 'InService' else \"âŒ\"\n",
    "        print(f\"   {status_icon} Status: {status}\")\n",
    "        print(f\"   ğŸ“… Created: {creation_time}\")\n",
    "        \n",
    "        if status == 'Failed':\n",
    "            print(f\"   ğŸ’¥ Failure Reason: {response.get('FailureReason', 'Unknown')}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Error checking endpoint status: {e}\")\n",
    "        return endpoint_name\n",
    "    \n",
    "    # 3. Check endpoint configuration\n",
    "    print(f\"\\nâš™ï¸  ENDPOINT CONFIGURATION:\")\n",
    "    try:\n",
    "        config_name = response['EndpointConfigName']\n",
    "        config_response = sagemaker.describe_endpoint_config(EndpointConfigName=config_name)\n",
    "        \n",
    "        for variant in config_response['ProductionVariants']:\n",
    "            print(f\"   ğŸ–¥ï¸  Instance Type: {variant['InstanceType']}\")\n",
    "            print(f\"   ğŸ“Š Instance Count: {variant['InitialInstanceCount']}\")\n",
    "            print(f\"   ğŸ·ï¸  Variant Name: {variant['VariantName']}\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Error checking endpoint config: {e}\")\n",
    "    \n",
    "    # 4. Check CloudWatch logs\n",
    "    print(f\"\\nğŸ“‹ CLOUDWATCH LOGS (Last 30 minutes):\")\n",
    "    try:\n",
    "        log_group = f\"/aws/sagemaker/Endpoints/{endpoint_name}\"\n",
    "        end_time = datetime.now()\n",
    "        start_time = end_time - timedelta(minutes=30)\n",
    "        \n",
    "        # Get log streams\n",
    "        streams_response = logs_client.describe_log_streams(\n",
    "            logGroupName=log_group,\n",
    "            orderBy='LastEventTime',\n",
    "            descending=True,\n",
    "            limit=5\n",
    "        )\n",
    "        \n",
    "        if streams_response['logStreams']:\n",
    "            print(f\"   ğŸ“ Found {len(streams_response['logStreams'])} log streams\")\n",
    "            \n",
    "            # Get recent log events\n",
    "            stream_name = streams_response['logStreams'][0]['logStreamName']\n",
    "            events_response = logs_client.get_log_events(\n",
    "                logGroupName=log_group,\n",
    "                logStreamName=stream_name,\n",
    "                startTime=int(start_time.timestamp() * 1000),\n",
    "                endTime=int(end_time.timestamp() * 1000),\n",
    "                limit=20\n",
    "            )\n",
    "            \n",
    "            events = events_response['events']\n",
    "            if events:\n",
    "                print(f\"   ğŸ“„ Recent log events:\")\n",
    "                for event in events[-10:]:  # Show last 10 events\n",
    "                    timestamp = datetime.fromtimestamp(event['timestamp'] / 1000)\n",
    "                    message = event['message'].strip()\n",
    "                    print(f\"   {timestamp.strftime('%H:%M:%S')} | {message}\")\n",
    "            else:\n",
    "                print(f\"   â„¹ï¸  No recent log events found\")\n",
    "        else:\n",
    "            print(f\"   â„¹ï¸  No log streams found yet\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"   âš ï¸  CloudWatch logs not accessible: {e}\")\n",
    "    \n",
    "    # 5. Test endpoint if InService\n",
    "    if status == 'InService':\n",
    "        print(f\"\\nğŸ§ª ENDPOINT CONNECTIVITY TEST:\")\n",
    "        try:\n",
    "            runtime = boto3.client('sagemaker-runtime')\n",
    "            test_data = [[5.1, 3.5, 1.4, 0.2]]\n",
    "            \n",
    "            response = runtime.invoke_endpoint(\n",
    "                EndpointName=endpoint_name,\n",
    "                ContentType='application/json',\n",
    "                Body=json.dumps(test_data)\n",
    "            )\n",
    "            \n",
    "            result = json.loads(response['Body'].read().decode())\n",
    "            print(f\"   âœ… Test successful! Prediction: {result}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"   âŒ Test failed: {e}\")\n",
    "    \n",
    "    # 6. Provide actionable recommendations\n",
    "    print(f\"\\nğŸ’¡ TROUBLESHOOTING RECOMMENDATIONS:\")\n",
    "    \n",
    "    if status == 'Failed':\n",
    "        print(f\"   ğŸ”§ ENDPOINT FAILED - Try these fixes:\")\n",
    "        print(f\"      1. Check the model artifacts exist and are accessible\")\n",
    "        print(f\"      2. Verify the inference script has proper /ping and /invocations handlers\")\n",
    "        print(f\"      3. Ensure model dependencies are correctly specified\")\n",
    "        print(f\"      4. Try a different instance type (ml.t3.medium for testing)\")\n",
    "        print(f\"      5. Check AWS account limits and quotas\")\n",
    "        \n",
    "    elif status == 'Creating':\n",
    "        print(f\"   â³ ENDPOINT CREATING - This is normal:\")\n",
    "        print(f\"      â€¢ Typical deployment takes 6-10 minutes\")\n",
    "        print(f\"      â€¢ Check again in a few minutes\")\n",
    "        print(f\"      â€¢ Monitor CloudWatch logs for progress\")\n",
    "        \n",
    "    elif status == 'InService':\n",
    "        print(f\"   âœ… ENDPOINT HEALTHY - All good!\")\n",
    "        print(f\"      â€¢ You can make predictions\")\n",
    "        print(f\"      â€¢ Remember to delete when done to save costs\")\n",
    "        \n",
    "    else:\n",
    "        print(f\"   âš ï¸  UNKNOWN STATUS - General troubleshooting:\")\n",
    "        print(f\"      1. Wait a few minutes and check again\")\n",
    "        print(f\"      2. Check AWS Service Health Dashboard\")\n",
    "        print(f\"      3. Verify your AWS credentials and region\")\n",
    "    \n",
    "    print(f\"\\nğŸ”„ Run this cell again to refresh diagnostics\")\n",
    "    return endpoint_name\n",
    "\n",
    "# Run diagnostics\n",
    "try:\n",
    "    # Try to use the endpoint from previous deployment\n",
    "    endpoint_name = locals().get('ENDPOINT_NAME') or globals().get('endpoint_info', {}).get('endpoint_name')\n",
    "    result_endpoint = comprehensive_endpoint_diagnostics(endpoint_name)\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"ğŸ’¥ Diagnostics failed: {e}\")\n",
    "    print(f\"ğŸ’¡ This might be normal if no endpoints exist yet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bffbade",
   "metadata": {},
   "source": [
    "## 9. Monitor Model Performance\n",
    "\n",
    "Set up monitoring to track model performance and data drift over time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd50b7f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ§¹ CLEANUP & COST MANAGEMENT\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"ğŸ§¹ CLEANUP & COST MANAGEMENT\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "import boto3\n",
    "from datetime import datetime\n",
    "\n",
    "def comprehensive_cleanup():\n",
    "    \"\"\"Clean up all SageMaker resources to prevent unnecessary costs\"\"\"\n",
    "    \n",
    "    sagemaker = boto3.client('sagemaker')\n",
    "    \n",
    "    print(f\"ğŸ” Scanning for SageMaker resources to clean up...\")\n",
    "    \n",
    "    # 1. List and optionally delete endpoints\n",
    "    print(f\"\\nğŸ“Š ENDPOINTS:\")\n",
    "    try:\n",
    "        response = sagemaker.list_endpoints()\n",
    "        endpoints = response['Endpoints']\n",
    "        \n",
    "        if not endpoints:\n",
    "            print(\"   âœ… No endpoints found\")\n",
    "        else:\n",
    "            for ep in endpoints:\n",
    "                status_icon = \"ğŸŸ¢\" if ep['EndpointStatus'] == 'InService' else \"ğŸ”´\"\n",
    "                cost_per_hour = get_estimated_cost(ep.get('InstanceType', 'ml.m5.large'))\n",
    "                print(f\"   {status_icon} {ep['EndpointName']}: {ep['EndpointStatus']} (~${cost_per_hour:.2f}/hour)\")\n",
    "        \n",
    "        # Ask if user wants to delete endpoints\n",
    "        if endpoints:\n",
    "            print(f\"\\nğŸ’° Estimated monthly cost if left running: ${len(endpoints) * 24 * 30 * 0.115:.2f}\")\n",
    "            print(f\"âš ï¸  Delete endpoints to stop charges!\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Error listing endpoints: {e}\")\n",
    "    \n",
    "    # 2. List training jobs\n",
    "    print(f\"\\nğŸ¯ RECENT TRAINING JOBS:\")\n",
    "    try:\n",
    "        response = sagemaker.list_training_jobs(\n",
    "            MaxResults=10,\n",
    "            SortBy='CreationTime',\n",
    "            SortOrder='Descending'\n",
    "        )\n",
    "        \n",
    "        jobs = response['TrainingJobSummaries']\n",
    "        if not jobs:\n",
    "            print(\"   âœ… No recent training jobs\")\n",
    "        else:\n",
    "            for job in jobs[:5]:  # Show last 5\n",
    "                status_icon = \"âœ…\" if job['TrainingJobStatus'] == 'Completed' else \"âŒ\"\n",
    "                print(f\"   {status_icon} {job['TrainingJobName']}: {job['TrainingJobStatus']}\")\n",
    "                \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Error listing training jobs: {e}\")\n",
    "    \n",
    "    # 3. List models\n",
    "    print(f\"\\nğŸ¤– MODELS:\")\n",
    "    try:\n",
    "        response = sagemaker.list_models(MaxResults=10)\n",
    "        models = response['Models']\n",
    "        \n",
    "        if not models:\n",
    "            print(\"   âœ… No models found\")\n",
    "        else:\n",
    "            for model in models:\n",
    "                print(f\"   ğŸ“¦ {model['ModelName']}: {model['CreationTime']}\")\n",
    "                \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Error listing models: {e}\")\n",
    "    \n",
    "    # 4. Provide cleanup options\n",
    "    print(f\"\\nğŸ§¹ CLEANUP OPTIONS:\")\n",
    "    print(f\"   1. Delete specific endpoint: predictor.delete_endpoint()\")\n",
    "    print(f\"   2. Delete all endpoints: Use the functions below\")\n",
    "    print(f\"   3. Models and training jobs don't incur ongoing costs\")\n",
    "\n",
    "def get_estimated_cost(instance_type):\n",
    "    \"\"\"Get estimated hourly cost for instance type\"\"\"\n",
    "    cost_map = {\n",
    "        'ml.t3.medium': 0.05,\n",
    "        'ml.m5.large': 0.115,\n",
    "        'ml.m5.xlarge': 0.23,\n",
    "        'ml.c5.large': 0.102,\n",
    "        'ml.c5.xlarge': 0.204\n",
    "    }\n",
    "    return cost_map.get(instance_type, 0.115)\n",
    "\n",
    "def delete_all_endpoints():\n",
    "    \"\"\"Delete all endpoints - USE WITH CAUTION\"\"\"\n",
    "    sagemaker = boto3.client('sagemaker')\n",
    "    \n",
    "    try:\n",
    "        response = sagemaker.list_endpoints()\n",
    "        endpoints = response['Endpoints']\n",
    "        \n",
    "        if not endpoints:\n",
    "            print(\"âœ… No endpoints to delete\")\n",
    "            return\n",
    "        \n",
    "        print(f\"ğŸ—‘ï¸  Deleting {len(endpoints)} endpoint(s)...\")\n",
    "        \n",
    "        for ep in endpoints:\n",
    "            endpoint_name = ep['EndpointName']\n",
    "            try:\n",
    "                sagemaker.delete_endpoint(EndpointName=endpoint_name)\n",
    "                print(f\"   âœ… Deleted: {endpoint_name}\")\n",
    "            except Exception as e:\n",
    "                print(f\"   âŒ Failed to delete {endpoint_name}: {e}\")\n",
    "        \n",
    "        print(f\"ğŸ‰ Cleanup complete! All endpoints deleted.\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Error during cleanup: {e}\")\n",
    "\n",
    "def delete_endpoint_by_name(endpoint_name):\n",
    "    \"\"\"Delete a specific endpoint by name\"\"\"\n",
    "    sagemaker = boto3.client('sagemaker')\n",
    "    \n",
    "    try:\n",
    "        sagemaker.delete_endpoint(EndpointName=endpoint_name)\n",
    "        print(f\"âœ… Successfully deleted endpoint: {endpoint_name}\")\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Failed to delete endpoint {endpoint_name}: {e}\")\n",
    "\n",
    "# Run the resource scan\n",
    "comprehensive_cleanup()\n",
    "\n",
    "print(f\"\\nğŸ’¡ CLEANUP COMMANDS:\")\n",
    "print(f\"   â€¢ Delete specific endpoint: delete_endpoint_by_name('your-endpoint-name')\")\n",
    "print(f\"   â€¢ Delete ALL endpoints: delete_all_endpoints()  # âš ï¸ USE WITH CAUTION\")\n",
    "print(f\"   â€¢ Using predictor object: predictor.delete_endpoint()\")\n",
    "\n",
    "print(f\"\\nğŸ’° COST REMINDERS:\")\n",
    "print(f\"   â€¢ Endpoints charge by the hour (~$0.05-0.23/hour)\")\n",
    "print(f\"   â€¢ Training jobs only charge while running\")\n",
    "print(f\"   â€¢ Models stored in S3 have minimal storage costs\")\n",
    "print(f\"   â€¢ Always clean up endpoints when done!\")\n",
    "\n",
    "print(f\"\\nğŸ”„ Run this cell periodically to monitor your AWS costs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "521a3ec5",
   "metadata": {},
   "source": [
    "## ğŸ¯ Summary: Your Complete MLOps Workflow\n",
    "\n",
    "### What you've learned:\n",
    "\n",
    "#### ğŸ”„ **Development Workflow:**\n",
    "1. **Explore & Experiment** â†’ Use SageMaker Notebook for EDA and prototyping\n",
    "2. **Process & Engineer** â†’ Create reproducible feature pipelines\n",
    "3. **Train & Validate** â†’ Use both local and SageMaker training\n",
    "4. **Deploy & Monitor** â†’ Production deployment with monitoring\n",
    "\n",
    "#### ğŸ“ **How `src/` supports you:**\n",
    "- **`src/model/train.py`** â†’ Production-ready training script you can customize\n",
    "- **`src/model/inference.py`** â†’ Handles model serving logic\n",
    "- **`src/container/`** â†’ Docker setup for custom algorithms\n",
    "- **`src/lambda/`** â†’ Pipeline automation and orchestration\n",
    "\n",
    "#### ğŸ› ï¸ **How `scripts/` supports you:**\n",
    "- **`scripts/build_and_push.sh`** â†’ Containerize and deploy your models\n",
    "- **`scripts/deploy.sh`** â†’ Orchestrated production deployment\n",
    "- **`scripts/test_endpoint.py`** â†’ Automated endpoint testing\n",
    "- **`scripts/cleanup.sh`** â†’ Clean up resources to save costs\n",
    "\n",
    "#### ğŸš€ **Next Steps:**\n",
    "1. **Customize training script** â†’ Modify `src/model/train.py` for your algorithms\n",
    "2. **Deploy to production** â†’ Run `scripts/deploy.sh` when ready\n",
    "3. **Set up monitoring** â†’ Use the baseline we created\n",
    "4. **Iterate and improve** â†’ Use the notebook for continuous experimentation\n",
    "\n",
    "#### ğŸ’¡ **Pro Tips:**\n",
    "- Save all your experiments and processed data to S3\n",
    "- Use the production scripts for consistency between dev and prod\n",
    "- Monitor your models continuously for drift and performance\n",
    "- Version your models and track experiments\n",
    "\n",
    "### ğŸ‰ **You now have a complete MLOps pipeline at your disposal!**"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
